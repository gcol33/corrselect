[{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Advanced Topics","text":"vignette covers advanced topics power users, researchers, method developers: Understanding Algorithms - Exact vs greedy, complexity analysis Custom Engines - Integrate modeling package (INLA, mgcv, brms) Exact Subset Enumeration - Multiple maximal subsets Performance Optimization - Speed memory considerations Troubleshooting - Common issues solutions Target audience: Users comfortable R programming statistical methods Estimated time: 15-20 minutes","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exact-vs-greedy-when-to-use-each","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.1 Exact vs Greedy: When to Use Each","title":"Advanced Topics","text":"corrselect offers two algorithmic approaches corrPrune():","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exact-mode-graph-theoretic","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Exact Mode (Graph-Theoretic)","title":"Advanced Topics","text":"Algorithm: Eppstein–Löffler–Strash (ELS) Bron–Kerbosch Complexity: O(2^p) - exponential number predictors Guarantee: Finds largest maximal independent set Use exact mode : - p ≤ 20 (feasible runtime) - need guaranteed optimal solution - Reproducibility critical - ’re writing paper (justify optimality)","code":"library(corrselect) data(mtcars)  # Exact mode: guaranteed optimal exact_result <- corrPrune(mtcars, threshold = 0.7, mode = \"exact\") cat(\"Exact mode kept:\", ncol(exact_result), \"variables\\n\") #> Exact mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"greedy-mode-heuristic","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Greedy Mode (Heuristic)","title":"Advanced Topics","text":"Algorithm: Deterministic iterative removal Complexity: O(p² × k) k = iterations Guarantee: Near-optimal, deterministic Use greedy mode : - p > 20 (exact becomes slow) - Speed priority - Near-optimal acceptable - High-dimensional data (p > 100)","code":"# Greedy mode: fast approximation greedy_result <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\") cat(\"Greedy mode kept:\", ncol(greedy_result), \"variables\\n\") #> Greedy mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"auto-mode-recommended","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Auto Mode (Recommended)","title":"Advanced Topics","text":"Automatically selects based p:","code":"# Auto mode: smart switching (exact if p ≤ 20, greedy otherwise) auto_result <- corrPrune(mtcars, threshold = 0.7, mode = \"auto\") cat(\"Auto mode kept:\", ncol(auto_result), \"variables\\n\") #> Auto mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"complexity-analysis-with-benchmarks","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.2 Complexity Analysis with Benchmarks","title":"Advanced Topics","text":"Let’s measure runtime scaling:  Key insight: Exact mode becomes impractical beyond p ≈ 25. Greedy mode scales linearly.","code":"# Generate datasets with increasing p benchmark_corrPrune <- function(p_values) {   results <- data.frame(     p = integer(),     exact_time = numeric(),     greedy_time = numeric()   )    for (p in p_values) {     # Generate correlated data     set.seed(123)     cor_mat <- 0.5^abs(outer(1:p, 1:p, \"-\"))     data <- as.data.frame(MASS::mvrnorm(n = 100, mu = rep(0, p), Sigma = cor_mat))      # Exact mode (skip if p too large)     exact_time <- if (p <= 25) {       system.time({         corrPrune(data, threshold = 0.7, mode = \"exact\")       })[\"elapsed\"]     } else {       NA     }      # Greedy mode     greedy_time <- system.time({       corrPrune(data, threshold = 0.7, mode = \"greedy\")     })[\"elapsed\"]      results <- rbind(results, data.frame(       p = p,       exact_time = exact_time,       greedy_time = greedy_time     ))   }    results }  # Benchmark p_values <- c(10, 15, 20, 25, 50, 100) benchmark <- benchmark_corrPrune(p_values) print(benchmark) #>            p exact_time greedy_time #> elapsed   10          0           0 #> elapsed1  15          0           0 #> elapsed2  20          0           0 #> elapsed3  25          0           0 #> elapsed4  50         NA           0 #> elapsed5 100         NA           0 # Visualize scaling plot(benchmark$p, benchmark$exact_time,      type = \"b\", col = \"red\", lwd = 2,      xlab = \"Number of Predictors (p)\",      ylab = \"Time (seconds)\",      main = \"Exact vs Greedy Scaling\",      ylim = c(0, max(benchmark$exact_time, na.rm = TRUE) * 1.1),      log = \"y\") #> Warning in xy.coords(x, y, xlabel, ylabel, log): 4 y values <= 0 omitted from #> logarithmic plot #> Warning in plot.window(...): nonfinite axis=2 limits [GScale(-inf,-inf,..); #> log=TRUE] -- corrected now lines(benchmark$p, benchmark$greedy_time, type = \"b\", col = \"blue\", lwd = 2) legend(\"topleft\", legend = c(\"Exact\", \"Greedy\"),        col = c(\"red\", \"blue\"), lwd = 2) abline(v = 20, lty = 2, col = \"gray\") text(20, max(benchmark$exact_time, na.rm = TRUE), \"Auto switches here\", pos = 4)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"deterministic-tie-breaking","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.3 Deterministic Tie-Breaking","title":"Advanced Topics","text":"multiple variables identical correlation profiles, corrselect uses deterministic tie-breaking: Tie-breaking rules: 1. Prefer variables lower mean absolute correlation others 2. still tied, prefer lexicographically first (alphabetical) ensures reproducibility across runs, machines, R versions.","code":"# Create data with identical correlations set.seed(123) x1 <- rnorm(100) x2 <- x1 + rnorm(100, sd = 0.1)  # Almost identical to x1 x3 <- x1 + rnorm(100, sd = 0.1)  # Also almost identical to x1 x4 <- rnorm(100)                  # Independent  data_ties <- data.frame(x1, x2, x3, x4)  # Run multiple times - always same result result1 <- corrPrune(data_ties, threshold = 0.95) result2 <- corrPrune(data_ties, threshold = 0.95)  cat(\"Run 1 selected:\", names(result1), \"\\n\") #> Run 1 selected: x2 x4 cat(\"Run 2 selected:\", names(result2), \"\\n\") #> Run 2 selected: x2 x4 cat(\"Identical:\", identical(names(result1), names(result2)), \"\\n\") #> Identical: TRUE"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"custom-engine-structure","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.1 Custom Engine Structure","title":"Advanced Topics","text":"custom engine named list two required functions:","code":"my_engine <- list(   # Required: How to fit the model   fit = function(formula, data, ...) {     # Your model fitting code     # Must return a fitted model object   },    # Required: How to compute diagnostics   diagnostics = function(model, fixed_effects) {     # Compute diagnostic scores for each fixed effect     # Higher values = worse (more likely to be removed)     # Must return a named numeric vector   },    # Optional: Name for error messages   name = \"my_custom_engine\"  # Defaults to \"custom\" )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-inla-engine-bayesian-spatial-models","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.2 Example: INLA Engine (Bayesian Spatial Models)","title":"Advanced Topics","text":"INLA popular package Bayesian inference. Let’s integrate : works: 1. fit function calls INLA fit model 2. diagnostics extracts posterior SDs fixed effects 3. modelPrune iteratively removes variables SD > 0.5","code":"# Custom engine for INLA inla_engine <- list(   name = \"inla\",    fit = function(formula, data, ...) {     # Fit INLA model     INLA::inla(       formula = formula,       data = data,       family = list(...)$family %||% \"gaussian\",       control.compute = list(config = TRUE),       ...     )   },    diagnostics = function(model, fixed_effects) {     # Use posterior SD as \"badness\" metric     # Higher SD = more uncertain = candidate for removal     summary_fixed <- model$summary.fixed     scores <- summary_fixed[, \"sd\"]     names(scores) <- rownames(summary_fixed)      # Return scores for fixed effects only     scores[fixed_effects]   } )  # Usage pruned <- modelPrune(   y ~ x1 + x2 + x3 + x4,   data = my_data,   engine = inla_engine,   limit = 0.5  # Remove if posterior SD > 0.5 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-mgcv-engine-gams","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.3 Example: mgcv Engine (GAMs)","title":"Advanced Topics","text":"Generalized Additive Models (GAMs) via mgcv:","code":"# Custom engine for mgcv GAMs mgcv_engine <- list(   name = \"mgcv_gam\",    fit = function(formula, data, ...) {     mgcv::gam(formula, data = data, ...)   },    diagnostics = function(model, fixed_effects) {     # Use p-values as badness metric     # Higher p-value = less significant = candidate for removal     summary_obj <- summary(model)      # Extract parametric term p-values     pvals <- summary_obj$p.pv      # Return p-values for fixed effects     pvals[fixed_effects]   } )  # Usage pruned <- modelPrune(   y ~ x1 + x2 + s(x3),  # s() for smooth terms   data = my_data,   engine = mgcv_engine,   limit = 0.05  # Remove if p > 0.05 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-custom-criterion-aic-based","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.4 Example: Custom Criterion (AIC-Based)","title":"Advanced Topics","text":"can define entirely custom pruning criteria:","code":"# AIC-based pruning engine aic_engine <- list(   name = \"aic_pruner\",    fit = function(formula, data, ...) {     lm(formula, data = data)   },    diagnostics = function(model, fixed_effects) {     # For each predictor, compute ΔAIC if removed     full_aic <- AIC(model)      scores <- numeric(length(fixed_effects))     names(scores) <- fixed_effects      for (var in fixed_effects) {       # Refit without this variable       reduced_formula <- update(formula(model), paste(\"~ . -\", var))       reduced_model <- lm(reduced_formula, data = model$model)        # ΔAIC: negative means removing improves model       # We negate so \"higher = worse\" convention holds       scores[var] <- -(AIC(reduced_model) - full_aic)     }      scores   } )  # Usage: Remove predictors with ΔAIC < -2 (improve AIC by > 2 when removed) pruned <- modelPrune(   y ~ x1 + x2 + x3,   data = my_data,   engine = aic_engine,   limit = -2 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"validation-and-error-handling","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.5 Validation and Error Handling","title":"Advanced Topics","text":"Custom engines validated automatically: Validation checks: - fit diagnostics must functions - diagnostics must return numeric vector - Correct length (one value per fixed effect) - Named vector correct names - missing values","code":"# Invalid engine: missing 'diagnostics' bad_engine <- list(   fit = function(formula, data, ...) lm(formula, data = data)   # Missing 'diagnostics' )  tryCatch({   modelPrune(mpg ~ ., data = mtcars, engine = bad_engine, limit = 5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: Custom engine missing required fields: diagnostics #> Required: 'fit' and 'diagnostics'"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"when-you-need-all-maximal-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.1 When You Need ALL Maximal Subsets","title":"Advanced Topics","text":"corrPrune() returns single subset. Sometimes want maximal subsets:","code":"# corrPrune: Single subset single <- corrPrune(mtcars, threshold = 0.7) cat(\"corrPrune returned:\", ncol(single), \"variables\\n\") #> corrPrune returned: 5 variables  # corrSelect: ALL maximal subsets (use higher threshold to ensure subsets exist) all_subsets <- corrSelect(mtcars, threshold = 0.9) show(all_subsets) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.900 #>   Subsets:     2 valid combinations #>   Data Rows:   32 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] mpg, disp, hp, drat, wt, qsec...  0.527  0.888    10 #>   [ 2] mpg, cyl, hp, drat, wt, qsec,...  0.531  0.868    10"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exploring-multiple-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.2 Exploring Multiple Subsets","title":"Advanced Topics","text":"multiple maximal subsets exist, can explore :","code":"if (length(all_subsets@subset_list) > 0) {   # Display first few subsets   cat(\"First few maximal subsets:\\n\")   for (i in seq_len(min(3, length(all_subsets@subset_list)))) {     cat(sprintf(\"\\nSubset %d (avg corr = %.3f):\\n\", i, all_subsets@avg_corr[i]))     cat(\" \", paste(all_subsets@subset_list[[i]], collapse = \", \"), \"\\n\")   }    # Analyze subset characteristics   subset_sizes <- lengths(all_subsets@subset_list)   cat(\"\\nSubset sizes:\\n\")   print(table(subset_sizes))    cat(\"\\nAverage correlations:\\n\")   print(summary(all_subsets@avg_corr)) } else {   cat(\"No subsets found at threshold 0.9\\n\") } #> First few maximal subsets: #>  #> Subset 1 (avg corr = 0.527): #>   mpg, disp, hp, drat, wt, qsec, vs, am, gear, carb  #>  #> Subset 2 (avg corr = 0.531): #>   mpg, cyl, hp, drat, wt, qsec, vs, am, gear, carb  #>  #> Subset sizes: #> subset_sizes #> 10  #>  2  #>  #> Average correlations: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.5269  0.5280  0.5290  0.5290  0.5301  0.5311"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"extracting-specific-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.3 Extracting Specific Subsets","title":"Advanced Topics","text":"","code":"if (length(all_subsets@subset_list) > 0) {   # Extract subset with lowest average correlation   best_idx <- which.min(all_subsets@avg_corr)   best_subset <- corrSubset(all_subsets, mtcars, which = best_idx)    cat(\"Best subset (lowest avg correlation):\\n\")   print(names(best_subset))    # Extract subset with most predictors   subset_sizes <- lengths(all_subsets@subset_list)   largest_idx <- which.max(subset_sizes)   largest_subset <- corrSubset(all_subsets, mtcars, which = largest_idx)    cat(\"\\nLargest subset:\\n\")   print(names(largest_subset)) } else {   cat(\"No subsets to extract at threshold 0.9\\n\") } #> Best subset (lowest avg correlation): #>  [1] \"mpg\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\" #>  #> Largest subset: #>  [1] \"mpg\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"advanced-domain-specific-subset-selection","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.4 Advanced: Domain-Specific Subset Selection","title":"Advanced Topics","text":"can define custom criteria choosing among multiple subsets:","code":"if (length(all_subsets@subset_list) > 0) {   # Custom criterion: Prefer subsets with specific variables   preferred_vars <- c(\"mpg\", \"hp\", \"wt\")    # Compute score: number of preferred variables in each subset   scores <- sapply(all_subsets@subset_list, function(vars) {     sum(preferred_vars %in% vars)   })    # Select subset with most preferred variables   best_idx <- which.max(scores)   cat(\"Subset with most preferred variables (score:\", scores[best_idx], \"):\\n\")   cat(paste(all_subsets@subset_list[[best_idx]], collapse = \", \"), \"\\n\")    # Extract as data frame   preferred_subset <- corrSubset(all_subsets, mtcars, which = best_idx)   print(head(preferred_subset)) } else {   cat(\"No subsets available for custom selection\\n\") } #> Subset with most preferred variables (score: 3 ): #> mpg, disp, hp, drat, wt, qsec, vs, am, gear, carb  #>                    mpg disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"precomputed-correlation-matrices","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.1 Precomputed Correlation Matrices","title":"Advanced Topics","text":"repeated pruning different thresholds, precompute correlation matrix: Use precomputed matrices : - Testing multiple thresholds - Cross-validation workflows - Sensitivity analysis","code":"# Slow: Recomputes correlation every time system.time({   result1 <- corrPrune(mtcars, threshold = 0.7)   result2 <- corrPrune(mtcars, threshold = 0.8)   result3 <- corrPrune(mtcars, threshold = 0.9) }) #>    user  system elapsed  #>    0.02    0.00    0.00  # Fast: Compute correlation once, reuse cor_matrix <- cor(mtcars) system.time({   result1 <- MatSelect(cor_matrix, threshold = 0.7)   result2 <- MatSelect(cor_matrix, threshold = 0.8)   result3 <- MatSelect(cor_matrix, threshold = 0.9) }) #>    user  system elapsed  #>       0       0       0"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"memory-considerations-for-large-data","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.2 Memory Considerations for Large Data","title":"Advanced Topics","text":"large datasets (n > 10,000, p > 500):","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"memory-efficient-correlation-computation","dir":"Articles","previous_headings":"4. Performance Optimization > 4.2 Memory Considerations for Large Data","what":"Memory-Efficient Correlation Computation","title":"Advanced Topics","text":"","code":"# Standard (memory-intensive for large n) cor_matrix <- cor(large_data)  # Memory-efficient alternative (for very large n) # Process in chunks if needed compute_cor_chunked <- function(data, chunk_size = 1000) {   n <- nrow(data)   n_chunks <- ceiling(n / chunk_size)    # Use online algorithm or chunked computation   # (Implementation depends on your data size) }"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"sparse-correlation-matrices","dir":"Articles","previous_headings":"4. Performance Optimization > 4.2 Memory Considerations for Large Data","what":"Sparse Correlation Matrices","title":"Advanced Topics","text":"correlations low, consider sparse storage:","code":"# Convert to sparse format (requires Matrix package) library(Matrix)  # Compute correlation cor_mat <- cor(data)  # Threshold and convert to sparse cor_sparse <- cor_mat cor_sparse[abs(cor_sparse) < 0.3] <- 0  # Set low correlations to 0 cor_sparse <- Matrix(cor_sparse, sparse = TRUE)  # Memory savings object.size(cor_mat) object.size(cor_sparse)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"parallel-processing-strategies","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.3 Parallel Processing Strategies","title":"Advanced Topics","text":"multiple independent pruning operations: Note: corrselect doesn’t parallelize internally (reproducibility), can parallelize across multiple analyses.","code":"library(parallel)  # Create cluster cl <- makeCluster(detectCores() - 1)  # Export functions to cluster clusterEvalQ(cl, library(corrselect))  # Parallel pruning with different thresholds thresholds <- seq(0.5, 0.9, by = 0.1) results <- parLapply(cl, thresholds, function(thresh) {   corrPrune(my_data, threshold = thresh) })  # Clean up stopCluster(cl)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"choosing-the-right-mode","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.4 Choosing the Right Mode","title":"Advanced Topics","text":"Decision tree mode selection:","code":"p ≤ 15:  Use \"exact\" (fast enough, guaranteed optimal) 15 < p ≤ 25:  Use \"exact\" if time permits, \"greedy\" if speed critical p > 25:  Use \"greedy\" or \"auto\" p > 100: Always use \"greedy\""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-no-valid-subsets-found","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: “No valid subsets found”","title":"Advanced Topics","text":"Cause: Threshold strict - variables exceed Solutions: 1. Increase threshold 2. Use force_in keep least one variable 3. Check data near-duplicates","code":"# Example: All correlations > 0.9 set.seed(123) x <- rnorm(100) high_cor_data <- data.frame(   x1 = x,   x2 = x + rnorm(100, sd = 0.01),   x3 = x + rnorm(100, sd = 0.01) )  tryCatch({   corrPrune(high_cor_data, threshold = 0.5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: No valid subsets found that satisfy the threshold constraint # Solution 1: Increase threshold result <- corrPrune(high_cor_data, threshold = 0.95) #> Error in corrPrune(high_cor_data, threshold = 0.95): No valid subsets found that satisfy the threshold constraint print(names(result)) #> Error: object 'result' not found  # Solution 2: Force keep one variable result <- corrPrune(high_cor_data, threshold = 0.5, force_in = \"x1\") #> Error in corrPrune(high_cor_data, threshold = 0.5, force_in = \"x1\"): No valid subsets found that satisfy the threshold constraint print(names(result)) #> Error: object 'result' not found"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-force_in-variables-conflict-with-threshold","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: force_in variables conflict with threshold","title":"Advanced Topics","text":"Cause: Variables force_in |correlation| > threshold Solution: Either increase threshold reduce force_in set","code":"# x1 and x2 are highly correlated tryCatch({   corrPrune(high_cor_data, threshold = 0.5, force_in = c(\"x1\", \"x2\")) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: Variables in 'force_in' violate the threshold constraint. Example: 'x1' and 'x2' have association 1.000 > 0.500"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-vif-computation-fails-in-modelprune","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: VIF computation fails in modelPrune()","title":"Advanced Topics","text":"Cause: Perfect multicollinearity (R² = 1) Solution: Use corrPrune() first remove perfect collinearity:","code":"# Create perfect multicollinearity perfect_data <- data.frame(   y = rnorm(100),   x1 = rnorm(100),   x2 = rnorm(100) ) perfect_data$x3 <- perfect_data$x1 + perfect_data$x2  # Perfect collinearity  tryCatch({   modelPrune(y ~ ., data = perfect_data, limit = 5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #>               y          x1          x2 #> 1   -0.71524219 -0.07355602 -0.60189285 #> 2   -0.75268897 -1.16865142 -0.99369859 #> 3   -0.93853870 -0.63474826  1.02678506 #> 4   -1.05251328 -0.02884155  0.75106130 #> 5   -0.43715953  0.67069597 -1.50916654 #> 6    0.33117917 -1.65054654 -0.09514745 #> 7   -2.01421050 -0.34975424 -0.89594782 #> 8    0.21198043  0.75640644 -2.07075107 #> 9    1.23667505 -0.53880916  0.15012013 #> 10   2.03757402  0.22729192 -0.07921171 #> 11   1.30117599  0.49222857 -0.09736927 #> 12   0.75677476  0.26783502  0.21615254 #> 13  -1.72673040  0.65325768  0.88246516 #> 14  -0.60150671 -0.12270866  0.20559750 #> 15  -0.35204646 -0.41367651 -0.61643584 #> 16   0.70352390 -2.64314895 -0.73479925 #> 17  -0.10567133 -0.09294102 -0.13180279 #> 18  -1.25864863  0.43028470  0.31001699 #> 19   1.68443571  0.53539884 -1.03968035 #> 20   0.91139129 -0.55527835 -0.18430887 #> 21   0.23743027  1.77950291  0.96726726 #> 22   1.21810861  0.28642442 -0.10828009 #> 23  -1.33877429  0.12631586 -0.69842067 #> 24   0.66082030  1.27226678 -0.27594517 #> 25  -0.52291238 -0.71846622  1.11464855 #> 26   0.68374552 -0.45033862  0.55004396 #> 27  -0.06082195  2.39745248  1.23667580 #> 28   0.63296071  0.01112919  0.13909786 #> 29   1.33551762  1.63356842  0.41027510 #> 30   0.00729009 -1.43850664 -0.55845691 #> 31   1.01755864 -0.19051680  0.60537067 #> 32  -1.18843404  0.37842390 -0.50633354 #> 33  -0.72160444  0.30003855 -1.42056550 #> 34   1.51921771 -1.00563626  0.12799297 #> 35   0.37738797  0.01925927  1.94585122 #> 36  -2.05222282 -1.07742065  0.80091434 #> 37  -1.36403745  0.71270333  1.16525339 #> 38  -0.20078102  1.08477509  0.35885572 #> 39   0.86577940 -2.22498770 -0.60855718 #> 40  -0.10188326  1.23569346 -0.20224086 #> 41   0.62418747 -1.24104450 -0.27324811 #> 42   0.95900538  0.45476927 -0.46869978 #> 43   1.67105483  0.65990264  0.70416728 #> 44   0.05601673 -0.19988983 -1.19736350 #> 45  -0.05198191 -0.64511396  0.86636613 #> 46  -1.75323736  0.16532102  0.86415249 #> 47   0.09932759  0.43881870 -1.19862236 #> 48  -0.57185006  0.88330282  0.63949200 #> 49  -0.97400958 -2.05233698  2.43022665 #> 50  -0.17990623 -1.63637927 -0.55721548 #> 51   1.01494317  1.43040234  0.84490424 #> 52  -1.99274849  1.04662885 -0.78220185 #> 53  -0.42727929  0.43528895  1.11071142 #> 54   0.11663728  0.71517841  0.24982472 #> 55  -0.89320757  0.91717492  1.65191539 #> 56   0.33390294 -2.66092280 -1.45897073 #> 57   0.41142992  1.11027710 -0.05129789 #> 58  -0.03303616 -0.48498760 -0.52692518 #> 59  -2.46589819  0.23061683 -0.19726487 #> 60   2.57145815 -0.29515780 -0.62957874 #> 61  -0.20529926  0.87196495 -0.83384358 #> 62   0.65119328 -0.34847245  0.57872237 #> 63   0.27376649  0.51850377 -1.08758071 #> 64   1.02467323 -0.39068498  1.48403093 #> 65   0.81765945 -1.09278721 -1.18620659 #> 66  -0.20979317  1.21001051  0.10107915 #> 67   0.37816777  0.74090001  0.53298929 #> 68  -0.94540883  1.72426224  0.58673534 #> 69   0.85692301  0.06515393 -0.30174666 #> 70  -0.46103834  1.12500275  0.07950200 #> 71   2.41677335  1.97541905  0.96126415 #> 72  -1.65104890 -0.28148212 -1.45646592 #> 73  -0.46398724 -1.32295111 -0.78173971 #> 74   0.82537986 -0.23935157  0.32040231 #> 75   0.51013255 -0.21404124 -0.44478198 #> 76  -0.58948104  0.15168050  1.37000399 #> 77  -0.99678074  1.71230498  0.67325386 #> 78   0.14447570 -0.32614389  0.07216675 #> 79  -0.01430741  0.37300466 -1.50775732 #> 80  -1.79028124 -0.22768406  0.02610023 #> 81   0.03455107  0.02045071 -0.31641587 #> 82   0.19023032  0.31405766 -0.10234651 #> 83   0.17472640  1.32821470 -1.18155923 #> 84  -1.05501704  0.12131838  0.49865804 #> 85   0.47613328  0.71284232 -1.03895644 #> 86   1.37857014  0.77886003 -0.22622198 #> 87   0.45623640  0.91477327  0.38142583 #> 88  -1.13558847 -0.57439455 -0.78351579 #> 89  -0.43564547  1.62688121  0.58299141 #> 90   0.34610362 -0.38095674 -1.31651040 #> 91  -0.64704563 -0.10578417 -2.80977468 #> 92  -2.15764634  1.40405027  0.46496799 #> 93   0.88425082  1.29408391  0.84053983 #> 94  -0.82947761 -1.08999187 -0.28584542 #> 95  -0.57356027 -0.87307100  0.50412625 #> 96   1.50390061 -1.35807906 -1.15591653 #> 97  -0.77414493  0.18184719 -0.12714861 #> 98   0.84573154  0.16484087 -1.94151838 #> 99  -1.26068288  0.36411469  1.18118089 #> 100 -0.35454240  0.55215771  1.85991086 # Two-step approach step1 <- corrPrune(perfect_data[, -1], threshold = 0.99) step2_data <- data.frame(y = perfect_data$y, step1) result <- modelPrune(y ~ ., data = step2_data, limit = 5) #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable print(attr(result, \"selected_vars\")) #> [1] \"x1\" \"x2\""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-corrprune-correlation-threshold","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"For corrPrune() (Correlation Threshold)","title":"Advanced Topics","text":"Conservative (strict): - threshold = 0.5: low redundancy, may lose information - Use : Interpretability critical, small sample size Moderate (recommended): - threshold = 0.7: Balances redundancy information retention - Use : Standard regression, general analysis Lenient: - threshold = 0.9: removes near-duplicates - Use : Large sample size, prediction focus","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-modelprune-vif-limit","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"For modelPrune() (VIF Limit)","title":"Advanced Topics","text":"Strict: - limit = 2: low multicollinearity, may -prune - Use : Small sample size, interpretability critical Moderate (recommended): - limit = 5: Standard threshold literature - Use : General regression analysis Lenient: - limit = 10: Tolerates multicollinearity - Use : Large sample size, prediction focus","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"empirical-approach-visualize-first","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"Empirical Approach: Visualize First","title":"Advanced Topics","text":"Strategy: Choose threshold curve begins plateau.","code":"data(mtcars)  # Visualize correlation distribution cor_mat <- cor(mtcars) cor_vec <- cor_mat[upper.tri(cor_mat)]  par(mfrow = c(1, 2))  # Histogram of correlations hist(abs(cor_vec), breaks = 30,      main = \"Distribution of |Correlations|\",      xlab = \"|Correlation|\",      col = \"lightblue\") abline(v = c(0.5, 0.7, 0.9), col = c(\"red\", \"blue\", \"green\"), lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"0.5 (strict)\", \"0.7 (moderate)\", \"0.9 (lenient)\"),        col = c(\"red\", \"blue\", \"green\"), lwd = 2, lty = 2)  # Subset size vs threshold thresholds <- seq(0.3, 0.95, by = 0.05) sizes <- sapply(thresholds, function(t) {   tryCatch({     ncol(corrPrune(mtcars, threshold = t))   }, error = function(e) NA) })  plot(thresholds, sizes, type = \"b\",      xlab = \"Threshold\",      ylab = \"Number of Variables Retained\",      main = \"Threshold Sensitivity\",      col = \"blue\", lwd = 2) abline(h = ncol(mtcars), lty = 2, col = \"gray\") text(0.3, ncol(mtcars), \"Original\", pos = 3)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"single-predictor-after-pruning","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"Single Predictor After Pruning","title":"Advanced Topics","text":"","code":"# Very strict threshold may leave only 1 variable strict_result <- corrPrune(mtcars, threshold = 0.3) cat(\"Variables remaining:\", ncol(strict_result), \"\\n\") #> Variables remaining: 2  # Check if result is usable if (ncol(strict_result) < 2) {   cat(\"Warning: Only 1 variable remaining. Consider:\\n\")   cat(\"  1. Increasing threshold\\n\")   cat(\"  2. Using force_in to keep important variables\\n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"all-variables-removed","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"All Variables Removed","title":"Advanced Topics","text":"","code":"# Impossible threshold tryCatch({   corrPrune(mtcars, threshold = 0.0) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: `threshold` must be in the range (0, 1]."},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"mixed-type-data","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"Mixed-Type Data","title":"Advanced Topics","text":"","code":"# Create mixed data mixed_data <- mtcars mixed_data$cyl <- factor(mixed_data$cyl) mixed_data$am <- factor(mixed_data$am)  # Use assocSelect for mixed types result <- assocSelect(mixed_data, threshold = 0.6) show(result) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_factor = eta, numeric_numeric = pearson, factor_numeric #>                = eta, factor_factor = cramersv #>   Threshold:   0.600 #>   Subsets:     20 valid combinations #>   Data Rows:   32 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] wt, vs, gear, carb                0.436  0.583     4 #>   [ 2] vs, am, carb                      0.265  0.570     3 #>   [ 3] wt, qsec, gear                    0.324  0.583     3 #>   [ 4] disp, carb, am                    0.348  0.591     3 #>   [ 5] drat, vs, carb                    0.367  0.570     3 #>   ... (15 more combinations)"},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-exploratory-analysis","dir":"Articles","previous_headings":"6. Best Practices > 6.1 Workflow Recommendations","what":"For Exploratory Analysis","title":"Advanced Topics","text":"","code":"# 1. Visualize correlations corrplot::corrplot(cor(data), method = \"circle\")  # 2. Try multiple thresholds results <- lapply(c(0.5, 0.7, 0.9), function(t) {   corrPrune(data, threshold = t) })  # 3. Compare subset sizes sapply(results, ncol)  # 4. Choose based on your needs final_data <- results[[2]]  # threshold = 0.7"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-publication-quality-analysis","dir":"Articles","previous_headings":"6. Best Practices > 6.1 Workflow Recommendations","what":"For Publication-Quality Analysis","title":"Advanced Topics","text":"","code":"# 1. Use exact mode for reproducibility and optimality data_pruned <- corrPrune(data, threshold = 0.7, mode = \"exact\")  # 2. Document in methods section cat(sprintf(   \"Variables were pruned using corrselect::corrPrune() with threshold = 0.7, \",   \"exact mode, retaining %d of %d original predictors.\",   ncol(data_pruned), ncol(data) ))  # 3. Report which variables were removed removed <- attr(data_pruned, \"removed_vars\") cat(\"Removed variables:\", paste(removed, collapse = \", \"))"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"combining-with-other-methods","dir":"Articles","previous_headings":"6. Best Practices","what":"6.2 Combining with Other Methods","title":"Advanced Topics","text":"","code":"# Comprehensive variable selection pipeline pipeline <- function(data, response) {   # Step 1: Remove correlations   step1 <- corrPrune(data, threshold = 0.7, mode = \"auto\")    # Step 2: VIF cleanup   step2_data <- data.frame(response = response, step1)   step2 <- modelPrune(response ~ ., data = step2_data, limit = 5)    # Step 3: Feature importance (optional)   if (requireNamespace(\"Boruta\", quietly = TRUE)) {     boruta_result <- Boruta::Boruta(response ~ ., data = step2)     important <- Boruta::getSelectedAttributes(boruta_result)     final_data <- step2[, c(\"response\", important)]   } else {     final_data <- step2   }    final_data }"},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"algorithms","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Algorithms","title":"Advanced Topics","text":"Use exact mode p ≤ 20 (optimal, reproducible) Use greedy mode p > 20 (fast, near-optimal) Use auto mode let corrselect decide","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"custom-engines","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Custom Engines","title":"Advanced Topics","text":"Integrate modeling package (INLA, mgcv, brms) Define custom pruning criteria (AIC, BIC, p-values) Two required functions: fit diagnostics","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"optimization","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Optimization","title":"Advanced Topics","text":"Precompute correlation matrices multiple thresholds Use greedy mode large p Parallelize across analyses, within","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"troubleshooting-1","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Troubleshooting","title":"Advanced Topics","text":"Visualize correlation distribution choosing threshold Use force_in protect important variables Two-step pruning (corrPrune → modelPrune) robustness","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"references","dir":"Articles","previous_headings":"","what":"8. References","title":"Advanced Topics","text":"Algorithms: - Eppstein, D., Löffler, M., & Strash, D. (2010). Listing maximal cliques sparse graphs near-optimal time. Symposium Algorithms Computation. - Bron, C., & Kerbosch, J. (1973). Algorithm 457: Finding cliques undirected graph. Communications ACM, 16(9), 575-577. Multicollinearity: - O’Brien, R. M. (2007). caution regarding rules thumb variance inflation factors. Quality & Quantity, 41(5), 673-690. - Belsley, D. ., Kuh, E., & Welsch, R. E. (1980). Regression Diagnostics. Wiley. Software: - INLA: Rue, H., Martino, S., & Chopin, N. (2009). Approximate Bayesian inference latent Gaussian models. Journal Royal Statistical Society: Series B, 71(2), 319-392. - mgcv: Wood, S. N. (2017). Generalized Additive Models: Introduction R (2nd ed.). Chapman Hall/CRC.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"see-also","dir":"Articles","previous_headings":"8. References","what":"See Also","title":"Advanced Topics","text":"vignette(\"quickstart\") - 5-minute introduction vignette(\"workflows\") - Real-world examples vignette(\"comparison\") - vs caret, Boruta, glmnet vignette(\"corrselect_vignette\") - Original exact methods vignette ?corrPrune - Association-based pruning ?modelPrune - Model-based pruning ?corrSelect - Exact subset enumeration","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Comparison with Alternatives","text":"vignette compares corrselect popular alternatives variable selection multicollinearity handling: Manual correlation filtering caret::findCorrelation() Boruta (feature selection) glmnet (regularization) Goal: Help choose right tool problem. Estimated time: 10 minutes","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"when-to-use-corrselect","dir":"Articles","previous_headings":"","what":"When to Use corrselect","title":"Comparison with Alternatives","text":"corrselect designed situations want : Remove redundant predictors based correlation structure Reduce multicollinearity regression models Maintain interpretability (keep predictors, transform ) Ensure reproducibility (deterministic results) Control variables keep (via force_in)","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"the-manual-approach","dir":"Articles","previous_headings":"Comparison 1: Manual Correlation Filtering","what":"The Manual Approach","title":"Comparison with Alternatives","text":"Many analysts use ad-hoc workflow: Problems: - Manual decision-making (variable drop?) - Time-consuming many variables - reproducible (different analysts make different choices) - guarantee optimality - Hard document decision process","code":"library(corrselect) data(mtcars)  # Manual approach cor_matrix <- cor(mtcars) print(cor_matrix[1:5, 1:5]) #>             mpg        cyl       disp         hp       drat #> mpg   1.0000000 -0.8521620 -0.8475514 -0.7761684  0.6811719 #> cyl  -0.8521620  1.0000000  0.9020329  0.8324475 -0.6999381 #> disp -0.8475514  0.9020329  1.0000000  0.7909486 -0.7102139 #> hp   -0.7761684  0.8324475  0.7909486  1.0000000 -0.4487591 #> drat  0.6811719 -0.6999381 -0.7102139 -0.4487591  1.0000000  # Identify high correlations (> 0.7) high_cor <- which(abs(cor_matrix) > 0.7 & abs(cor_matrix) < 1, arr.ind = TRUE) head(high_cor) #>      row col #> cyl    2   1 #> disp   3   1 #> hp     4   1 #> wt     6   1 #> mpg    1   2 #> disp   3   2  # Now what? Manually decide which to remove... # This is tedious, subjective, and non-reproducible!"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"the-corrselect-approach","dir":"Articles","previous_headings":"Comparison 1: Manual Correlation Filtering","what":"The corrselect Approach","title":"Comparison with Alternatives","text":"Advantages: - Fully automated - manual decisions - Reproducible - result every time - Optimal - maximizes retained variables (exact mode) - Documented - clear record removals - Fast - greedy mode large datasets","code":"# Automated, reproducible, optimal pruned <- corrPrune(mtcars, threshold = 0.7)  # Clear documentation of what was removed attr(pruned, \"removed_vars\") #> NULL attr(pruned, \"selected_vars\") #> [1] \"mpg\"  \"drat\" \"qsec\" \"gear\" \"carb\""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-2-caretfindcorrelation","dir":"Articles","previous_headings":"","what":"Comparison 2: caret::findCorrelation()","title":"Comparison with Alternatives","text":"caret provides findCorrelation() removing correlated predictors. Let’s compare.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"side-by-side-comparison","dir":"Articles","previous_headings":"Comparison 2: caret::findCorrelation()","what":"Side-by-Side Comparison","title":"Comparison with Alternatives","text":"","code":"# Prepare data (numeric only for caret) mtcars_num <- mtcars  # caret approach if (requireNamespace(\"caret\", quietly = TRUE)) {   cor_matrix <- cor(mtcars_num)   to_remove_caret <- caret::findCorrelation(cor_matrix, cutoff = 0.7)   mtcars_caret <- mtcars_num[, -to_remove_caret]    cat(\"caret kept:\", ncol(mtcars_caret), \"variables\\n\")   cat(\"caret removed:\", colnames(mtcars_num)[to_remove_caret], \"\\n\\n\") } #> caret kept: 3 variables #> caret removed: cyl disp mpg wt hp vs drat am  # corrselect approach mtcars_corrselect <- corrPrune(mtcars_num, threshold = 0.7)  cat(\"corrselect kept:\", ncol(mtcars_corrselect), \"variables\\n\") #> corrselect kept: 5 variables cat(\"corrselect removed:\", attr(mtcars_corrselect, \"removed_vars\"), \"\\n\") #> corrselect removed:"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"reproducibility-test","dir":"Articles","previous_headings":"Comparison 2: caret::findCorrelation()","what":"Reproducibility Test","title":"Comparison with Alternatives","text":"Let’s verify caret’s non-determinism: Takeaway: corrselect guarantees reproducibility, caret .","code":"if (requireNamespace(\"caret\", quietly = TRUE)) {   # Run caret multiple times   set.seed(123)   run1 <- caret::findCorrelation(cor(mtcars), cutoff = 0.7)    set.seed(456)   run2 <- caret::findCorrelation(cor(mtcars), cutoff = 0.7)    cat(\"caret run 1 removed:\", length(run1), \"variables\\n\")   cat(\"caret run 2 removed:\", length(run2), \"variables\\n\")   cat(\"Identical results?\", identical(run1, run2), \"\\n\\n\") } #> caret run 1 removed: 8 variables #> caret run 2 removed: 8 variables #> Identical results? TRUE  # Run corrselect multiple times run1 <- corrPrune(mtcars, threshold = 0.7) run2 <- corrPrune(mtcars, threshold = 0.7)  cat(\"corrselect run 1 kept:\", ncol(run1), \"variables\\n\") #> corrselect run 1 kept: 5 variables cat(\"corrselect run 2 kept:\", ncol(run2), \"variables\\n\") #> corrselect run 2 kept: 5 variables cat(\"Identical results?\", identical(names(run1), names(run2)), \"\\n\") #> Identical results? TRUE"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"when-to-use-each","dir":"Articles","previous_headings":"Comparison 2: caret::findCorrelation()","what":"When to Use Each","title":"Comparison with Alternatives","text":"Use caret::findCorrelation() : - need quick--dirty solution - Exact reproducibility doesn’t matter - ’re already using caret tasks Use corrselect::corrPrune() : - need reproducible research - want largest possible subset - need protect certain variables (force_in) - ’re working mixed-type data","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-3-boruta-feature-importance","dir":"Articles","previous_headings":"","what":"Comparison 3: Boruta (Feature Importance)","title":"Comparison with Alternatives","text":"Boruta feature selection algorithm based random forests. identifies important variables, redundant ones.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"different-goals","dir":"Articles","previous_headings":"Comparison 3: Boruta (Feature Importance)","what":"Different Goals","title":"Comparison with Alternatives","text":"","code":"library(Boruta)  # Boruta: Which variables are important? set.seed(123) boruta_result <- Boruta(mpg ~ ., data = mtcars, maxRuns = 50) print(boruta_result)  # Get important variables important_vars <- names(boruta_result$finalDecision[boruta_result$finalDecision == \"Confirmed\"]) cat(\"\\nBoruta selected:\", important_vars, \"\\n\") # corrselect: Which variables are redundant? corrselect_result <- corrPrune(mtcars[, -1], threshold = 0.7)  # Exclude mpg cat(\"corrselect kept:\", ncol(corrselect_result), \"variables\\n\") #> corrselect kept: 5 variables cat(\"Variables:\", names(corrselect_result), \"\\n\") #> Variables: cyl drat qsec gear carb"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"complementary-not-competitive","dir":"Articles","previous_headings":"Comparison 3: Boruta (Feature Importance)","what":"Complementary, Not Competitive","title":"Comparison with Alternatives","text":"Boruta corrselect solve different problems:","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"workflow-use-both","dir":"Articles","previous_headings":"Comparison 3: Boruta (Feature Importance)","what":"Workflow: Use Both!","title":"Comparison with Alternatives","text":"best approach often combines : works: 1. corrselect reduces dimensionality (fast, deterministic) 2. Boruta identifies importance among non-redundant variables 3. Final model parsimonious interpretable","code":"# Step 1: Remove redundant predictors (corrselect) data_pruned <- corrPrune(raw_data, threshold = 0.7)  # Step 2: Identify important predictors (Boruta) boruta_result <- Boruta(response ~ ., data = data_pruned)  # Step 3: Final model with non-redundant, important variables final_vars <- names(boruta_result$finalDecision[boruta_result$finalDecision == \"Confirmed\"]) final_model <- lm(response ~ ., data = data_pruned[, c(\"response\", final_vars)])"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-4-glmnet-regularization","dir":"Articles","previous_headings":"","what":"Comparison 4: glmnet (Regularization)","title":"Comparison with Alternatives","text":"glmnet uses L1/L2 penalties shrink coefficients, effectively performing variable selection.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"different-approach","dir":"Articles","previous_headings":"Comparison 4: glmnet (Regularization)","what":"Different Approach","title":"Comparison with Alternatives","text":"","code":"library(glmnet)  # glmnet: Shrink coefficients via regularization X <- as.matrix(mtcars[, -1]) y <- mtcars$mpg  # Fit LASSO (L1 penalty) set.seed(123) cv_lasso <- cv.glmnet(X, y, alpha = 1)  # Extract non-zero coefficients coef_lasso <- coef(cv_lasso, s = \"lambda.1se\") selected_lasso <- rownames(coef_lasso)[coef_lasso[, 1] != 0][-1]  # Remove intercept  cat(\"glmnet selected:\", selected_lasso, \"\\n\") cat(\"Number of variables:\", length(selected_lasso), \"\\n\") # corrselect: Remove correlated predictors corrselect_result <- corrPrune(mtcars[, -1], threshold = 0.7) cat(\"\\ncorrselect kept:\", ncol(corrselect_result), \"variables\\n\")  # Compare: Can we fit a model with similar performance? model_glmnet <- lm(mpg ~ ., data = mtcars[, c(\"mpg\", selected_lasso)]) model_corrselect <- lm(mpg ~ ., data = cbind(mpg = mtcars$mpg, corrselect_result))  cat(\"\\nglmnet R²:\", round(summary(model_glmnet)$r.squared, 3), \"\\n\") cat(\"corrselect R²:\", round(summary(model_corrselect)$r.squared, 3), \"\\n\")"},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"use-glmnet-when","dir":"Articles","previous_headings":"Comparison 4: glmnet (Regularization) > When to Use Each","what":"Use glmnet when:","title":"Comparison with Alternatives","text":"Primary goal: Prediction accuracy many predictors (p >> n) ’re okay biased coefficients want automatic hyperparameter tuning (via CV)","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"use-corrselect-when","dir":"Articles","previous_headings":"Comparison 4: glmnet (Regularization) > When to Use Each","what":"Use corrselect when:","title":"Comparison with Alternatives","text":"Primary goal: Interpretability want unbiased coefficient estimates need explain variables matter () want remove multicollinearity explicitly ’re exploratory analysis (response variable yet)","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"can-you-use-both","dir":"Articles","previous_headings":"Comparison 4: glmnet (Regularization)","what":"Can You Use Both?","title":"Comparison with Alternatives","text":"Yes! Combine best worlds:","code":"# Workflow 1: Pruning before regularization data_pruned <- corrPrune(predictors, threshold = 0.7) glmnet_fit <- cv.glmnet(as.matrix(data_pruned), response, alpha = 1)  # Workflow 2: Regularization for variable screening, corrselect for final model lasso_vars <- # ... extract non-zero coefficients from glmnet final_pruned <- corrPrune(data[, lasso_vars], threshold = 0.7) final_model <- lm(response ~ ., data = final_pruned)"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"benchmark-comparison","dir":"Articles","previous_headings":"","what":"Benchmark Comparison","title":"Comparison with Alternatives","text":"Let’s compare performance realistic dataset:","code":"data(bioclim_example)  # Extract predictors (exclude response) predictors <- bioclim_example[, -1] response <- bioclim_example[, 1]  cat(\"Original predictors:\", ncol(predictors), \"\\n\\n\") #> Original predictors: 19"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"method-1-manual-simulated","dir":"Articles","previous_headings":"Benchmark Comparison","what":"Method 1: Manual (simulated)","title":"Comparison with Alternatives","text":"","code":"# Identify pairs with |r| > 0.7 cor_mat <- cor(predictors) high_cor_pairs <- sum(abs(cor_mat) > 0.7 & abs(cor_mat) < 1) / 2 cat(\"Manual approach:\\n\") #> Manual approach: cat(\"  High-correlation pairs to resolve:\", high_cor_pairs, \"\\n\") #>   High-correlation pairs to resolve: 13 cat(\"  Time required: ~30 minutes of manual work\\n\") #>   Time required: ~30 minutes of manual work cat(\"  Reproducible: NO\\n\\n\") #>   Reproducible: NO"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"method-2-caretfindcorrelation","dir":"Articles","previous_headings":"Benchmark Comparison","what":"Method 2: caret::findCorrelation()","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"caret\", quietly = TRUE)) {   time_caret <- system.time({     to_remove <- caret::findCorrelation(cor(predictors), cutoff = 0.7)     result_caret <- predictors[, -to_remove]   })    cat(\"caret::findCorrelation():\\n\")   cat(\"  Variables kept:\", ncol(result_caret), \"\\n\")   cat(\"  Time:\", round(time_caret[\"elapsed\"], 3), \"seconds\\n\")   cat(\"  Reproducible: NO\\n\")   cat(\"  Max correlation:\", round(max(abs(cor(result_caret)[upper.tri(cor(result_caret))])), 3), \"\\n\\n\") } #> caret::findCorrelation(): #>   Variables kept: 10  #>   Time: 0 seconds #>   Reproducible: NO #>   Max correlation: 0.689"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"method-3-corrselect-exact-mode","dir":"Articles","previous_headings":"Benchmark Comparison","what":"Method 3: corrselect (exact mode)","title":"Comparison with Alternatives","text":"","code":"time_exact <- system.time({   result_exact <- corrPrune(predictors, threshold = 0.7, mode = \"exact\") })  cat(\"corrselect (exact mode):\\n\") #> corrselect (exact mode): cat(\"  Variables kept:\", ncol(result_exact), \"\\n\") #>   Variables kept: 12 cat(\"  Time:\", round(time_exact[\"elapsed\"], 3), \"seconds\\n\") #>   Time: 0 seconds cat(\"  Reproducible: YES\\n\") #>   Reproducible: YES cat(\"  Max correlation:\", round(max(abs(cor(result_exact)[upper.tri(cor(result_exact))])), 3), \"\\n\\n\") #>   Max correlation: 0.689"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"method-4-corrselect-greedy-mode","dir":"Articles","previous_headings":"Benchmark Comparison","what":"Method 4: corrselect (greedy mode)","title":"Comparison with Alternatives","text":"","code":"time_greedy <- system.time({   result_greedy <- corrPrune(predictors, threshold = 0.7, mode = \"greedy\") })  cat(\"corrselect (greedy mode):\\n\") #> corrselect (greedy mode): cat(\"  Variables kept:\", ncol(result_greedy), \"\\n\") #>   Variables kept: 12 cat(\"  Time:\", round(time_greedy[\"elapsed\"], 3), \"seconds\\n\") #>   Time: 0 seconds cat(\"  Reproducible: YES\\n\") #>   Reproducible: YES cat(\"  Max correlation:\", round(max(abs(cor(result_greedy)[upper.tri(cor(result_greedy))])), 3), \"\\n\\n\") #>   Max correlation: 0.689"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"benchmark-summary-table","dir":"Articles","previous_headings":"Benchmark Comparison","what":"Benchmark Summary Table","title":"Comparison with Alternatives","text":"Key findings: - corrselect (exact) keeps variables satisfying threshold - corrselect (greedy) fastest nearly optimal - corrselect modes reproducible - caret fast non-reproducible removes necessary - Manual approach extremely time-consuming","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"flowchart-which-tool-should-i-use","dir":"Articles","previous_headings":"Decision Guide","what":"Flowchart: Which Tool Should I Use?","title":"Comparison with Alternatives","text":"","code":"START   │   ├─ Do you have correlated predictors?   │   ├─ NO → Consider Boruta, glmnet for feature selection   │   └─ YES → Continue   │   ├─ Do you need reproducible results?   │   ├─ NO → caret::findCorrelation() is fine   │   └─ YES → Continue   │   ├─ Do you want interpretable coefficients (not shrunk)?   │   ├─ NO → Use glmnet   │   └─ YES → Continue   │   ├─ Do you have a response variable?   │   ├─ NO → Use corrselect::corrPrune()   │   └─ YES → Continue   │   ├─ Is multicollinearity your main concern?   │   ├─ YES → Use corrselect::modelPrune()   │   └─ NO → Use Boruta or glmnet   │   END"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"combining-multiple-approaches","dir":"Articles","previous_headings":"","what":"Combining Multiple Approaches","title":"Comparison with Alternatives","text":"Often, best solution uses multiple tools sequence:","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"workflow-1-comprehensive-variable-selection","dir":"Articles","previous_headings":"Combining Multiple Approaches","what":"Workflow 1: Comprehensive Variable Selection","title":"Comparison with Alternatives","text":"","code":"# Step 1: Remove correlations (corrselect) data_decorrelated <- corrPrune(raw_data, threshold = 0.7,                                force_in = c(\"age\", \"treatment\"))  # Step 2: Identify important variables (Boruta) boruta_result <- Boruta(response ~ ., data = data_decorrelated) important_vars <- getSelectedAttributes(boruta_result)  # Step 3: Final VIF check (corrselect) final_data <- modelPrune(response ~ .,                          data = data_decorrelated[, c(\"response\", important_vars)],                          limit = 5)  # Step 4: Fit final model final_model <- lm(response ~ ., data = final_data)"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"workflow-2-prediction-interpretation","dir":"Articles","previous_headings":"Combining Multiple Approaches","what":"Workflow 2: Prediction + Interpretation","title":"Comparison with Alternatives","text":"","code":"# Step 1: Use glmnet for variable screening cv_lasso <- cv.glmnet(X, y, alpha = 1) selected <- # ... extract non-zero coefficients  # Step 2: Remove multicollinearity among selected (corrselect) pruned <- corrPrune(data[, selected], threshold = 0.7)  # Step 3: Fit interpretable model interpretable_model <- lm(y ~ ., data = pruned)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"when-to-choose-corrselect","dir":"Articles","previous_headings":"Summary","what":"When to Choose corrselect","title":"Comparison with Alternatives","text":"Choose corrselect need : Remove redundant predictors reproducible way Reduce multicollinearity stable regression coefficients Maximize retained variables subject correlation threshold Protect important variables removal (force_in) Work mixed-type data (numeric + categorical) Ensure reproducibility research Handle large datasets efficiently (greedy mode)","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"when-to-choose-alternatives","dir":"Articles","previous_headings":"Summary","what":"When to Choose Alternatives","title":"Comparison with Alternatives","text":"caret: Quick--dirty, already using caret, reproducibility critical Boruta: Feature importance (variables predict?), just redundancy glmnet: Prediction focus, okay biased coefficients, automatic tuning Manual: Simple cases, educational purposes, full control","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"best-practice","dir":"Articles","previous_headings":"Summary","what":"Best Practice","title":"Comparison with Alternatives","text":"Don’t choose one tool - use right combination! effective workflows combine: 1. corrselect multicollinearity removal 2. Boruta glmnet importance/screening 3. Standard regression final interpretable model","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Comparison with Alternatives","text":"Packages compared: - corrselect (package) - caret: Kuhn, M. (2008). Building predictive models R using caret package. Journal Statistical Software, 28(5), 1-26. - Boruta: Kursa, M. B., & Rudnicki, W. R. (2010). Feature selection Boruta package. Journal Statistical Software, 36(11), 1-13. - glmnet: Friedman, J., Hastie, T., & Tibshirani, R. (2010). Regularization paths generalized linear models via coordinate descent. Journal Statistical Software, 33(1), 1-22. Multicollinearity: - O’Brien, R. M. (2007). caution regarding rules thumb variance inflation factors. Quality & Quantity, 41(5), 673-690. - Dormann, C. F., et al. (2013). Collinearity: review methods deal . Ecography, 36(1), 27-46.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"see-also","dir":"Articles","previous_headings":"References","what":"See Also","title":"Comparison with Alternatives","text":"vignette(\"quickstart\") - 5-minute introduction corrselect vignette(\"workflows\") - Complete real-world examples vignette(\"corrselect_vignette\") - Advanced exact methods ?corrPrune - Association-based pruning ?modelPrune - Model-based pruning","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Correlation Subset Selection with corrselect","text":"corrselect identifies maximal subsets variables whose pairwise correlations stay chosen threshold. process reduces multicollinearity redundancy modeling, preserving interpretability. Unlike greedy stepwise approaches, corrselect exhaustively searches valid subsets using fast, exact algorithms. fully model-agnostic, making suitable preprocessing step regression, clustering, feature selection, analyses. Given threshold t∈(0,1)t \\(0,1), functions corrSelect() (data-frame interface) MatSelect() (matrix interface) enumerate maximal subsets SS variables satisfying: ∀,j∈S,≠j:|rij|<t \\forall , j \\S,\\ \\neq j: \\ |r_{ij}| < t rijr_{ij} denotes chosen correlation measure variables ii jj. Enumeration relies two exact graph-theoretic algorithms: Eppstein–Löffler–Strash (ELS), degeneracy-ordered backtracking algorithm optimized sparse graphs. Bron–Kerbosch (BK), classical recursive clique-finding method, optional pivoting reduce search space. Results returned CorrCombo S4 object containing subset’s variable names summary statistics (avg_corr, min_corr, max_corr). can extract subsets original data via corrSubset(). procedure depend downstream model, cleanly separates “feature curation” “model fitting” supports multiple correlation measures (pearson, spearman, kendall, bicor, distance, maximal).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"simulated-numeric-example","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Simulated numeric example","title":"Correlation Subset Selection with corrselect","text":"","code":"set.seed(42) n <- 100 df <- data.frame(   A = rnorm(n),   B = rnorm(n),   C = rnorm(n),   D = rnorm(n),   E = rnorm(n) ) df$F <- df$A * 0.9 + rnorm(n, sd = 0.1)  # strongly correlated with A"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"basic-selection","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Basic selection","title":"Correlation Subset Selection with corrselect","text":"","code":"res <- corrSelect(df, threshold = 0.7) res #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 as.data.frame(res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E corrSubset(res, df, which = 1)[1:10,] #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"forcing-variables-into-all-subsets","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Forcing variables into all subsets","title":"Correlation Subset Selection with corrselect","text":"","code":"res2 <- corrSelect(df, threshold = 0.7, force_in = \"A\") res2 #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   100 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"using-a-different-correlation-method","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Using a different correlation method","title":"Correlation Subset Selection with corrselect","text":"","code":"res3 <- corrSelect(df, threshold = 0.6, cor_method = \"spearman\") res3 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.600 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"matrix-interface-matselect","dir":"Articles","previous_headings":"","what":"Matrix Interface (MatSelect)","title":"Correlation Subset Selection with corrselect","text":"already computed correlation matrix want apply method precomputed correlations: Selecting subsets: Force variable 1 every subset:","code":"mat <- cor(df) res4 <- MatSelect(mat, threshold = 0.7) res4 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.500 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5, force_in = 1) #> CorrCombo object #> ----------------- #>   Method:      els #>   Threshold:   0.500 #>   Subsets:     1 valid combinations #>   Data Rows:   6 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"mixed-data-types-assocselect","dir":"Articles","previous_headings":"","what":"Mixed Data Types (assocSelect)","title":"Correlation Subset Selection with corrselect","text":"","code":"df_ass <- data.frame(   height = rnorm(15, 170, 10),   weight = rnorm(15, 70, 12),   group  = factor(rep(LETTERS[1:3], each = 5)),   score  = ordered(sample(c(\"low\",\"med\",\"high\"), 15, TRUE)) )  # keep every subset whose internal associations ≤ 0.6 res5 <- assocSelect(df_ass, threshold = 0.6) res5 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.600 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.267  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"changing-correlation-method","dir":"Articles","previous_headings":"","what":"Changing Correlation Method","title":"Correlation Subset Selection with corrselect","text":"default, corrSelect() uses Pearson correlation. can choose alternatives cor_method argument: \"pearson\": linear correlation (default) \"spearman\": rank-based monotonic association \"kendall\": Kendall’s tau \"bicor\": robust biweight midcorrelation (WGCNA::bicor) \"distance\": distance correlation (energy::dcor) \"maximal\": maximal information coefficient (minerva::mine) Example:","code":"res6 <- corrSelect(df, threshold = 0.7, cor_method = \"spearman\") res6 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"handling-mixed-data-types","dir":"Articles","previous_headings":"","what":"Handling Mixed Data Types","title":"Correlation Subset Selection with corrselect","text":"function assocSelect() extends corrSelect() support mixed data types — including numeric, factor, ordered variables — using appropriate association measures variable pair. Instead single correlation matrix, constructs generalized association matrix using following logic: defaults numeric-numeric, numeric-ordered, ordered-ordered associations can changed via arguments: combinations use fixed methods (eta cramersv) appropriate measuring association strength.","code":"assocSelect(df_ass,   method_num_num = \"kendall\",   method_num_ord = \"spearman\",   method_ord_ord = \"kendall\" ) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = kendall, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.270  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"example-with-mixed-types","dir":"Articles","previous_headings":"Handling Mixed Data Types","what":"Example with Mixed Types","title":"Correlation Subset Selection with corrselect","text":"pairwise association bounded [0,1] treated analogously correlation.","code":"df_ass <- data.frame(   height = rnorm(10),   weight = rnorm(10),   group  = factor(sample(c(\"A\", \"B\"), 10, replace = TRUE)),   score  = ordered(sample(1:3, 10, replace = TRUE)) )  res7 <- assocSelect(df_ass, threshold = 1, method = \"bron-kerbosch\", use_pivot = TRUE) res7 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   1.000 #>   Subsets:     1 valid combinations #>   Data Rows:   10 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.336  0.495     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"theory","dir":"Articles","previous_headings":"","what":"Theory","title":"Correlation Subset Selection with corrselect","text":"Given symmetric correlation matrix R∈ℝp×pR \\\\mathbb{R}^{p \\times p}, seek maximal subsets S⊆{1,…,p}S \\subseteq \\{1, \\dots, p\\} : ∀,j∈S,≠j:|Rij|<t \\forall , j \\S,\\ \\neq j: \\ |R_{ij}| < t fixed threshold t∈(0,1)t \\(0, 1). equivalent finding maximal cliques thresholded correlation graph, : Nodes represent variables Edges connect nodes whose absolute correlation threshold maximal clique corresponds variable subset extended without violating correlation limit.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"els-eppsteinlöfflerstrash","dir":"Articles","previous_headings":"Algorithms","what":"ELS (Eppstein–Löffler–Strash)","title":"Correlation Subset Selection with corrselect","text":"ELS algorithm efficiently enumerates maximal cliques sparse graph using degeneracy ordering: Compute degeneracy ordering v1,…,vpv_1, \\dots, v_p. ii, extend current clique SS {vi}\\{v_i\\} within candidate set C={vi+1,…,vp}C = \\{v_{+1}, \\dots, v_p\\}. Recursively build cliques, pruning vertices can added. Formally, define: extend(S,C)={S,C=∅,⋃v∈Cextend(S∪{v},C\\(N(v)∪{v})),otherwise. \\text{extend}(S, C) = \\begin{cases} S, & C = \\emptyset, \\\\ \\bigcup_{v \\C} \\text{extend}(S \\cup \\{v\\},\\ C \\setminus (N(v) \\cup \\{v\\})), & \\text{otherwise}. \\end{cases} ELS avoids redundant exploration, achieving good performance typical correlation graphs.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"bronkerbosch-with-pivoting","dir":"Articles","previous_headings":"Algorithms","what":"Bron–Kerbosch (with Pivoting)","title":"Correlation Subset Selection with corrselect","text":"classical Bron–Kerbosch algorithm enumerates maximal cliques via recursive backtracking optional pivoting: Let RR = current clique, PP = prospective nodes, XX = excluded nodes. : BK(R,P,X)={report(R),P=X=∅,v∈P\\N(u):BK(R∪{v},P∩N(v),X∩N(v)),P←P\\{v},X←X∪{v}. \\text{BK}(R, P, X) = \\begin{cases} \\text{report}(R), & P = X = \\emptyset, \\\\ \\text{} v \\P \\setminus N(u): \\\\ \\quad \\text{BK}(R \\cup \\{v\\},\\ P \\cap N(v),\\ X \\cap N(v)), \\ \\quad P \\leftarrow P \\setminus \\{v\\},\\ X \\leftarrow X \\cup \\{v\\}. \\end{cases} Choosing pivot u∈P∪Xu \\P \\cup X iterating P\\N(u)P \\setminus N(u) reduces recursive calls.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"why-corrselect","dir":"Articles","previous_headings":"","what":"Why corrselect?","title":"Correlation Subset Selection with corrselect","text":"existing R tools: Filter one variable time (e.g. findCorrelation) Use greedy backward-selection heuristics enumerate valid subsets corrselect uniquely provides: Exact enumeration maximal subsets Support multiple correlation measures Optional forcing variables Full inspection via CorrCombo objects Fast C++ implementations via Rcpp makes ideal pipelines interpretability completeness essential.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"inspecting-results","dir":"Articles","previous_headings":"","what":"Inspecting Results","title":"Correlation Subset Selection with corrselect","text":"Convert results downstream use: Extract individual subsets: Summarize correlation metrics:","code":"df_res <- as.data.frame(res) head(df_res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E lapply(corrSubset(res, df, which = 1:2), function(x) head(x, 10)) #> $Subset1 #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279 #>  #> $Subset2 #>              A          B          C            D           E #> 1   1.37095845  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.56469817  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.36312841 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.63286260  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.40426832 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.10612452  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.51152200 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.09465904 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   2.01842371  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10 -0.06271410  0.1191610 -0.1853780 -0.033487525 -1.90915279 # Number and size of subsets length(res@subset_list) #> [1] 2 summary(lengths(res@subset_list)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       5       5       5       5       5       5  # Summaries of within-subset correlations summary(res@max_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.185   0.185   0.185   0.185   0.185   0.185 summary(res@avg_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.08162 0.08185 0.08208 0.08208 0.08232 0.08255"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"corrcombo-object-structure","dir":"Articles","previous_headings":"","what":"CorrCombo Object Structure","title":"Correlation Subset Selection with corrselect","text":"CorrCombo S4 object contains: subset_list: list character vectors (variable names) avg_corr, min_corr, max_corr: numeric vectors correlation metrics threshold, forced_in, search_type, cor_method, n_rows_used Attribute use_pivot (applicable) Inspect slots:","code":"str(res@subset_list) #> List of 2 #>  $ : chr [1:5] \"F\" \"B\" \"C\" \"D\" ... #>  $ : chr [1:5] \"A\" \"B\" \"C\" \"D\" ..."},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Correlation Subset Selection with corrselect","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13 ucrt) #> Platform: x86_64-w64-mingw32/x64 #> Running under: Windows 11 x64 (build 26200) #>  #> Matrix products: default #>   LAPACK version 3.12.1 #>  #> locale: #> [1] LC_COLLATE=English_United States.utf8  #> [2] LC_CTYPE=English_United States.utf8    #> [3] LC_MONETARY=English_United States.utf8 #> [4] LC_NUMERIC=C                           #> [5] LC_TIME=English_United States.utf8     #>  #> time zone: Europe/Luxembourg #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] corrselect_3.0.0 #>  #> loaded via a namespace (and not attached): #>  [1] digest_0.6.37     desc_1.4.3        R6_2.6.1          fastmap_1.2.0     #>  [5] xfun_0.53         cachem_1.1.0      knitr_1.50        htmltools_0.5.8.1 #>  [9] rmarkdown_2.30    lifecycle_1.0.4   cli_3.6.5         sass_0.4.10       #> [13] pkgdown_2.1.3     textshaping_1.0.3 jquerylib_0.1.4   systemfonts_1.2.3 #> [17] compiler_4.5.1    tools_4.5.1       ragg_1.5.0        evaluate_1.0.5    #> [21] bslib_0.9.0       Rcpp_1.1.0        yaml_2.3.10       jsonlite_2.0.0    #> [25] rlang_1.1.6       fs_1.6.6          htmlwidgets_1.6.4"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning Objectives","title":"Quick Start: Predictor Pruning with corrselect","text":"reading 5-minute guide, able : Remove correlated predictors corrPrune() Reduce multicollinearity modelPrune() Understand use approach","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"prerequisites","dir":"Articles","previous_headings":"","what":"Prerequisites","title":"Quick Start: Predictor Pruning with corrselect","text":"Basic R knowledge Familiarity linear models (helpful required) Estimated time: 5 minutes","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"the-problem","dir":"Articles","previous_headings":"","what":"The Problem","title":"Quick Start: Predictor Pruning with corrselect","text":"many predictors, highly correlated. causes: Unstable coefficient estimates Inflated standard errors Poor model interpretability solution: Remove redundant predictors modeling.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"solution-1-association-based-pruning-with-corrprune","dir":"Articles","previous_headings":"","what":"Solution 1: Association-Based Pruning with corrPrune()","title":"Quick Start: Predictor Pruning with corrselect","text":"use: want clean data modeling, don’t specific model mind yet.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"example-ecological-data","dir":"Articles","previous_headings":"Solution 1: Association-Based Pruning with corrPrune()","what":"Example: Ecological Data","title":"Quick Start: Predictor Pruning with corrselect","text":"Let’s use bioclim_example dataset 19 WorldClim bioclimatic variables: Many variables redundant. Let’s remove variables correlate > 0.7: Result: Reduced 19 → ~8 variables, pairwise correlations ≤ 0.7.","code":"library(corrselect) data(bioclim_example)  # How many variables? ncol(bioclim_example) - 1  # Exclude response variable #> [1] 19 # Remove correlated predictors pruned <- corrPrune(   data = bioclim_example[, -1],  # Exclude response variable   threshold = 0.7                 # Max correlation allowed )  # How many variables remain? ncol(pruned) #> [1] 12"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"check-what-was-removed","dir":"Articles","previous_headings":"Solution 1: Association-Based Pruning with corrPrune()","what":"Check what was removed","title":"Quick Start: Predictor Pruning with corrselect","text":"","code":"# Variables that were kept head(attr(pruned, \"selected_vars\")) #> [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\"  # Variables that were removed head(attr(pruned, \"removed_vars\")) #> NULL"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"visualize-the-improvement","dir":"Articles","previous_headings":"Solution 1: Association-Based Pruning with corrPrune()","what":"Visualize the improvement","title":"Quick Start: Predictor Pruning with corrselect","text":"Key insight: correlations now threshold (red dashed line).","code":"par(mfrow = c(1, 2))  # Before pruning cor_before <- cor(bioclim_example[, -1]) hist(cor_before[upper.tri(cor_before)],      breaks = 30,      main = \"Before Pruning\",      xlab = \"Pairwise Correlation\",      col = \"salmon\") abline(v = 0.7, col = \"red\", lwd = 2, lty = 2)  # After pruning cor_after <- cor(pruned) hist(cor_after[upper.tri(cor_after)],      breaks = 30,      main = \"After Pruning\",      xlab = \"Pairwise Correlation\",      col = \"lightblue\") abline(v = 0.7, col = \"red\", lwd = 2, lty = 2)"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"solution-2-model-based-pruning-with-modelprune","dir":"Articles","previous_headings":"","what":"Solution 2: Model-Based Pruning with modelPrune()","title":"Quick Start: Predictor Pruning with corrselect","text":"use: ’re building regression model want remove multicollinearity based VIF (Variance Inflation Factor).","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"example-predicting-species-richness","dir":"Articles","previous_headings":"Solution 2: Model-Based Pruning with modelPrune()","what":"Example: Predicting Species Richness","title":"Quick Start: Predictor Pruning with corrselect","text":"Let’s build model predicting species richness, first remove multicollinear predictors:","code":"# Prune predictors based on VIF model_data <- modelPrune(   formula = species_richness ~ .,   data = bioclim_example,   limit = 5  # Max VIF allowed (common threshold) )  # How many predictors remain? length(attr(model_data, \"selected_vars\")) #> [1] 16"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"what-happened","dir":"Articles","previous_headings":"Solution 2: Model-Based Pruning with modelPrune()","what":"What happened?","title":"Quick Start: Predictor Pruning with corrselect","text":"","code":"# Predictors removed (high VIF) attr(model_data, \"removed_vars\") #> [1] \"BIO2\" \"BIO7\" \"BIO5\"  # Final model is ready to use final_model <- attr(model_data, \"final_model\") summary(final_model) #>  #> Call: #> stats::lm(formula = formula, data = data) #>  #> Residuals: #>      Min       1Q   Median       3Q      Max  #> -10.1515  -2.8570  -0.2266   2.8122  13.3286  #>  #> Coefficients: #>               Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -2.556e+02  3.719e+01  -6.874 1.08e-09 *** #> BIO1         6.123e-01  1.356e-01   4.515 2.07e-05 *** #> BIO3        -9.124e-02  1.824e-01  -0.500   0.6182     #> BIO4        -1.464e-01  1.909e-01  -0.767   0.4452     #> BIO6         1.896e-01  1.621e-01   1.170   0.2453     #> BIO8         1.506e-01  1.852e-01   0.813   0.4186     #> BIO9         2.781e-01  2.001e-01   1.390   0.1683     #> BIO10       -4.914e-01  2.104e-01  -2.336   0.0219 *   #> BIO11        9.878e-02  1.627e-01   0.607   0.5454     #> BIO12        2.994e-01  7.323e-03  40.884  < 2e-16 *** #> BIO13       -1.997e-03  7.911e-03  -0.252   0.8013     #> BIO14       -3.675e-03  8.891e-03  -0.413   0.6804     #> BIO15        1.945e-01  9.652e-03  20.150  < 2e-16 *** #> BIO16        5.817e-03  7.566e-03   0.769   0.4441     #> BIO17        2.802e-03  7.720e-03   0.363   0.7176     #> BIO18        6.126e-04  7.263e-03   0.084   0.9330     #> BIO19       -2.241e-03  6.560e-03  -0.342   0.7335     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.785 on 83 degrees of freedom #> Multiple R-squared:  0.985,  Adjusted R-squared:  0.9821  #> F-statistic:   340 on 16 and 83 DF,  p-value: < 2.2e-16"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"beforeafter-vif-comparison","dir":"Articles","previous_headings":"Solution 2: Model-Based Pruning with modelPrune()","what":"Before/After VIF Comparison","title":"Quick Start: Predictor Pruning with corrselect","text":"Let’s compare VIF values pruning:  Key insight: VIF values now 5 (red dashed line), indicating acceptable multicollinearity.","code":"# VIF before pruning (fit full model) full_model <- lm(species_richness ~ ., data = bioclim_example)  # Compute VIF manually X_full <- model.matrix(full_model)[, -1]  # Remove intercept vif_before <- sapply(colnames(X_full), function(var) {   1 / (1 - summary(lm(X_full[, var] ~ X_full[, -which(colnames(X_full) == var)]))$r.squared) })  # VIF after pruning X_pruned <- model.matrix(final_model)[, -1] vif_after <- sapply(colnames(X_pruned), function(var) {   1 / (1 - summary(lm(X_pruned[, var] ~ X_pruned[, -which(colnames(X_pruned) == var)]))$r.squared) })  # Visualize par(mfrow = c(1, 2)) barplot(sort(vif_before, decreasing = TRUE)[1:20],         las = 2,         main = \"Before Pruning (top 20)\",         ylab = \"VIF\",         col = \"salmon\",         cex.names = 0.7) abline(h = 5, col = \"red\", lwd = 2, lty = 2)  barplot(sort(vif_after, decreasing = TRUE),         las = 2,         main = \"After Pruning\",         ylab = \"VIF\",         col = \"lightblue\",         cex.names = 0.7) abline(h = 5, col = \"red\", lwd = 2, lty = 2)"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"choosing-between-corrprune-and-modelprune","dir":"Articles","previous_headings":"","what":"Choosing Between corrPrune() and modelPrune()","title":"Quick Start: Predictor Pruning with corrselect","text":"Pro tip: Use !","code":"# Step 1: Quick correlation cleanup (exploratory) data_cleaned <- corrPrune(your_data, threshold = 0.7)  # Step 2: VIF-based pruning (model-specific) model_ready <- modelPrune(response ~ ., data = data_cleaned, limit = 5)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"choosing-the-wrong-threshold","dir":"Articles","previous_headings":"Common Pitfalls","what":"1. Choosing the wrong threshold","title":"Quick Start: Predictor Pruning with corrselect","text":"strict (e.g., threshold = 0.3): May remove many useful variables lenient (e.g., threshold = 0.95): Multicollinearity persists Recommendation: Start 0.7 correlations, 5 VIF","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"forgetting-to-protect-important-variables","dir":"Articles","previous_headings":"Common Pitfalls","what":"2. Forgetting to protect important variables","title":"Quick Start: Predictor Pruning with corrselect","text":"Use force_in keep key predictors:","code":"pruned <- corrPrune(data, threshold = 0.7,                     force_in = c(\"age\", \"treatment\"))"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"pruning-the-response-variable","dir":"Articles","previous_headings":"Common Pitfalls","what":"3. Pruning the response variable","title":"Quick Start: Predictor Pruning with corrselect","text":"Always exclude response variable corrPrune():","code":"# WRONG pruned <- corrPrune(my_data, threshold = 0.7)  # RIGHT pruned <- corrPrune(my_data[, -which(names(my_data) == \"response\")],                     threshold = 0.7)"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Quick Start: Predictor Pruning with corrselect","text":"’ve learned: corrPrune() removes correlated predictors (model-free) modelPrune() reduces VIF (model-based) Use complete workflow Check results visualizations 5 minutes, can now: Clean data corrPrune() Prepare models modelPrune() Understand use approach","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Quick Start: Predictor Pruning with corrselect","text":"examples: See vignette(\"workflows\") complete workflows across different domains Advanced features: See vignette(\"corrselect_vignette\") exact subset enumeration Function reference: See ?corrPrune ?modelPrune full documentation","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"quick-reference","dir":"Articles","previous_headings":"","what":"Quick Reference","title":"Quick Start: Predictor Pruning with corrselect","text":"","code":"# Association-based pruning pruned <- corrPrune(   data = your_data,   threshold = 0.7,       # Max correlation   mode = \"auto\",         # \"exact\", \"greedy\", or \"auto\"   force_in = NULL        # Variables to protect )  # Model-based pruning pruned <- modelPrune(   formula = y ~ .,   data = your_data,   engine = \"lm\",         # \"lm\", \"glm\", \"lme4\", \"glmmTMB\"   limit = 5,             # Max VIF   force_in = NULL        # Variables to protect )"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Complete Workflows: Real-World Examples","text":"vignette demonstrates complete end--end workflows using corrselect across four different research domains: Ecological Modeling: Predicting species distribution bioclimatic variables Survey Data Analysis: Analyzing questionnaires redundant items High-Dimensional Data: Gene expression analysis Mixed Models: Longitudinal studies random effects workflow shows realistic data, complete code, interpretation guidance. Estimated time: 15-20 minutes","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"scenario","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Scenario","title":"Complete Workflows: Real-World Examples","text":"’re building species distribution model using 19 WorldClim bioclimatic variables. Many variables highly correlated (e.g., different temperature metrics), causing multicollinearity. Goal: Identify parsimonious set predictors : - Covers different environmental dimensions - low multicollinearity - Predicts species richness well","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-1-load-and-explore-data","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Step 1: Load and explore data","title":"Complete Workflows: Real-World Examples","text":"Visualize correlation structure:  Many variable pairs exceed 0.7 threshold, indicating redundancy.","code":"library(corrselect) data(bioclim_example)  # Data structure dim(bioclim_example) #> [1] 100  20 head(names(bioclim_example)) #> [1] \"species_richness\" \"BIO1\"             \"BIO2\"             \"BIO3\"             #> [5] \"BIO4\"             \"BIO5\"  # Response variable summary(bioclim_example$species_richness) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>     5.0    96.0   118.5   120.2   144.2   206.0 # Correlation matrix cor_matrix <- cor(bioclim_example[, -1])  # Histogram of correlations hist(cor_matrix[upper.tri(cor_matrix)],      breaks = 30,      main = \"Distribution of Pairwise Correlations\",      xlab = \"Correlation\",      col = \"lightblue\",      border = \"white\") abline(v = 0.7, col = \"red\", lwd = 2, lty = 2) text(0.7, par(\"usr\")[4] * 0.9, \"threshold = 0.7\", pos = 4, col = \"red\")"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-2-quick-correlation-cleanup-with-corrprune","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Step 2: Quick correlation cleanup with corrPrune()","title":"Complete Workflows: Real-World Examples","text":"Visualize improvement:  correlations now fall within ±0.7 threshold.","code":"# Remove highly correlated predictors bio_clean <- corrPrune(   data = bioclim_example[, -1],  # Exclude response   threshold = 0.7,   mode = \"auto\" )  # How much did we reduce? cat(sprintf(\"Reduced from %d → %d variables\\n\",             ncol(bioclim_example) - 1,             ncol(bio_clean))) #> Reduced from 19 → 12 variables  # Which variables were kept? head(attr(bio_clean, \"selected_vars\"), 10) #>  [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\" \"BIO13\" \"BIO14\" \"BIO16\" #> [10] \"BIO17\" par(mfrow = c(1, 2))  # Before pruning cor_before <- cor(bioclim_example[, -1]) hist(cor_before[upper.tri(cor_before)],      breaks = 30,      main = \"Before corrPrune()\",      xlab = \"Correlation\",      col = \"salmon\",      xlim = c(-1, 1)) abline(v = c(-0.7, 0.7), col = \"red\", lwd = 2, lty = 2)  # After pruning cor_after <- cor(bio_clean) hist(cor_after[upper.tri(cor_after)],      breaks = 30,      main = \"After corrPrune()\",      xlab = \"Correlation\",      col = \"lightblue\",      xlim = c(-1, 1)) abline(v = c(-0.7, 0.7), col = \"red\", lwd = 2, lty = 2)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-3-fit-initial-model","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Step 3: Fit initial model","title":"Complete Workflows: Real-World Examples","text":"","code":"# Add response back bio_clean_full <- data.frame(   species_richness = bioclim_example$species_richness,   bio_clean )  # Fit linear model model_initial <- lm(species_richness ~ ., data = bio_clean_full)  # Quick summary cat(sprintf(\"R² = %.3f\\n\", summary(model_initial)$r.squared)) #> R² = 0.909 cat(sprintf(\"Adj R² = %.3f\\n\", summary(model_initial)$adj.r.squared)) #> Adj R² = 0.896"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-4-vif-cleanup-with-modelprune","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Step 4: VIF cleanup with modelPrune()","title":"Complete Workflows: Real-World Examples","text":"Even correlation pruning, multicollinearity may remain. Let’s remove predictors VIF > 5:","code":"# Further pruning based on VIF bio_final <- modelPrune(   formula = species_richness ~ .,   data = bio_clean_full,   limit = 5 )  # Final predictor set final_vars <- attr(bio_final, \"selected_vars\") cat(sprintf(\"Final model: %d predictors\\n\", length(final_vars))) #> Final model: 12 predictors print(final_vars) #>  [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\" \"BIO13\" \"BIO14\" \"BIO16\" #> [10] \"BIO17\" \"BIO18\" \"BIO19\""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-5-compare-models","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Step 5: Compare models","title":"Complete Workflows: Real-World Examples","text":"Visualize model comparison:  Interpretation: - R² decreased slightly (expected - removed predictors) - Adjusted R² improved (better parsimony) - AIC improved (better model fit penalized complexity) - Multicollinearity eliminated (VIF < 5)","code":"# Get final model final_model <- attr(bio_final, \"final_model\")  # Compare comparison <- data.frame(   Model = c(\"Full model\", \"After corrPrune\", \"After modelPrune\"),   R2 = c(     summary(lm(species_richness ~ ., data = bioclim_example))$r.squared,     summary(model_initial)$r.squared,     summary(final_model)$r.squared   ),   Adj_R2 = c(     summary(lm(species_richness ~ ., data = bioclim_example))$adj.r.squared,     summary(model_initial)$adj.r.squared,     summary(final_model)$adj.r.squared   ),   AIC = c(     AIC(lm(species_richness ~ ., data = bioclim_example)),     AIC(model_initial),     AIC(final_model)   ) )  print(comparison) #>              Model        R2    Adj_R2      AIC #> 1       Full model 0.9856050 0.9821862 615.9339 #> 2  After corrPrune 0.9088563 0.8962848 786.4894 #> 3 After modelPrune 0.9088563 0.8962848 786.4894 par(mfrow = c(1, 2))  # Number of predictors barplot(c(19, length(attr(bio_clean, \"selected_vars\")), length(final_vars)),         names.arg = c(\"Full\\n(19 vars)\", \"corrPrune\\n(~8 vars)\", \"modelPrune\\n(~6 vars)\"),         main = \"Number of Predictors\",         ylab = \"Count\",         col = c(\"salmon\", \"lightblue\", \"lightgreen\"),         ylim = c(0, 20))  # Model quality (Adjusted R²) barplot(comparison$Adj_R2,         names.arg = c(\"Full\", \"corrPrune\", \"modelPrune\"),         main = \"Adjusted R²\",         ylab = \"Value\",         col = c(\"salmon\", \"lightblue\", \"lightgreen\"),         ylim = c(0, 1))"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"visualize-coefficient-stability","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Visualize coefficient stability","title":"Complete Workflows: Real-World Examples","text":"Key insight: Coefficients stable interpretable pruned model.","code":"# Extract coefficients (excluding intercept) coef_full <- coef(lm(species_richness ~ ., data = bioclim_example))[-1] coef_final <- coef(final_model)[-1]  # Plot for variables present in final model common_vars <- intersect(names(coef_full), names(coef_final))  par(mfrow = c(1, 2)) barplot(coef_full[common_vars],         las = 2,         main = \"Full Model\",         ylab = \"Coefficient\",         col = \"salmon\",         cex.names = 0.6)  barplot(coef_final[common_vars],         las = 2,         main = \"Final Model (8 vars)\",         ylab = \"Coefficient\",         col = \"lightblue\",         cex.names = 0.6)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"scenario-1","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Scenario","title":"Complete Workflows: Real-World Examples","text":"questionnaire 30 Likert-scale items measuring satisfaction, engagement, loyalty. Many items redundant (asking similar questions). want identify items keep parsimonious model. Goal: Reduce questionnaire length retaining construct coverage protecting key demographic variables.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-1-load-data","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Step 1: Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(survey_example)  # Data structure dim(survey_example) #> [1] 200  35 str(survey_example[, 1:10])  # First 10 columns #> 'data.frame':    200 obs. of  10 variables: #>  $ respondent_id       : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ age                 : num  38 32 18 18 19 39 33 26 26 42 ... #>  $ gender              : Factor w/ 3 levels \"Female\",\"Male\",..: 2 3 1 2 2 1 1 2 2 1 ... #>  $ education           : Ord.factor w/ 4 levels \"High School\"<..: 3 1 4 2 2 1 1 1 2 3 ... #>  $ overall_satisfaction: num  58 40 44 40 58 67 61 49 51 52 ... #>  $ satisfaction_1      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 5 3 4 5 5 4 4 5 ... #>  $ satisfaction_2      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 4 6 6 4 4 3 ... #>  $ satisfaction_3      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 3 4 5 3 4 4 ... #>  $ satisfaction_4      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 4 4 5 4 3 2 4 ... #>  $ satisfaction_5      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 7 4 5 5 5 4 3 6 4 6 ..."},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-2-prune-redundant-items-with-force_in","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Step 2: Prune redundant items with force_in","title":"Complete Workflows: Real-World Examples","text":"want : - Remove redundant Likert items (correlation > 0.6) - Always keep age (key covariate)","code":"# Exclude respondent_id, overall_satisfaction, and factor variables survey_predictors <- survey_example[, !(names(survey_example) %in%                                          c(\"respondent_id\", \"overall_satisfaction\",                                            \"gender\", \"education\"))]  # Convert ordered factors (Likert items 1-7) to numeric for correlation analysis survey_numeric <- as.data.frame(lapply(survey_predictors, function(x) {   if (is.ordered(x)) as.numeric(as.character(x)) else as.numeric(x) }))  # Prune with protected variables survey_clean <- corrPrune(   data = survey_numeric,   threshold = 0.6,   force_in = \"age\" )  # How many items remain? cat(sprintf(\"Reduced from %d → %d variables\\n\",             ncol(survey_numeric),             ncol(survey_clean))) #> Reduced from 31 → 4 variables  # Which items were kept? selected <- attr(survey_clean, \"selected_vars\") print(selected) #> [1] \"age\"            \"satisfaction_5\" \"engagement_1\"   \"loyalty_5\""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-3-verify-construct-coverage","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Step 3: Verify construct coverage","title":"Complete Workflows: Real-World Examples","text":"Visualize construct coverage:  Interpretation: construct represented fewer items, reducing respondent burden maintaining coverage.","code":"# Count items per construct satisfaction_kept <- sum(grepl(\"satisfaction_\", selected)) engagement_kept <- sum(grepl(\"engagement_\", selected)) loyalty_kept <- sum(grepl(\"loyalty_\", selected))  cat(sprintf(\"Satisfaction: %d/10 items kept\\n\", satisfaction_kept)) #> Satisfaction: 1/10 items kept cat(sprintf(\"Engagement: %d/10 items kept\\n\", engagement_kept)) #> Engagement: 1/10 items kept cat(sprintf(\"Loyalty: %d/10 items kept\\n\", loyalty_kept)) #> Loyalty: 1/10 items kept par(mfrow = c(1, 2))  # Items kept per construct construct_data <- rbind(   c(10, 10, 10),   c(satisfaction_kept, engagement_kept, loyalty_kept) )  barplot(construct_data,         beside = TRUE,         names.arg = c(\"Satisfaction\", \"Engagement\", \"Loyalty\"),         col = c(\"lightgray\", \"lightblue\"),         legend.text = c(\"Original (10)\", \"After pruning\"),         args.legend = list(x = \"topright\", bty = \"n\"),         main = \"Items per Construct\",         ylab = \"Number of Items\",         ylim = c(0, 12))  # Percentage reduction barplot(c(ncol(survey_numeric), ncol(survey_clean)),         names.arg = c(\"Before\", \"After\"),         col = c(\"salmon\", \"lightgreen\"),         main = \"Total Variables\",         ylab = \"Count\",         ylim = c(0, max(ncol(survey_numeric)) * 1.2)) text(0.7, ncol(survey_numeric) + 1, ncol(survey_numeric), pos = 3) text(1.9, ncol(survey_clean) + 1, ncol(survey_clean), pos = 3)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-4-model-overall-satisfaction","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Step 4: Model overall satisfaction","title":"Complete Workflows: Real-World Examples","text":"","code":"# Add response back survey_model_data <- data.frame(   overall_satisfaction = survey_example$overall_satisfaction,   survey_clean )  # Fit regression model model_survey <- lm(overall_satisfaction ~ ., data = survey_model_data)  # Summary summary(model_survey) #>  #> Call: #> lm(formula = overall_satisfaction ~ ., data = survey_model_data) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -16.463  -4.384   0.374   4.494  17.338  #>  #> Coefficients: #>                Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    25.13579    2.16083  11.632   <2e-16 *** #> age             0.01805    0.04329   0.417    0.677     #> satisfaction_5  4.89449    0.35881  13.641   <2e-16 *** #> engagement_1    0.45383    0.32950   1.377    0.170     #> loyalty_5       0.34698    0.31296   1.109    0.269     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 6.661 on 195 degrees of freedom #> Multiple R-squared:  0.6605, Adjusted R-squared:  0.6535  #> F-statistic: 94.82 on 4 and 195 DF,  p-value: < 2.2e-16"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-5-compare-with-full-model","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Step 5: Compare with full model","title":"Complete Workflows: Real-World Examples","text":"Key insight: Similar predictive power 70% fewer items - much practical future surveys!","code":"# Full model (all 30 items + demographics) full_survey_data <- data.frame(   overall_satisfaction = survey_example$overall_satisfaction,   survey_predictors )  model_full_survey <- lm(overall_satisfaction ~ ., data = full_survey_data)  # Compare data.frame(   Model = c(\"Full (33 vars)\", \"Pruned (10 vars)\"),   R2 = c(summary(model_full_survey)$r.squared,          summary(model_survey)$r.squared),   Adj_R2 = c(summary(model_full_survey)$adj.r.squared,              summary(model_survey)$adj.r.squared),   Num_Predictors = c(33, 10) ) #>              Model        R2    Adj_R2 Num_Predictors #> 1   Full (33 vars) 0.9790144 0.7679931             33 #> 2 Pruned (10 vars) 0.6604503 0.6534852             10"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"scenario-2","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"Scenario","title":"Complete Workflows: Real-World Examples","text":"gene expression data: 200 genes measured across 100 samples. want identify genes associated disease removing redundant (co-expressed) genes. Challenge: p >> n scenario high correlation structure. Goal: Reduce dimensionality efficiently using greedy mode.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-1-load-data-1","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"Step 1: Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(genes_example)  # Data structure dim(genes_example) #> [1] 100 202  # Disease prevalence table(genes_example$disease_status) #>  #> Healthy Disease  #>       2      98"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-2-greedy-pruning-for-large-p","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"Step 2: Greedy pruning for large p","title":"Complete Workflows: Real-World Examples","text":"200 genes, exact mode slow. Use greedy mode: Visualize dimensionality reduction:  Result: Completed < 1 second (vs. hours exact mode p=200).","code":"# Extract gene expression data (exclude ID and outcome) gene_expr <- genes_example[, -(1:2)]  # Greedy pruning system.time({   genes_pruned <- corrPrune(     data = gene_expr,     threshold = 0.8,     mode = \"greedy\"  # Fast for large p   ) }) #>    user  system elapsed  #>    0.02    0.00    0.02  # Reduction cat(sprintf(\"Reduced from %d → %d genes\\n\",             ncol(gene_expr),             ncol(genes_pruned))) #> Reduced from 200 → 177 genes # Barplot showing reduction reduction_data <- c(ncol(gene_expr), ncol(genes_pruned)) barplot(reduction_data,         names.arg = c(\"Original\", \"After Pruning\"),         main = \"Gene Dimensionality Reduction\",         ylab = \"Number of Genes\",         col = c(\"salmon\", \"lightblue\"),         ylim = c(0, max(reduction_data) * 1.2)) text(0.7, reduction_data[1] + 10, paste(reduction_data[1], \"genes\"), pos = 3) text(1.9, reduction_data[2] + 10, paste(reduction_data[2], \"genes\\n(\",      round(100 * reduction_data[2] / reduction_data[1], 1), \"% retained)\"), pos = 3)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-3-compare-exact-vs-greedy-for-subset","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"Step 3: Compare exact vs greedy for subset","title":"Complete Workflows: Real-World Examples","text":"Let’s verify greedy performance smaller subset (first 50 genes): Key insight: Greedy mode faster produces solutions close optimal.","code":"# Subset for comparison gene_subset <- gene_expr[, 1:50]  # Exact mode system.time({   exact_result <- corrPrune(gene_subset, threshold = 0.8, mode = \"exact\") }) #>    user  system elapsed  #>  475.80    4.13  482.85  # Greedy mode system.time({   greedy_result <- corrPrune(gene_subset, threshold = 0.8, mode = \"greedy\") }) #>    user  system elapsed  #>       0       0       0  # Compare sizes cat(sprintf(\"Exact mode: %d genes kept\\n\", ncol(exact_result))) #> Exact mode: 28 genes kept cat(sprintf(\"Greedy mode: %d genes kept\\n\", ncol(greedy_result))) #> Greedy mode: 27 genes kept"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-4-use-pruned-genes-for-classification","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"Step 4: Use pruned genes for classification","title":"Complete Workflows: Real-World Examples","text":"","code":"# Prepare classification data classification_data <- data.frame(   disease_status = genes_example$disease_status,   genes_pruned )  # Logistic regression model_genes <- glm(disease_status ~ .,                    data = classification_data,                    family = binomial())  # Prediction accuracy predictions <- ifelse(predict(model_genes, type = \"response\") > 0.5,                      \"Disease\", \"Healthy\") accuracy <- mean(predictions == genes_example$disease_status)  cat(sprintf(\"Classification accuracy: %.1f%%\\n\", accuracy * 100)) #> Classification accuracy: 100.0%"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"scenario-3","dir":"Articles","previous_headings":"Workflow 4: Mixed Models (Longitudinal Data)","what":"Scenario","title":"Complete Workflows: Real-World Examples","text":"longitudinal data: 50 subjects measured 10 timepoints , 20 correlated predictors. want prune fixed effects preserving random effects structure (subject site). Goal: Remove multicollinear fixed effects using modelPrune() lme4 engine.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-1-load-data-2","dir":"Articles","previous_headings":"Workflow 4: Mixed Models (Longitudinal Data)","what":"Step 1: Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(longitudinal_example)  # Data structure dim(longitudinal_example) #> [1] 500  25 head(longitudinal_example) #>   obs_id subject site time  outcome          x1         x2          x3 #> 1      1       1    1    1 12.10893 -0.62045078 -0.8629274 -0.39625483 #> 2      2       1    1    2 13.97195  0.04255998  0.4086801  0.27069591 #> 3      3       1    1    3 15.71622  0.20445067 -1.0457672  1.69557480 #> 4      4       1    1    4 12.61343  0.38437289  2.0301256 -1.17894923 #> 5      5       1    1    5 15.73139 -0.06402543  1.1645219 -0.19757260 #> 6      6       1    1    6 13.19571  0.65208588 -1.5040345  0.07671762 #>           x4         x5          x6         x7         x8           x9 #> 1 -0.4557709 -1.2550770 -0.35966846 -1.9288176  0.8393628  0.151111346 #> 2 -0.7652493 -1.2136755 -0.05181211 -0.4759841  0.9063848  1.429621637 #> 3  0.5569423 -1.4962408  0.23986408 -1.7077822  1.0343806  0.797974670 #> 4  0.1604224 -0.8192580 -0.94858863 -1.9314095 -0.0639552  0.887413164 #> 5 -1.3331022 -0.6162473 -0.61339605 -0.9439486 -0.1220047 -0.796244469 #> 6  0.5205094 -0.8547461  0.24120308 -1.3083776  0.8716209  0.005423635 #>          x10        x11       x12         x13        x14        x15         x16 #> 1  0.9681971 -0.1384342 0.2598923  0.37082493 -0.1829715 -1.1853721 -0.72703262 #> 2  2.0989531  0.6303914 0.6211064 -0.91103843 -0.1125705 -0.3458058 -0.44331165 #> 3  0.2329831 -0.8618361 2.0854289  0.02634099 -1.3522055 -1.2151804  0.00311954 #> 4  1.5491815  1.7595441 0.8198899  0.18115372 -0.5638401 -1.3637072 -0.55274223 #> 5  2.3485234 -0.1267969 2.6230203 -1.13918808 -1.1559678 -0.3214032 -0.87713586 #> 6 -0.1860167 -0.4620834 1.6075140 -1.81586413 -0.0172986 -0.1041232 -0.56268259 #>           x17        x18        x19       x20 #> 1  0.91333399  1.2398417  1.2973339 1.0590334 #> 2 -0.09799793 -1.3670758 -1.0050198 0.9990451 #> 3 -0.14957945 -0.8573087  0.9004974 0.5399732 #> 4  0.55650397  0.7458841  0.7415159 1.7067212 #> 5  0.36401595 -0.4019171  1.1669136 0.7799264 #> 6  0.30234421 -0.6646296 -0.6615620 1.5092899  # Study design cat(sprintf(\"Subjects: %d\\n\", length(unique(longitudinal_example$subject)))) #> Subjects: 50 cat(sprintf(\"Sites: %d\\n\", length(unique(longitudinal_example$site)))) #> Sites: 5 cat(sprintf(\"Observations per subject: %d\\n\",             nrow(longitudinal_example) / length(unique(longitudinal_example$subject)))) #> Observations per subject: 10"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-2-prune-fixed-effects-with-mixed-model-engine","dir":"Articles","previous_headings":"Workflow 4: Mixed Models (Longitudinal Data)","what":"Step 2: Prune fixed effects with mixed model engine","title":"Complete Workflows: Real-World Examples","text":"","code":"# Note: This example requires lme4 package library(lme4)  # Define formula with random effects # Note: Only fixed effects (x1-x5) will be pruned #       Random effects (1|subject), (1|site) are preserved  pruned_mixed <- modelPrune(   formula = outcome ~ x1 + x2 + x3 + x4 + x5 + (1|subject) + (1|site),   data = longitudinal_example,   engine = \"lme4\",   limit = 5 )  # Which fixed effects were kept? selected_fixed <- attr(pruned_mixed, \"selected_vars\") cat(\"Fixed effects kept:\\n\") print(selected_fixed)  # Which were removed? removed_fixed <- attr(pruned_mixed, \"removed_vars\") cat(\"\\nFixed effects removed:\\n\") print(removed_fixed)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-3-examine-final-model","dir":"Articles","previous_headings":"Workflow 4: Mixed Models (Longitudinal Data)","what":"Step 3: Examine final model","title":"Complete Workflows: Real-World Examples","text":"Key insight: Random effects (1|subject) (1|site) preserved - problematic fixed effects removed.","code":"final_mixed <- attr(pruned_mixed, \"final_model\") summary(final_mixed)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"step-4-verify-vif-reduction","dir":"Articles","previous_headings":"Workflow 4: Mixed Models (Longitudinal Data)","what":"Step 4: Verify VIF reduction","title":"Complete Workflows: Real-World Examples","text":"Result: VIF values now limit 5.","code":"# Note: This example requires lme4 package library(lme4)  # Fit full model full_formula <- as.formula(paste(\"outcome ~\",                                  paste(paste0(\"x\", 1:5), collapse = \" + \"),                                  \"+ (1|subject) + (1|site)\"))  model_full_mixed <- lmer(full_formula, data = longitudinal_example)  # Extract fixed effects design matrices X_full <- getME(model_full_mixed, \"X\") X_pruned <- getME(final_mixed, \"X\")  # Compute VIF compute_vif <- function(X) {   X_scaled <- scale(X[, -1])  # Remove intercept   sapply(1:ncol(X_scaled), function(i) {     r2 <- summary(lm(X_scaled[, i] ~ X_scaled[, -i]))$r.squared     1 / (1 - r2)   }) }  vif_full <- compute_vif(X_full) vif_pruned <- compute_vif(X_pruned)  # Compare data.frame(   Predictor = colnames(X_pruned)[-1],   VIF_Before = vif_full,   VIF_After = vif_pruned )"},{"path":[]},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"for-corrprune-correlation-threshold","dir":"Articles","previous_headings":"Comparison Summary > Choosing thresholds","what":"For corrPrune() (correlation threshold)","title":"Complete Workflows: Real-World Examples","text":"0.5: Strict (low redundancy, may lose information) 0.7: Moderate (recommended starting point) 0.9: Lenient (remove near-duplicates)","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"for-modelprune-vif-limit","dir":"Articles","previous_headings":"Comparison Summary > Choosing thresholds","what":"For modelPrune() (VIF limit)","title":"Complete Workflows: Real-World Examples","text":"5: Standard threshold (moderate multicollinearity) 10: Lenient (tolerate multicollinearity) 2: Strict (low multicollinearity, may -prune) Pro tip: Visualize correlation/VIF distributions choosing!","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"pattern-1-two-step-pruning","dir":"Articles","previous_headings":"Common Patterns","what":"Pattern 1: Two-Step Pruning","title":"Complete Workflows: Real-World Examples","text":"Use : many predictors (p > 30) want computational efficiency.","code":"# Step 1: Fast correlation cleanup data_cleaned <- corrPrune(raw_data, threshold = 0.7)  # Step 2: Model-specific VIF cleanup model_ready <- modelPrune(response ~ ., data = data_cleaned, limit = 5)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"pattern-2-protected-variables","dir":"Articles","previous_headings":"Common Patterns","what":"Pattern 2: Protected Variables","title":"Complete Workflows: Real-World Examples","text":"Use : predictors must remain scientific/policy reasons.","code":"# Always keep age, gender, treatment pruned <- corrPrune(data, threshold = 0.6,                     force_in = c(\"age\", \"gender\", \"treatment\"))"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"pattern-3-mixed-model-workflow","dir":"Articles","previous_headings":"Common Patterns","what":"Pattern 3: Mixed Model Workflow","title":"Complete Workflows: Real-World Examples","text":"Use : hierarchical/repeated measures data.","code":"# Prune only fixed effects pruned <- modelPrune(   y ~ x1 + x2 + x3 + (1|subject) + (1|site),   data = longitudinal_data,   engine = \"lme4\",   limit = 5 )"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"problem-no-valid-subsets-found","dir":"Articles","previous_headings":"Troubleshooting","what":"Problem: “No valid subsets found”","title":"Complete Workflows: Real-World Examples","text":"Cause: Threshold strict - variables exceed . Solution: Increase threshold use mode = \"greedy\" best-effort solution.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"problem-too-many-variables-removed","dir":"Articles","previous_headings":"Troubleshooting","what":"Problem: Too many variables removed","title":"Complete Workflows: Real-World Examples","text":"Cause: Threshold lenient, limit low. Solution: - Decrease correlation threshold (e.g., 0.7 → 0.8) - Increase VIF limit (e.g., 5 → 10) - Use force_in protect important variables","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"problem-pruning-takes-too-long","dir":"Articles","previous_headings":"Troubleshooting","what":"Problem: Pruning takes too long","title":"Complete Workflows: Real-World Examples","text":"Cause: Using mode = \"exact\" large p. Solution: Use mode = \"greedy\" mode = \"auto\" (auto-switches p > 20).","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next Steps","title":"Complete Workflows: Real-World Examples","text":"Advanced features: See vignette(\"corrselect_vignette\") exact subset enumeration Custom engines: See ?modelPrune integrating custom modeling packages (INLA, mgcv, etc.) Function reference: Full documentation ?corrPrune ?modelPrune","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Complete Workflows: Real-World Examples","text":"Thresholds: - O’Brien, R. M. (2007). caution regarding rules thumb variance inflation factors. Quality & Quantity, 41(5), 673-690. - Dormann, C. F., et al. (2013). Collinearity: review methods deal . Ecography, 36(1), 27-46. Methods: - See package documentation JOSS paper algorithm details","code":""},{"path":"https://gcol33.github.io/corrselect/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gilles Colling. Author, maintainer.","code":""},{"path":"https://gcol33.github.io/corrselect/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Colling G (2025). corrselect: Correlation-Based Variable Subset Selection. R package version 1.0.0, https://github.com/gcol33/corrselect.","code":"@Manual{,   title = {corrselect: Correlation-Based Variable Subset Selection},   author = {Gilles Colling},   year = {2025},   note = {R package version 1.0.0},   url = {https://github.com/gcol33/corrselect}, }"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"CLAUDE.md","text":"corrselect R package performs exhaustive, model-agnostic variable subset selection based pairwise correlation association. identifies maximal subsets variables whose pairwise correlations/associations remain user-defined threshold, helping reduce multicollinearity maintaining interpretability.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"build-and-install","dir":"","previous_headings":"Development Commands","what":"Build and Install","title":"CLAUDE.md","text":"","code":"# Load package for development devtools::load_all()  # Install package locally devtools::install()  # If modifying C++ code, clean DLL first devtools::clean_dll() devtools::install()  # Regenerate documentation (after roxygen2 changes) devtools::document()"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"testing","dir":"","previous_headings":"Development Commands","what":"Testing","title":"CLAUDE.md","text":"","code":"# Run full test suite devtools::test()  # Run complete package check (includes tests, examples, documentation) devtools::check()  # Run specific test file during development testthat::test_file(\"tests/testthat/test-corrSelect.R\")  # Run test directory testthat::test_dir(\"tests/testthat\")"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"documentation","dir":"","previous_headings":"Development Commands","what":"Documentation","title":"CLAUDE.md","text":"","code":"# Build vignettes devtools::build_vignettes()  # Build pkgdown site locally (output in docs/) pkgdown::build_site()"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"high-level-design","dir":"","previous_headings":"Architecture","what":"High-Level Design","title":"CLAUDE.md","text":"package provides three main user-facing functions converge common C++ backend: corrSelect() - Data frame interface numeric correlation assocSelect() - Data frame interface mixed-type data (numeric, factor, ordered) MatSelect() - Direct correlation/association matrix interface three functions: - Preprocess input (handle missing data, validate types) - Compute validate correlation/association matrix - Call C++ backend findAllMaxSets() enumerate maximal subsets - Return CorrCombo S4 object results","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"c-backend-architecture","dir":"","previous_headings":"Architecture","what":"C++ Backend Architecture","title":"CLAUDE.md","text":"Entry point: src/corrselect_main.cpp::findAllMaxSets() C++ layer implements two exact graph-theoretic algorithms enumerating maximal cliques graph edges represent “sufficiently low correlation”: Recommended using force_in (variables must appear subsets) Exact enumeration maximal independent sets Optional pivoting performance (use_pivot = TRUE) Default algorithm force_in specified Key types (src/corrselect_types.h): - Combo = std::vector<int> (variable indices) - ComboList = std::vector<Combo> (collection subsets) Utilities (src/utils.cpp, src/utils.h): - Matrix validation - Correlation statistics (mean, min, max subsets)","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"r-layer-architecture","dir":"","previous_headings":"Architecture","what":"R Layer Architecture","title":"CLAUDE.md","text":"Data frame preprocessing: - corrSelect(): Filters numeric columns , removes NA rows, computes correlation matrix using cor_method parameter - assocSelect(): Handles mixed types computing appropriate metrics pair type (Pearson, Spearman, Kendall, Eta-squared, Cramér’s V) CorrCombo S4 class (R/CorrCombo.R): - Stores discovered subsets metadata - Slots: subset_list, avg_corr, min_corr, max_corr, threshold, forced_in, search_type, cor_method, n_rows_used, names - Custom show() method user-friendly output - .data.frame() method tidy data extraction Helper functions: - corrSubset() (R/corrSubset.R): Extracts specific subsets original data, option keep non-numeric columns (keepExtra = TRUE) - findAllMaxSets() (R/findAllMaxSets.R): R wrapper calling C++ via Rcpp","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"algorithm-selection-logic","dir":"","previous_headings":"Architecture","what":"Algorithm Selection Logic","title":"CLAUDE.md","text":"Default method selection corrSelect() assocSelect(): - force_in provided → use ELS algorithm - Otherwise → use Bron-Kerbosch algorithm Users can override explicitly setting method = \"els\" method = \"bron-kerbosch\".","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"association-metrics-for-mixed-data","dir":"","previous_headings":"Architecture","what":"Association Metrics for Mixed Data","title":"CLAUDE.md","text":"assocSelect() automatically selects metrics based variable pair types: External correlation methods require additional packages: - bicor: WGCNA package - distance: energy package - maximal: minerva package","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"file-organization","dir":"","previous_headings":"","what":"File Organization","title":"CLAUDE.md","text":"","code":"R/                           # R source files ├── corrSelect.R            # Numeric data frame interface ├── assocSelect.R           # Mixed-type data frame interface ├── MatSelect.R             # Matrix interface ├── CorrCombo.R             # S4 class definition and methods ├── corrSubset.R            # Subset extraction helper └── findAllMaxSets.R        # R wrapper for C++ entry point  src/                         # C++ source files (Rcpp) ├── corrselect_main.cpp     # Main entry point and algorithm dispatch ├── corrselect_types.h      # Type definitions (Combo, ComboList) ├── method_els.{cpp,h}      # Eppstein-Löffler-Strash implementation ├── method_bronkerbosch.{cpp,h}  # Bron-Kerbosch implementation ├── utils.{cpp,h}           # Matrix validation and correlation stats └── RcppExports.cpp         # Generated Rcpp bindings  tests/testthat/             # Unit tests ├── test-corrSelect.R ├── test-assocSelect.R ├── test-CorrCombo.R ├── test-corrMatSelect-els.R ├── test-corrMatSelect-bron-kerbosch.R └── test-corrSubset.R  vignettes/                   # Long-form documentation man/                         # Generated documentation (roxygen2) docs/                        # Generated pkgdown website claude/                      # Claude Code working files (git-ignored)                              # Store generated .md files and notes here"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"index-conversion","dir":"","previous_headings":"Important Conventions","what":"Index Conversion","title":"CLAUDE.md","text":"R layer: 1-based indexing (standard R convention) C++ layer: 0-based indexing (standard C++ convention) Conversion happens corrselect_main.cpp: subtract 1 entering C++, add 1 returning R","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"force-in-variables","dir":"","previous_headings":"Important Conventions","what":"Force-In Variables","title":"CLAUDE.md","text":"force_in parameter can : - Character vector variable names (R layer converts indices) - Numeric vector column indices (user must provide 1-based) variables appear every returned subset. converted 0-based indices passed C++.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"result-ordering","dir":"","previous_headings":"Important Conventions","what":"Result Ordering","title":"CLAUDE.md","text":"Results sorted : 1. Size (descending) - larger subsets first 2. Average absolute correlation (ascending) - lower correlation preferred happens C++ returning R.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"missing-data-handling","dir":"","previous_headings":"Important Conventions","what":"Missing Data Handling","title":"CLAUDE.md","text":"corrSelect() assocSelect() remove rows NA values computing correlation matrix. warning issued rows dropped. number rows actually used stored CorrCombo object’s n_rows_used slot.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"CLAUDE.md","text":"Keep tests fast reproducible Always use set.seed() random data Include edge cases (empty data, single variable, correlated, uncorrelated) Test algorithms (ELS Bron-Kerbosch) Test force_in functionality Test mixed-type data scenarios assocSelect tests","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"documentation-1","dir":"","previous_headings":"","what":"Documentation","title":"CLAUDE.md","text":"exported functions use roxygen2 documentation : - @param descriptions - @return type structure - @details algorithm specifics - @examples executable - @seealso cross-references Vignettes provide: - Usage examples real-world scenarios - Performance comparisons algorithms - Guidance threshold selection - Mixed-type data workflows","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Code of Conduct","text":"aim maintain open, friendly, professional environment within corrselect project. Everyone taking part (contributors, maintainers, users) feel welcome respected, regardless background, identity, experience level.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Code of Conduct","text":"Examples behavior helps create good environment: Communicating clearly respectfully open different opinions approaches Offering constructive feedback Helping others learn contribute Staying focused collaboration shared goals Examples behavior acceptable: Personal attacks insulting language Disrespectful dismissive comments Sharing private information without consent form harassment hostility toward others","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"responsibilities","dir":"","previous_headings":"","what":"Responsibilities","title":"Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior taking fair action necessary. may edit, remove, reject contributions violate Code Conduct disrupt collaboration.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Code of Conduct","text":"Code Conduct applies project spaces, including discussions, issues, pull requests, community interactions related corrselect.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Code of Conduct","text":"experience witness behavior violates Code Conduct, please contact maintainer privately. Reports handled discretion, maintainers take appropriate action needed.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, simplified better fit tone open scientific software project. Contact: gilles.colling051@gmail.com","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contribution Guidelines","title":"Contribution Guidelines","text":"First , thank much taking time contribute corrselect project! document provides guidelines contributing corrselect—codebase documentation. guidelines meant guide , restrict . doubt, use best judgment feel free propose improvements issue pull request.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table Of Contents","title":"Contribution Guidelines","text":"Code Conduct Obtaining source Setting R environment Installing source Testing Install dependencies Building documentation Design docs Project organization Contributing workflow Style guidelines Pull request checklist Reporting bugs","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contribution Guidelines","text":"project everyone participating governed Code Conduct (CODE_OF_CONDUCT.md). participating, expected uphold code maintain respectful, inclusive environment.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Contribution Guidelines","text":"installation guide focused development. regular installation, please see README.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"obtaining-the-source","dir":"","previous_headings":"Installation","what":"Obtaining the source","title":"Contribution Guidelines","text":"Clone corrselect repository: work development branch:","code":"git clone https://github.com/gcol33/corrselect.git cd corrselect git checkout dev git pull origin dev"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"setting-up-your-r-environment","dir":"","previous_headings":"Installation","what":"Setting up your R environment","title":"Contribution Guidelines","text":"corrselect R package uses C++ code via Rcpp. Install required tools R (≥ 4.0) Rtools (Windows) Xcode Command Line Tools (macOS) Git editor IDE (RStudio, VS Code, etc.) Install development dependencies Load development build","code":"install.packages(c(\"devtools\", \"roxygen2\", \"testthat\", \"rmarkdown\", \"knitr\", \"pkgdown\")) devtools::load_all()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"installing-from-source","dir":"","previous_headings":"Installation","what":"Installing from source","title":"Contribution Guidelines","text":"Build install package locally: modify C++ code, rebuild DLL reinstalling: Regenerate documentation :","code":"devtools::install() devtools::clean_dll() devtools::install() devtools::document()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"Contribution Guidelines","text":"corrselect uses testthat testing. tests located tests/testthat/. Run full test suite: Run complete package check: Run subset tests development: Guidelines: - Keep tests fast reproducible. - Use set.seed() random data. - Include edge cases expected failures. - Prefer small examples large datasets.","code":"devtools::test() devtools::check() testthat::test_dir(\"tests/testthat\") testthat::test_file(\"tests/testthat/test-corrSelect.R\")"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"install-dependencies","dir":"","previous_headings":"Documentation","what":"Install dependencies","title":"Contribution Guidelines","text":"","code":"install.packages(c(\"rmarkdown\", \"knitr\", \"pkgdown\"))"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"building-the-documentation","dir":"","previous_headings":"Documentation","what":"Building the documentation","title":"Contribution Guidelines","text":"Build vignettes: Build pkgdown site locally: generated site saved docs/ directory. Open docs/index.html browser view .","code":"devtools::build_vignettes() pkgdown::build_site()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"design-of-the-docs","dir":"","previous_headings":"Documentation","what":"Design of the docs","title":"Contribution Guidelines","text":"Function documentation: man/ (generated roxygen2) Tutorials examples: vignettes/ Website configuration: _pkgdown.yml Package overview: README.md Changelog: NEWS.md","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"project-organization","dir":"","previous_headings":"","what":"Project organization","title":"Contribution Guidelines","text":"","code":"corrselect/ ├── .github/                <- Continuous integration workflows ├── .gitignore ├── .Rbuildignore ├── corrselect.Rproj ├── DESCRIPTION             <- Package metadata ├── NAMESPACE               <- Function exports and imports ├── LICENSE ├── LICENSE.md ├── NEWS.md ├── README.md ├── _pkgdown.yml ├── R/                      <- R source files ├── src/                    <- C++ source files (Rcpp) ├── man/                    <- Generated documentation ├── inst/                   <- Installed files (e.g., CITATION, extdata) ├── vignettes/              <- Long-form documentation and usage examples ├── tests/ │   └── testthat/           <- Unit tests ├── docs/                   <- pkgdown website (generated) ├── doc/                    <- Built vignettes for local preview (ignored in Git) ├── Meta/                   <- Metadata created during package build (ignored) └── corrselect.Rcheck/      <- Artifacts from local package checks (ignored)"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"contributing-workflow","dir":"","previous_headings":"","what":"Contributing workflow","title":"Contribution Guidelines","text":"Create feature branch Make focused commits clear messages. Run tests checks committing: Update documentation roxygen2 NEWS.md. Update vignettes/examples user-facing behavior changes. Open pull request short description change. Respond review feedback constructively.","code":"git checkout -b feature/my-feature devtools::test() devtools::check()"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"r-code","dir":"","previous_headings":"Style guidelines","what":"R code","title":"Contribution Guidelines","text":"Use descriptive names consistent indentation. Prefer vectorized operations loops. Validate inputs early clear error messages. Document exported functions roxygen2.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"c-code","dir":"","previous_headings":"Style guidelines","what":"C++ code","title":"Contribution Guidelines","text":"Keep headers minimal separate interface implementation. Use RAII possible. Comment algorithmic details numerical behavior. Avoid unnecessary memory allocations.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"tests","dir":"","previous_headings":"Style guidelines","what":"Tests","title":"Contribution Guidelines","text":"Add update tests functionality changes. Keep tests minimal reproducible. Avoid external dependencies unless essential.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"pull-request-checklist","dir":"","previous_headings":"","what":"Pull request checklist","title":"Contribution Guidelines","text":"Tests pass (devtools::test() devtools::check()) Documentation updated (roxygen + NEWS.md) Vignettes/examples updated needed unrelated formatting changes PR description clearly explains change","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"reporting-bugs","dir":"","previous_headings":"","what":"Reporting bugs","title":"Contribution Guidelines","text":"reporting issue, please include: - minimal reproducible example (reprex) - Output sessionInfo() - Expected vs. actual results - Threshold method used (e.g., \"els\" \"bron-kerbosch\") - R operating system version - Toolchain info relevant (e.g., Rtools Windows) contributing corrselect, agree code released license package.","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"corrselect","dir":"","previous_headings":"","what":"Correlation-Based and Model-Based Predictor Pruning","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Fast Flexible Predictor Pruning Data Analysis Modeling corrselect package provides simple, high-level functions predictor pruning using association-based model-based approaches. Whether need reduce multicollinearity modeling clean correlated predictors dataset, corrselect offers fast, deterministic solutions minimal code.","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"library(corrselect) data(mtcars)  # Association-based pruning (model-free) pruned <- corrPrune(mtcars, threshold = 0.7) names(pruned)  # Model-based pruning (VIF) pruned <- modelPrune(mpg ~ ., data = mtcars, limit = 5) attr(pruned, \"selected_vars\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"statement-of-need","dir":"","previous_headings":"","what":"Statement of Need","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Variable selection central task statistics machine learning, particularly working high-dimensional collinear data. many applications, users aim retain sets variables weakly associated one another avoid redundancy reduce overfitting. Common approaches greedy filtering regularized regression either discard useful features guarantee bounded pairwise associations. package addresses admissible set problem: selecting maximal subsets variables pair exceeds user-defined threshold. generalizes mixed-type data, supports multiple association metrics, allows constrained subset selection via force_in (e.g. always include key predictors). features make package useful domains like: ecological bioclimatic modeling, trait-based species selection, interpretable machine learning pipelines.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"high-level-pruning-functions","dir":"","previous_headings":"Features","what":"High-Level Pruning Functions","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Model-free, works raw data Automatic correlation/association measure selection Fast greedy mode large datasets (p > 100) Exact mode guaranteed optimal solutions (p ≤ 20) Protect important variables force_in VIF-based iterative removal Supports lm, glm, lme4, glmmTMB engines Custom engine support modeling package (INLA, mgcv, brms, etc.) Prunes fixed effects mixed models Returns fitted model pruned predictors","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"advanced-subset-enumeration","dir":"","previous_headings":"Features","what":"Advanced Subset Enumeration","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Eppstein–Löffler–Strash (ELS) Bron–Kerbosch (optional pivoting) Used internally corrPrune(mode = \"exact\") \"pearson\", \"spearman\", \"kendall\" \"bicor\" (WGCNA), \"distance\" (energy), \"maximal\" (minerva) \"eta\", \"cramersv\" mixed-type data force_in: protect variables removal Deterministic tie-breaking reproducibility","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Install from GitHub remotes::install_github(\"gcol33/corrselect\")"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"association-based-pruning-corrprune","dir":"","previous_headings":"Usage Examples","what":"Association-Based Pruning (corrPrune)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"library(corrselect) data(mtcars)  # Basic: Remove correlated predictors pruned <- corrPrune(mtcars, threshold = 0.7) names(pruned)  # Protect important variables pruned <- corrPrune(mtcars, threshold = 0.7, force_in = \"mpg\")  # Use exact mode (slower, guaranteed optimal) pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"exact\")  # Use greedy mode (faster for large datasets) pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\")  # Check what was removed attr(pruned, \"selected_vars\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"model-based-pruning-modelprune","dir":"","previous_headings":"Usage Examples","what":"Model-Based Pruning (modelPrune)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Linear model with VIF threshold pruned <- modelPrune(mpg ~ cyl + disp + hp + wt, data = mtcars, limit = 5) attr(pruned, \"removed_vars\")  # GLM with binomial family mtcars$am_binary <- as.factor(mtcars$am) pruned <- modelPrune(am_binary ~ cyl + disp + hp,                      data = mtcars, engine = \"glm\",                      family = binomial(), limit = 5)  # Mixed model (requires lme4) if (requireNamespace(\"lme4\", quietly = TRUE)) {   df <- data.frame(     y = rnorm(100),     x1 = rnorm(100),     x2 = rnorm(100),     group = rep(1:10, each = 10)   )   pruned <- modelPrune(y ~ x1 + x2 + (1|group),                        data = df, engine = \"lme4\", limit = 5) }  # Custom engine (advanced: works with any modeling package) # Example: INLA-based pruning if (requireNamespace(\"INLA\", quietly = TRUE)) {   inla_engine <- list(     name = \"inla\",     fit = function(formula, data, ...) {       INLA::inla(formula = formula, data = data,                  family = \"gaussian\", ...)     },     diagnostics = function(model, fixed_effects) {       # Use posterior SD as badness metric       scores <- model$summary.fixed[, \"sd\"]       names(scores) <- rownames(model$summary.fixed)       scores[fixed_effects]     }   )    pruned <- modelPrune(y ~ x1 + x2, data = df,                        engine = inla_engine, limit = 0.5) }"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"exact-subset-enumeration-advanced","dir":"","previous_headings":"Usage Examples","what":"Exact Subset Enumeration (Advanced)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Find ALL maximal subsets res <- corrSelect(mtcars, threshold = 0.7) show(res)  # Extract a specific subset subset1 <- corrSubset(res, mtcars, which = 1)  # Convert to data frame as.data.frame(res)"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"choosing-between-corrprune-and-modelprune","dir":"","previous_headings":"","what":"Choosing Between corrPrune and modelPrune","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Tip: Use corrPrune() first reduce dimensionality, modelPrune() final cleanup within modeling framework.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"mixed-type-data","dir":"","previous_headings":"Advanced Features","what":"Mixed-Type Data","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Use assocSelect() exact enumeration mixed data types:","code":"df <- data.frame(   height = rnorm(30, 170, 10),   weight = rnorm(30, 70, 12),   group  = factor(sample(c(\"A\",\"B\"), 30, TRUE)),   rating = ordered(sample(c(\"low\",\"med\",\"high\"), 30, TRUE)) )  res <- assocSelect(df, threshold = 0.6) show(res)"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"precomputed-correlation-matrices","dir":"","previous_headings":"Advanced Features","what":"Precomputed Correlation Matrices","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Work directly correlation matrices:","code":"mat <- cor(mtcars) res <- MatSelect(mat, threshold = 0.7, method = \"els\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"joss-paper","dir":"","previous_headings":"","what":"JOSS Paper","title":"Correlation-Based and Model-Based Predictor Pruning","text":"repository includes short paper prepared submission Journal Open Source Software (JOSS). can find manuscript references paper/ directory: paper/paper.md – main text paper/paper.bib – bibliography","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Correlation-Based and Model-Based Predictor Pruning","text":"MIT (see LICENSE.md file)","code":""},{"path":"https://gcol33.github.io/corrselect/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Gilles Colling Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"Converts CorrCombo object data frame variable combinations.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"","code":"# S3 method for class 'CorrCombo' as.data.frame(x, row.names = NULL, optional = FALSE, ...)"},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"x CorrCombo object. row.names Optional row names output data frame. optional Logical. Passed data.frame(). ... Additional arguments passed data.frame().","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"data frame row corresponds subset variables. Columns named VarName01, VarName02, ..., size largest subset. Subsets shorter maximum length padded NA.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"","code":"set.seed(1) mat <- matrix(rnorm(100), ncol = 10) colnames(mat) <- paste0(\"V\", 1:10) res <- corrSelect(cor(mat), threshold = 0.5) as.data.frame(res) #>                      VarName01 VarName02 VarName03 #> Subset01 [avg=0.261]        V3        V7       V10 #> Subset02 [avg=0.295]        V1        V7       V10 #> Subset03 [avg=0.300]        V8        V9       V10 #> Subset04 [avg=0.331]        V2        V7       V10 #> Subset05 [avg=0.343]        V9        V7       V10 #> Subset06 [avg=0.350]        V3        V8       V10 #> Subset07 [avg=0.374]        V2        V8       V10 #> Subset08 [avg=0.384]        V6        V7       V10 #> Subset09 [avg=0.388]        V6        V8       V10 #> Subset10 [avg=0.086]        V3        V4      <NA> #> Subset11 [avg=0.098]        V5        V8      <NA> #> Subset12 [avg=0.208]        V1        V4      <NA> #> Subset13 [avg=0.220]        V2        V4      <NA> #> Subset14 [avg=0.295]        V9        V4      <NA> #> Subset15 [avg=0.319]        V6        V4      <NA> #> Subset16 [avg=0.407]        V5        V7      <NA>"},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"Identifies combinations variables common data type (numeric, ordered factors, unordered) factors—whose pair-wise association exceed user-supplied threshold. routine wraps MatSelect() handles pre-processing (type conversion, missing-row removal, constant-column checks) typical data-frame/tibble/data-table inputs.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"","code":"assocSelect(   df,   threshold = 0.7,   method = NULL,   force_in = NULL,   method_num_num = c(\"pearson\", \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\"),   method_num_ord = c(\"spearman\", \"kendall\"),   method_ord_ord = c(\"spearman\", \"kendall\"),   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"df data frame (tibble / data.table). May contain mix : numeric / integer (treated numeric) ordered factors unordered factors (character vectors coerced factors) threshold Numeric \\((0,1)\\). Maximum allowed pair-wise absolute association. Default 0.7. method Character; subset-search algorithm. One \"els\" \"bron-kerbosch\".  NULL (default) function selects automatically: ELS force_in supplied, otherwise Bron–Kerbosch. force_in Optional character vector column indices specifying variables must appear every returned subset. method_num_num Association measure numeric–numeric pairs. One \"pearson\" (default), \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\". method_num_ord Association measure numeric–ordered pairs. One \"spearman\" (default) \"kendall\". method_ord_ord Association measure ordered–ordered pairs. One \"spearman\" (default) \"kendall\". ... Additional arguments passed unchanged MatSelect() (e.g., use_pivot = TRUE Bron–Kerbosch).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"CorrCombo S4 object containing: valid subsets, summary association statistics, metadata (algorithm used, rows kept, forced-variables, etc.). object’s show() method prints association metrics actually used data set.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"single call can therefore screen data set mixes continuous categorical features return every subset whose internal associations “sufficiently low” metric(s) choose. Rows containing NA dropped warning; constant columns treated zero association every variable. default association measure variable-type combination : numeric – numeric method_num_num (default \"pearson\") numeric – ordered method_num_ord numeric – unordered \"eta\" (ANOVA \\(\\eta^{2}\\)) ordered – ordered method_ord_ord ordered – unordered \"cramersv\" unordered – unordered \"cramersv\" association measures rescaled \\([0,1]\\) thresholding. External packages required \"bicor\" (WGCNA), \"distance\" (energy), \"maximal\" (minerva); informative error thrown missing.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"","code":"set.seed(42) df <- data.frame(   height = rnorm(15, 170, 10),   weight = rnorm(15, 70, 12),   group  = factor(rep(LETTERS[1:3], each = 5)),   score  = ordered(sample(c(\"low\",\"med\",\"high\"), 15, TRUE)) )  ## keep every subset whose internal associations <= 0.6 assocSelect(df, threshold = 0.6) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.600 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.186  0.475     4  ## use Kendall for all rank-based comparisons and force 'height' to appear assocSelect(df,             threshold       = 0.5,             method_num_num  = \"kendall\",             method_num_ord  = \"kendall\",             method_ord_ord  = \"kendall\",             force_in        = \"height\") #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: mixed #>   AssocMethod: numeric_numeric = kendall, numeric_factor = eta, numeric_ordered #>                = kendall, factor_ordered = cramersv #>   Threshold:   0.500 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Forced-in:   height #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.159  0.365     4"},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"simulated dataset 19 WorldClim bioclimatic variables (https://www.worldclim.org/data/bioclim.html) measured 100 geographic locations, species richness response variable. Variables organized correlated blocks representing temperature (BIO1-BIO11) precipitation (BIO12-BIO19).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"","code":"bioclim_example"},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"data frame 100 rows 20 variables: species_richness Integer. Number species observed (response variable) BIO1 Numeric. Annual Mean Temperature BIO2 Numeric. Mean Diurnal Range BIO3 Numeric. Isothermality BIO4 Numeric. Temperature Seasonality BIO5 Numeric. Max Temperature Warmest Month BIO6 Numeric. Min Temperature Coldest Month BIO7 Numeric. Temperature Annual Range BIO8 Numeric. Mean Temperature Wettest Quarter BIO9 Numeric. Mean Temperature Driest Quarter BIO10 Numeric. Mean Temperature Warmest Quarter BIO11 Numeric. Mean Temperature Coldest Quarter BIO12 Numeric. Annual Precipitation BIO13 Numeric. Precipitation Wettest Month BIO14 Numeric. Precipitation Driest Month BIO15 Numeric. Precipitation Seasonality BIO16 Numeric. Precipitation Wettest Quarter BIO17 Numeric. Precipitation Driest Quarter BIO18 Numeric. Precipitation Warmest Quarter BIO19 Numeric. Precipitation Coldest Quarter","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"Simulated data based 19 WorldClim bioclimatic variables","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"dataset demonstrates common problem ecological modeling: bioclimatic predictors highly correlated within groups (temperature variables BIO1-BIO11 highly correlated; precipitation variables BIO12-BIO19 moderately correlated), leading multicollinearity issues. species richness response depends subset predictors. Use case: Demonstrating corrPrune() modelPrune() reducing correlated environmental predictors fitting species distribution models.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"","code":"data(bioclim_example) #> Warning: data set 'bioclim_example' not found  # The 19 WorldClim bioclimatic variables (https://www.worldclim.org/data/bioclim.html) # Many are highly correlated, making them ideal for pruning  # Remove highly correlated variables pruned <- corrPrune(bioclim_example[, -1], threshold = 0.7) #> Error in corrPrune(bioclim_example[, -1], threshold = 0.7): could not find function \"corrPrune\" ncol(pruned)  # Reduced from 19 to ~8 variables #> Error: object 'pruned' not found  # Model-based pruning with VIF model_data <- modelPrune(species_richness ~ .,                          data = bioclim_example,                          limit = 5) #> Error in modelPrune(species_richness ~ ., data = bioclim_example, limit = 5): could not find function \"modelPrune\" attr(model_data, \"selected_vars\") #> Error: object 'model_data' not found"},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":null,"dir":"Reference","previous_headings":"","what":"CorrCombo S4 class — CorrCombo","title":"CorrCombo S4 class — CorrCombo","text":"Holds result corrSelect MatSelect: list valid variable combinations correlation statistics. class stores subsets variables meet specified correlation constraint, along metadata algorithm used, correlation method(s), variables forced every subset, summary statistics combination.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CorrCombo S4 class — CorrCombo","text":"","code":"# S4 method for class 'CorrCombo' show(object)"},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CorrCombo S4 class — CorrCombo","text":"object CorrCombo object printed.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"CorrCombo S4 class — CorrCombo","text":"subset_list list character vectors. vector valid subset (variable names). avg_corr numeric vector. Average absolute correlation within subset. min_corr numeric vector. Minimum pairwise absolute correlation subset. max_corr numeric vector. Maximum pairwise absolute correlation within subset. names Character vector variable names used decoding. threshold Numeric scalar. correlation threshold used selection. forced_in Character vector. Variable names forced subset. search_type Character string. One \"els\" \"bron-kerbosch\". cor_method Character string. Either single method (e.g. \"pearson\") \"mixed\" multiple methods used. n_rows_used Integer. Number rows used computing correlation matrix (removing missing values).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CorrCombo S4 class — CorrCombo","text":"","code":"show(new(\"CorrCombo\",   subset_list = list(c(\"A\", \"B\"), c(\"A\", \"C\")),   avg_corr = c(0.2, 0.3),   min_corr = c(0.1, 0.2),   max_corr = c(0.3, 0.4),   names = c(\"A\", \"B\", \"C\"),   threshold = 0.5,   forced_in = character(),   search_type = \"els\",   cor_method = \"mixed\",   n_rows_used = as.integer(5) )) #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: mixed #>   Threshold:   0.500 #>   Subsets:     2 valid combinations #>   Data Rows:   5 used in correlation #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B                              0.200  0.300     2 #>   [ 2] A, C                              0.300  0.400     2"},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":null,"dir":"Reference","previous_headings":"","what":"Association-Based Predictor Pruning — corrPrune","title":"Association-Based Predictor Pruning — corrPrune","text":"corrPrune() performs model-free variable subset selection iteratively removing predictors pairwise associations fall specified threshold. returns single pruned data frame predictors satisfy association constraint.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Association-Based Predictor Pruning — corrPrune","text":"","code":"corrPrune(   data,   threshold = 0.7,   measure = \"auto\",   mode = \"auto\",   force_in = NULL,   by = NULL,   group_q = 1,   max_exact_p = 20,   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Association-Based Predictor Pruning — corrPrune","text":"data data.frame containing candidate predictors. threshold Numeric scalar. Maximum allowed pairwise association (default: 0.7). Must non-negative. measure Character string specifying association measure use. Options: \"auto\" (default), \"pearson\", \"spearman\", \"kendall\", \"cramersv\", \"eta\", etc. \"auto\", Pearson correlation used -numeric data, appropriate measures selected mixed-type data. mode Character string specifying search algorithm. Options: \"auto\" (default): uses exact search number predictors ≤ max_exact_p, otherwise uses greedy search \"exact\": exhaustive search maximal subsets (may slow large p) \"greedy\": fast approximate search using iterative removal force_in Character vector variable names must retained final subset. Default: NULL. Character vector naming one grouping variables. provided, associations computed separately within group, aggregated using quantile specified group_q. Default: NULL (grouping). group_q Numeric scalar (0, 1]. Quantile used aggregate associations across groups provided. Default: 1 (maximum, ensuring threshold holds groups). Use 0.9 90th percentile, etc. max_exact_p Integer. Maximum number predictors exact mode used mode = \"auto\". Default: 20. ... Additional arguments (reserved future use).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Association-Based Predictor Pruning — corrPrune","text":"data.frame containing pruned subset predictors. result following attributes: selected_vars Character vector retained variable names mode Character string indicating mode used (\"exact\" \"greedy\") measure Character string indicating association measure used threshold threshold value used","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Association-Based Predictor Pruning — corrPrune","text":"corrPrune() identifies subset predictors whose pairwise associations threshold. function works several stages: Variable type detection: Identifies numeric vs. categorical predictors Association measurement: Computes appropriate pairwise associations Grouping (optional): specified, computes associations within group aggregates using specified quantile Feasibility check: Verifies force_in variables satisfy threshold constraint Subset selection: Uses either exact greedy search find valid subset Grouped Pruning: provided, function ensures selected predictors satisfy threshold constraint across groups. example, group_q = 1 (default), returned predictors pairwise associations threshold groups. group_q = 0.9, satisfy constraint least 90% groups. Mode Selection: Exact mode guarantees finding maximal subsets returns largest one (deterministic tie-breaking). Greedy mode faster approximate, using deterministic removal strategy based association scores.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Association-Based Predictor Pruning — corrPrune","text":"","code":"# Basic numeric data pruning data(mtcars) pruned <- corrPrune(mtcars, threshold = 0.7) #> Error in corrPrune(mtcars, threshold = 0.7): could not find function \"corrPrune\" names(pruned) #> Error: object 'pruned' not found  # Force certain variables to be included pruned <- corrPrune(mtcars, threshold = 0.7, force_in = \"mpg\") #> Error in corrPrune(mtcars, threshold = 0.7, force_in = \"mpg\"): could not find function \"corrPrune\"  # Use greedy mode for faster computation pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\") #> Error in corrPrune(mtcars, threshold = 0.7, mode = \"greedy\"): could not find function \"corrPrune\""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"Identifies combinations numeric variables data frame pairwise absolute correlations fall specified threshold. function wrapper around MatSelect() accepts data frames, tibbles, data tables automatic preprocessing.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"","code":"corrSelect(   df,   threshold = 0.7,   method = NULL,   force_in = NULL,   cor_method = c(\"pearson\", \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\"),   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"df data frame. numeric columns used. threshold numeric value (0, 1). Maximum allowed absolute correlation. Defaults 0.7. method Character. Selection algorithm use. One \"els\" \"bron-kerbosch\". specified, function chooses automatically: \"els\" force_in provided, otherwise \"bron-kerbosch\". force_in Optional character vector numeric indices columns force subsets. cor_method Character string indicating correlation method use. One \"pearson\" (default), \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\". ... Additional arguments passed MatSelect(), e.g., use_pivot.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"object class CorrCombo, containing selected subsets correlation statistics.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"numeric columns used correlation analysis. Non‐numeric columns (factors, characters, logicals, etc.) ignored, names types printed inform user. can optionally reattached later using corrSubset() keepExtra = TRUE. Rows missing values removed computing correlations. warning issued rows dropped. cor_method controls correlation matrix computed: \"pearson\": Standard linear correlation. \"spearman\": Rank-based monotonic correlation. \"kendall\": Kendall's tau. \"bicor\": Biweight midcorrelation (WGCNA::bicor). \"distance\": Distance correlation (energy::dcor). \"maximal\": Maximal information coefficient (minerva::mine). \"bicor\", \"distance\", \"maximal\", corresponding package must installed.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"","code":"set.seed(42) n <- 100  # Create 20 variables: 5 blocks of correlated variables + some noise block1 <- matrix(rnorm(n * 4), ncol = 4) block2 <- matrix(rnorm(n), ncol = 1) block2 <- matrix(rep(block2, 4), ncol = 4) + matrix(rnorm(n * 4, sd = 0.1), ncol = 4) block3 <- matrix(rnorm(n * 4), ncol = 4) block4 <- matrix(rnorm(n * 4), ncol = 4) block5 <- matrix(rnorm(n * 4), ncol = 4)  df <- as.data.frame(cbind(block1, block2, block3, block4, block5)) colnames(df) <- paste0(\"V\", 1:20)  # Add a non-numeric column to be ignored df$label <- factor(sample(c(\"A\", \"B\"), n, replace = TRUE))  # Basic usage corrSelect(df, threshold = 0.8) #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.800 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.075  0.241    17 #>   [ 2] V1, V2, V3, V4, V6, V9, ...       0.075  0.259    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.075  0.269    17 #>   [ 4] V1, V2, V3, V4, V5, V9, ...       0.076  0.288    17  # Try Bron–Kerbosch with pivoting corrSelect(df, threshold = 0.6, method = \"bron-kerbosch\", use_pivot = TRUE) #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.600 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.075  0.241    17 #>   [ 2] V1, V2, V3, V4, V6, V9, ...       0.075  0.259    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.075  0.269    17 #>   [ 4] V1, V2, V3, V4, V5, V9, ...       0.076  0.288    17  # Force in a specific variable and use Spearman correlation corrSelect(df, threshold = 0.6, force_in = \"V10\", cor_method = \"spearman\") #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: spearman #>   Threshold:   0.600 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Forced-in:   V10 #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.076  0.239    17 #>   [ 2] V1, V2, V3, V4, V5, V9, ...       0.076  0.269    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.076  0.246    17 #>   [ 4] V1, V2, V3, V4, V6, V9, ...       0.076  0.252    17"},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Variable Subsets from a CorrCombo Object — corrSubset","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"Extracts one variable subsets CorrCombo object data frames. Typically used corrSelect MatSelect obtain filtered versions original dataset containing low‐correlation variable combinations.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"","code":"corrSubset(res, df, which = \"best\", keepExtra = FALSE)"},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"res CorrCombo object returned corrSelect MatSelect. df data frame matrix. Must contain variables listed res@names. Columns res@names ignored unless keepExtra = TRUE. Subsets extract. One : \"best\" (default) 1: top‐ranked subset. single integer (e.g. 2): nth ranked subset. vector integers (e.g. 1:3): multiple subsets. \"\": available subsets. Subsets ranked decreasing size, increasing average correlation. keepExtra Logical. TRUE, columns df res@names (e.g., factors, characters) retained. Defaults FALSE.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"data frame single subset extracted, list data frames multiple subsets extracted. data frame contains selected variables (optionally extras).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"warning issued rows contain missing values selected variables.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"","code":"# Simulate input data set.seed(123) df <- as.data.frame(matrix(rnorm(100), nrow = 10)) colnames(df) <- paste0(\"V\", 1:10)  # Compute correlation matrix cmat <- cor(df)  # Select subsets using corrSelect res <- corrSelect(cmat, threshold = 0.5)  # Extract the best subset (default) corrSubset(res, df) #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469  # Extract the second-best subset corrSubset(res, df, which = 2) #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469  # Extract the first three subsets corrSubset(res, df, which = 1:3) #> $Subset1 #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset2 #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset3 #>            V2          V5          V6          V7 #> 1   1.2240818 -0.69470698  0.25331851  0.37963948 #> 2   0.3598138 -0.20791728 -0.02854676 -0.50232345 #> 3   0.4007715 -1.26539635 -0.04287046 -0.33320738 #> 4   0.1106827  2.16895597  1.36860228 -1.01857538 #> 5  -0.5558411  1.20796200 -0.22577099 -1.07179123 #> 6   1.7869131 -1.12310858  1.51647060  0.30352864 #> 7   0.4978505 -0.40288484 -1.54875280  0.44820978 #> 8  -1.9666172 -0.46665535  0.58461375  0.05300423 #> 9   0.7013559  0.77996512  0.12385424  0.92226747 #> 10 -0.4727914 -0.08336907  0.21594157  2.05008469 #>   # Extract all subsets corrSubset(res, df, which = \"all\") #> $Subset1 #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset2 #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset3 #>            V2          V5          V6          V7 #> 1   1.2240818 -0.69470698  0.25331851  0.37963948 #> 2   0.3598138 -0.20791728 -0.02854676 -0.50232345 #> 3   0.4007715 -1.26539635 -0.04287046 -0.33320738 #> 4   0.1106827  2.16895597  1.36860228 -1.01857538 #> 5  -0.5558411  1.20796200 -0.22577099 -1.07179123 #> 6   1.7869131 -1.12310858  1.51647060  0.30352864 #> 7   0.4978505 -0.40288484 -1.54875280  0.44820978 #> 8  -1.9666172 -0.46665535  0.58461375  0.05300423 #> 9   0.7013559  0.77996512  0.12385424  0.92226747 #> 10 -0.4727914 -0.08336907  0.21594157  2.05008469 #>  #> $Subset4 #>             V1          V5          V6          V7 #> 1  -0.56047565 -0.69470698  0.25331851  0.37963948 #> 2  -0.23017749 -0.20791728 -0.02854676 -0.50232345 #> 3   1.55870831 -1.26539635 -0.04287046 -0.33320738 #> 4   0.07050839  2.16895597  1.36860228 -1.01857538 #> 5   0.12928774  1.20796200 -0.22577099 -1.07179123 #> 6   1.71506499 -1.12310858  1.51647060  0.30352864 #> 7   0.46091621 -0.40288484 -1.54875280  0.44820978 #> 8  -1.26506123 -0.46665535  0.58461375  0.05300423 #> 9  -0.68685285  0.77996512  0.12385424  0.92226747 #> 10 -0.44566197 -0.08336907  0.21594157  2.05008469 #>  #> $Subset5 #>             V4          V5        V10 #> 1   0.42646422 -0.69470698  0.9935039 #> 2  -0.29507148 -0.20791728  0.5483970 #> 3   0.89512566 -1.26539635  0.2387317 #> 4   0.87813349  2.16895597 -0.6279061 #> 5   0.82158108  1.20796200  1.3606524 #> 6   0.68864025 -1.12310858 -0.6002596 #> 7   0.55391765 -0.40288484  2.1873330 #> 8  -0.06191171 -0.46665535  1.5326106 #> 9  -0.30596266  0.77996512 -0.2357004 #> 10 -0.38047100 -0.08336907 -1.0264209 #>  #> $Subset6 #>              V9          V5        V10 #> 1   0.005764186 -0.69470698  0.9935039 #> 2   0.385280401 -0.20791728  0.5483970 #> 3  -0.370660032 -1.26539635  0.2387317 #> 4   0.644376549  2.16895597 -0.6279061 #> 5  -0.220486562  1.20796200  1.3606524 #> 6   0.331781964 -1.12310858 -0.6002596 #> 7   1.096839013 -0.40288484  2.1873330 #> 8   0.435181491 -0.46665535  1.5326106 #> 9  -0.325931586  0.77996512 -0.2357004 #> 10  1.148807618 -0.08336907 -1.0264209 #>  #> $Subset7 #>            V3          V5        V10 #> 1  -1.0678237 -0.69470698  0.9935039 #> 2  -0.2179749 -0.20791728  0.5483970 #> 3  -1.0260044 -1.26539635  0.2387317 #> 4  -0.7288912  2.16895597 -0.6279061 #> 5  -0.6250393  1.20796200  1.3606524 #> 6  -1.6866933 -1.12310858 -0.6002596 #> 7   0.8377870 -0.40288484  2.1873330 #> 8   0.1533731 -0.46665535  1.5326106 #> 9  -1.1381369  0.77996512 -0.2357004 #> 10  1.2538149 -0.08336907 -1.0264209 #>  #> $Subset8 #>             V4          V5          V6 #> 1   0.42646422 -0.69470698  0.25331851 #> 2  -0.29507148 -0.20791728 -0.02854676 #> 3   0.89512566 -1.26539635 -0.04287046 #> 4   0.87813349  2.16895597  1.36860228 #> 5   0.82158108  1.20796200 -0.22577099 #> 6   0.68864025 -1.12310858  1.51647060 #> 7   0.55391765 -0.40288484 -1.54875280 #> 8  -0.06191171 -0.46665535  0.58461375 #> 9  -0.30596266  0.77996512  0.12385424 #> 10 -0.38047100 -0.08336907  0.21594157 #>  #> $Subset9 #>            V8          V6          V7 #> 1  -0.4910312  0.25331851  0.37963948 #> 2  -2.3091689 -0.02854676 -0.50232345 #> 3   1.0057385 -0.04287046 -0.33320738 #> 4  -0.7092008  1.36860228 -1.01857538 #> 5  -0.6880086 -0.22577099 -1.07179123 #> 6   1.0255714  1.51647060  0.30352864 #> 7  -0.2847730 -1.54875280  0.44820978 #> 8  -1.2207177  0.58461375  0.05300423 #> 9   0.1813035  0.12385424  0.92226747 #> 10 -0.1388914  0.21594157  2.05008469 #>  #> $Subset10 #>              V9          V5          V6 #> 1   0.005764186 -0.69470698  0.25331851 #> 2   0.385280401 -0.20791728 -0.02854676 #> 3  -0.370660032 -1.26539635 -0.04287046 #> 4   0.644376549  2.16895597  1.36860228 #> 5  -0.220486562  1.20796200 -0.22577099 #> 6   0.331781964 -1.12310858  1.51647060 #> 7   1.096839013 -0.40288484 -1.54875280 #> 8   0.435181491 -0.46665535  0.58461375 #> 9  -0.325931586  0.77996512  0.12385424 #> 10  1.148807618 -0.08336907  0.21594157 #>   # Extract best subset and retain additional numeric column df$CopyV1 <- df$V1 corrSubset(res, df, which = 1, keepExtra = TRUE) #>            V2          V5        V10          V7      CopyV1 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 -0.56047565 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 -0.23017749 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738  1.55870831 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538  0.07050839 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123  0.12928774 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864  1.71506499 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978  0.46091621 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 -1.26506123 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 -0.68685285 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 -0.44566197"},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Gene Expression Data for Bioinformatics — genes_example","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"simulated gene expression dataset 200 genes measured across 100 samples, organized co-expression modules binary disease outcome.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"","code":"genes_example"},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"data frame 100 rows 202 variables: sample_id Character. Unique sample identifier disease_status Factor. Disease status (Healthy, Disease) GENE001, GENE002, GENE003, GENE004, GENE005, GENE006, GENE007, GENE008, GENE009, GENE010, GENE011, GENE012, GENE013, GENE014, GENE015, GENE016, GENE017, GENE018, GENE019, GENE020, GENE021, GENE022, GENE023, GENE024, GENE025, GENE026, GENE027, GENE028, GENE029, GENE030, GENE031, GENE032, GENE033, GENE034, GENE035, GENE036, GENE037, GENE038, GENE039, GENE040, GENE041, GENE042, GENE043, GENE044, GENE045, GENE046, GENE047, GENE048, GENE049, GENE050, GENE051, GENE052, GENE053, GENE054, GENE055, GENE056, GENE057, GENE058, GENE059, GENE060, GENE061, GENE062, GENE063, GENE064, GENE065, GENE066, GENE067, GENE068, GENE069, GENE070, GENE071, GENE072, GENE073, GENE074, GENE075, GENE076, GENE077, GENE078, GENE079, GENE080, GENE081, GENE082, GENE083, GENE084, GENE085, GENE086, GENE087, GENE088, GENE089, GENE090, GENE091, GENE092, GENE093, GENE094, GENE095, GENE096, GENE097, GENE098, GENE099, GENE100, GENE101, GENE102, GENE103, GENE104, GENE105, GENE106, GENE107, GENE108, GENE109, GENE110, GENE111, GENE112, GENE113, GENE114, GENE115, GENE116, GENE117, GENE118, GENE119, GENE120, GENE121, GENE122, GENE123, GENE124, GENE125, GENE126, GENE127, GENE128, GENE129, GENE130, GENE131, GENE132, GENE133, GENE134, GENE135, GENE136, GENE137, GENE138, GENE139, GENE140, GENE141, GENE142, GENE143, GENE144, GENE145, GENE146, GENE147, GENE148, GENE149, GENE150, GENE151, GENE152, GENE153, GENE154, GENE155, GENE156, GENE157, GENE158, GENE159, GENE160, GENE161, GENE162, GENE163, GENE164, GENE165, GENE166, GENE167, GENE168, GENE169, GENE170, GENE171, GENE172, GENE173, GENE174, GENE175, GENE176, GENE177, GENE178, GENE179, GENE180, GENE181, GENE182, GENE183, GENE184, GENE185, GENE186, GENE187, GENE188, GENE189, GENE190, GENE191, GENE192, GENE193, GENE194, GENE195, GENE196, GENE197, GENE198, GENE199, GENE200 Numeric. Gene expression values (log-transformed)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"Simulated data based typical gene expression microarray structures","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"dataset simulates high-dimensional, low-sample scenario common genomics. Genes organized four co-expression modules: Module 1 (GENE001-GENE050): Highly correlated (r ≈ 0.80), disease-associated Module 2 (GENE051-GENE100): Moderately correlated (r ≈ 0.60) Module 3 (GENE101-GENE150): Weakly correlated (r ≈ 0.40) Module 4 (GENE151-GENE200): Independent (r ≈ 0) Disease outcome depends subset genes Module 1. Use case: Demonstrating corrPrune() mode = \"greedy\" handling high-dimensional data efficiently.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"","code":"data(genes_example) #> Warning: data set 'genes_example' not found  # Greedy pruning for high-dimensional data gene_data <- genes_example[, -(1:2)]  # Exclude ID and outcome #> Error: object 'genes_example' not found pruned <- corrPrune(gene_data, threshold = 0.8, mode = \"greedy\") #> Error in corrPrune(gene_data, threshold = 0.8, mode = \"greedy\"): could not find function \"corrPrune\" ncol(pruned)  # Reduced from 200 to ~50 genes #> Error: object 'pruned' not found  # Use pruned genes for classification pruned_with_outcome <- data.frame(   disease_status = genes_example$disease_status,   pruned ) #> Error: object 'genes_example' not found"},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Longitudinal Data for Clinical Research — longitudinal_example","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"simulated longitudinal study dataset 50 subjects measured 10 timepoints , 20 correlated predictors nested random effects (subject site).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"","code":"longitudinal_example"},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"data frame 500 rows 25 variables: obs_id Integer. Observation identifier (1-500) subject Factor. Subject identifier (1-50) site Factor. Study site identifier (1-5) time Integer. Measurement timepoint (1-10) outcome Numeric. Continuous outcome variable x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20 Numeric. Correlated predictor variables","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"Simulated data based typical clinical trial designs","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"dataset represents typical longitudinal study repeated measures. Predictors correlated within subjects: Predictors x1-x10: Highly correlated (r ≈ 0.75) Predictors x11-x20: Moderately correlated (r ≈ 0.50) outcome depends time (linear trend), random effects (subject site), subset fixed-effect predictors (x1, x5, x15). Use case: Demonstrating modelPrune() mixed models (lme4 engine) prune fixed effects preserving random effects structure.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"","code":"data(longitudinal_example) #> Warning: data set 'longitudinal_example' not found  if (FALSE) { # \\dontrun{ # Prune fixed effects in mixed model (requires lme4) if (requireNamespace(\"lme4\", quietly = TRUE)) {   pruned <- modelPrune(     outcome ~ x1 + x2 + x3 + x4 + x5 + (1|subject) + (1|site),     data = longitudinal_example,     engine = \"lme4\",     limit = 5   )    # Random effects preserved, only fixed effects pruned   attr(pruned, \"selected_vars\") } } # }"},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"Identifies maximal subsets variables symmetric matrix (typically correlation matrix) pairwise absolute values stay specified threshold. Implements exact algorithms Eppstein–Löffler–Strash (ELS) Bron–Kerbosch (without pivoting).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"","code":"MatSelect(mat, threshold = 0.7, method = NULL, force_in = NULL, ...)"},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"mat numeric, symmetric matrix 1s diagonal (e.g. correlation matrix). Column names (present) used label output variables. threshold numeric scalar (0, 1). Maximum allowed absolute pairwise value. Defaults 0.7. method Character. Selection algorithm use. One \"els\" \"bron-kerbosch\". specified, function chooses automatically: \"els\" force_in provided, otherwise \"bron-kerbosch\". force_in Optional integer vector 1-based column indices force every subset. ... Additional arguments passed backend, e.g., use_pivot (logical) enabling pivoting Bron–Kerbosch (ignored ELS).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"object class CorrCombo, containing valid subsets correlation statistics.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"","code":"set.seed(42) mat <- matrix(rnorm(100), ncol = 10) colnames(mat) <- paste0(\"V\", 1:10) cmat <- cor(mat)  # Default method (Bron-Kerbosch) res1 <- MatSelect(cmat, threshold = 0.5)  # Bron–Kerbosch without pivot res2 <- MatSelect(cmat, threshold = 0.5, method = \"bron-kerbosch\", use_pivot = FALSE)  # Bron–Kerbosch with pivoting res3 <- MatSelect(cmat, threshold = 0.5, method = \"bron-kerbosch\", use_pivot = TRUE)  # Force variable 1 into every subset (with warning if too correlated) res4 <- MatSelect(cmat, threshold = 0.5, force_in = 1)"},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-Based Predictor Pruning — modelPrune","title":"Model-Based Predictor Pruning — modelPrune","text":"modelPrune() performs iterative removal fixed-effect predictors based model diagnostics (e.g., VIF) remaining predictors satisfy specified threshold. supports linear models, generalized linear models, mixed models.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-Based Predictor Pruning — modelPrune","text":"","code":"modelPrune(   formula,   data,   engine = \"lm\",   criterion = \"vif\",   limit = 5,   force_in = NULL,   max_steps = NULL,   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-Based Predictor Pruning — modelPrune","text":"formula model formula specifying response predictors. May include random effects mixed models (e.g., y ~ x1 + x2 + (1|group)). data data.frame containing variables formula. engine Either character string built-engines, list defining custom engine. Built-engines (character string): \"lm\" (default): Linear models via stats::lm() \"glm\": Generalized linear models via stats::glm() (requires family argument) \"lme4\": Mixed models via lme4::lmer() lme4::glmer() (requires lme4 package) \"glmmTMB\": Generalized linear mixed models via glmmTMB::glmmTMB() (requires glmmTMB package) Custom engine (named list required components): fit: function(formula, data, ...) returns fitted model object diagnostics: function(model, fixed_effects) returns named numeric vector diagnostic scores (one per fixed effect, higher values = worse) name (optional): character string used error messages (default: \"custom\") criterion Character string specifying diagnostic criterion pruning. built-engines, \"vif\" (Variance Inflation Factor) supported. custom engines, parameter ignored (diagnostics computed engine's diagnostics function). Default: \"vif\". limit Numeric scalar. Maximum allowed value criterion. Predictors diagnostic values exceeding limit iteratively removed. Default: 5 (common VIF threshold). force_in Character vector predictor names must retained final model. variables removed pruning. Default: NULL. max_steps Integer. Maximum number pruning iterations. NULL (default), pruning continues diagnostics limit removable predictors remain. ... Additional arguments passed modeling function (e.g., family glm/glmer, control parameters lme4/glmmTMB).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-Based Predictor Pruning — modelPrune","text":"data.frame containing retained predictors (response). result following attributes: selected_vars Character vector retained predictor names removed_vars Character vector removed predictor names (order removal) engine Character string indicating engine used criterion Character string indicating criterion used limit threshold value used final_model final fitted model object (optional)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model-Based Predictor Pruning — modelPrune","text":"modelPrune() works : Parsing formula identify fixed-effect predictors Fitting initial model Computing diagnostics fixed-effect predictor Checking feasibility force_in constraints Iteratively removing predictor worst diagnostic value (excluding force_in variables) diagnostics ≤ limit Returning pruned data frame Random Effects: mixed models (lme4, glmmTMB), fixed-effect predictors considered pruning. Random-effect structure preserved exactly specified original formula. VIF Computation: Variance Inflation Factors computed fixed-effects design matrix. categorical predictors, VIF represents inflation entire factor (individual dummy variables). Determinism: algorithm deterministic. Ties diagnostic values broken removing predictor appears last formula. Force-Constraints: variables force_in violate diagnostic threshold, function error. ensures constraint feasible pruning begins.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-Based Predictor Pruning — modelPrune","text":"","code":"# Linear model with VIF-based pruning data(mtcars) pruned <- modelPrune(mpg ~ ., data = mtcars, engine = \"lm\", limit = 5) #> Error in modelPrune(mpg ~ ., data = mtcars, engine = \"lm\", limit = 5): could not find function \"modelPrune\" names(pruned) #> Error: object 'pruned' not found  # Force certain predictors to remain pruned <- modelPrune(mpg ~ ., data = mtcars, force_in = \"drat\", limit = 20) #> Error in modelPrune(mpg ~ ., data = mtcars, force_in = \"drat\", limit = 20): could not find function \"modelPrune\"  # GLM example (requires family argument) pruned <- modelPrune(am ~ ., data = mtcars, engine = \"glm\",                      family = binomial(), limit = 5) #> Error in modelPrune(am ~ ., data = mtcars, engine = \"glm\", family = binomial(),     limit = 5): could not find function \"modelPrune\"  if (FALSE) { # \\dontrun{ # Custom engine example (INLA) inla_engine <- list(   name = \"inla\",   fit = function(formula, data, ...) {     inla::inla(formula = formula, data = data,                family = list(...)$family %||% \"gaussian\",                control.compute = list(config = TRUE))   },   diagnostics = function(model, fixed_effects) {     scores <- model$summary.fixed[, \"sd\"]     names(scores) <- rownames(model$summary.fixed)     scores[fixed_effects]   } )  pruned <- modelPrune(y ~ x1 + x2 + x3, data = df,                      engine = inla_engine, limit = 0.5) } # }"},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Survey Data for Social Science Research — survey_example","title":"Example Survey Data for Social Science Research — survey_example","text":"simulated questionnaire dataset 30 Likert-scale items measuring three latent constructs (satisfaction, engagement, loyalty), plus demographic variables overall satisfaction score.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Survey Data for Social Science Research — survey_example","text":"","code":"survey_example"},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Survey Data for Social Science Research — survey_example","text":"data frame 200 rows 35 variables: respondent_id Integer. Unique respondent identifier age Integer. Respondent age (18-75 years) gender Factor. Gender (Male, Female, ) education Ordered factor. Education level (High School, Bachelor, Master, PhD) overall_satisfaction Integer. Overall satisfaction score (0-100) satisfaction_1, satisfaction_2, satisfaction_3, satisfaction_4, satisfaction_5, satisfaction_6, satisfaction_7, satisfaction_8, satisfaction_9, satisfaction_10 Ordered factor. Satisfaction items (1-7 Likert scale) engagement_1, engagement_2, engagement_3, engagement_4, engagement_5, engagement_6, engagement_7, engagement_8, engagement_9, engagement_10 Ordered factor. Engagement items (1-7 Likert scale) loyalty_1, loyalty_2, loyalty_3, loyalty_4, loyalty_5, loyalty_6, loyalty_7, loyalty_8, loyalty_9, loyalty_10 Ordered factor. Loyalty items (1-7 Likert scale)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Survey Data for Social Science Research — survey_example","text":"Simulated data based typical customer satisfaction survey structures","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Survey Data for Social Science Research — survey_example","text":"dataset represents common scenario survey research: multiple items measuring similar constructs lead redundancy multicollinearity. Items within construct correlated (satisfaction, engagement, loyalty), constructs inter-correlated. Use case: Demonstrating assocSelect() identifying redundant questionnaire items mixed-type data (ordered factors + numeric variables).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Survey Data for Social Science Research — survey_example","text":"","code":"data(survey_example)  # This dataset has mixed types: numeric (age, overall_satisfaction), # factors (gender, education), and ordered factors (Likert items) str(survey_example[, 1:10]) #> 'data.frame':\t200 obs. of  10 variables: #>  $ respondent_id       : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ age                 : num  38 32 18 18 19 39 33 26 26 42 ... #>  $ gender              : Factor w/ 3 levels \"Female\",\"Male\",..: 2 3 1 2 2 1 1 2 2 1 ... #>  $ education           : Ord.factor w/ 4 levels \"High School\"<..: 3 1 4 2 2 1 1 1 2 3 ... #>  $ overall_satisfaction: num  58 40 44 40 58 67 61 49 51 52 ... #>  $ satisfaction_1      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 5 3 4 5 5 4 4 5 ... #>  $ satisfaction_2      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 4 6 6 4 4 3 ... #>  $ satisfaction_3      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 3 4 5 3 4 4 ... #>  $ satisfaction_4      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 4 4 5 4 3 2 4 ... #>  $ satisfaction_5      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 7 4 5 5 5 4 3 6 4 6 ...  # \\donttest{ # Use assocSelect() for mixed-type data pruning # This may take a few seconds with 34 variables pruned <- assocSelect(survey_example[, -1],  # Exclude respondent_id                       threshold = 0.8,                       method_ord_ord = \"spearman\") length(attr(pruned, \"selected_vars\")) #> [1] 0 # }"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"major-release-predictor-pruning-toolkit-3-0-0","dir":"Changelog","previous_headings":"","what":"Major Release: Predictor Pruning Toolkit","title":"corrselect 3.0.0","text":"Version 3.0.0 represents major expansion corrselect specialized subset enumeration tool comprehensive predictor pruning toolkit. Fully backward compatible 2.x - existing code continues work.","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"bug-fixes-3-0-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"corrselect 3.0.0","text":"Added proper handling Inf NA VIF values pruning loop Clamped extreme R² values (> 0.9999) prevent division near-zero Added safety checks prevent removing variables Now uses stats::model.matrix() engines (robust) Eliminated “find columns” warnings Test suite: 261 tests pass zero warnings (CRAN-compliant)","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"new-functions-3-0-0","dir":"Changelog","previous_headings":"Major Features","what":"New Functions","title":"corrselect 3.0.0","text":"Model-free pruning using pairwise correlations associations Automatic measure selection (measure = \"auto\") Supports exact mode (small p), greedy mode (large p), auto-selection force_in parameter protect important predictors Returns single pruned data.frame pairwise associations ≤ threshold VIF-based iterative removal multicollinear predictors Supports multiple engines: lm, glm, lme4, glmmTMB Custom engine support: Define modeling backends (INLA, mgcv, brms, etc.) Prunes fixed effects (preserves random effects mixed models) force_in parameter protecting important variables Returns pruned data.frame final fitted model","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"new-c-backend-3-0-0","dir":"Changelog","previous_headings":"Major Features","what":"New C++ Backend","title":"corrselect 3.0.0","text":"Polynomial-time complexity O(p² × k) vs exponential exact search Handles p > 100 efficiently Deterministic tie-breaking reproducibility Used corrPrune(mode = \"greedy\") mode = \"auto\"","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"enhancements-3-0-0","dir":"Changelog","previous_headings":"","what":"Enhancements","title":"corrselect 3.0.0","text":"Exact methods (corrSelect(), assocSelect()) now integrate seamlessly corrPrune() Deterministic subset selection multiple maximal sets exist Improved error messages threshold feasibility checks Better handling edge cases (single predictor, correlated, etc.) Custom engine interface modelPrune(): Users can define custom modeling backends fit diagnostics functions, enabling integration R modeling package","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"documentation-3-0-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"corrselect 3.0.0","text":"Quick Start: 5-minute introduction corrPrune() modelPrune() Complete Workflows: Real-world examples across 4 domains (ecology, social science, genomics, clinical) Comparison Alternatives: choose corrselect vs caret, Boruta, glmnet Performance Benchmarks: Timing comparisons, scalability tests, optimization guidelines Advanced Topics: Algorithms, custom engines (INLA, mgcv), performance optimization, troubleshooting Four new example datasets full documentation (bioclim, survey, genes, longitudinal) Updated README quickstart examples custom engine support Full documentation corrPrune() modelPrune() Usage examples modeling engines","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"package-changes-3-0-0","dir":"Changelog","previous_headings":"","what":"Package Changes","title":"corrselect 3.0.0","text":"Added lme4 glmmTMB Suggests (required respective engines) Version bumped 3.0.0 (major feature release) Updated package description reflect expanded pruning functionality","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"notes-3-0-0","dir":"Changelog","previous_headings":"","what":"Notes","title":"corrselect 3.0.0","text":"breaking changes: Version 3.0.0 fully backward compatible 2.0.1 large predictor sets (p > 20), use corrPrune(mode = \"auto\") best performance Mixed model engines require optional packages: install install.packages(c(\"lme4\", \"glmmTMB\"))","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"corrselect-201","dir":"Changelog","previous_headings":"","what":"corrselect 2.0.1","title":"corrselect 2.0.1","text":"CRAN release: 2025-09-08","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"bug-fixes-2-0-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"corrselect 2.0.1","text":"force_in MatSelect() now correctly accepts character column names. els now correctly lists valid subsets single variable forced . corrSelect() now displays appropriate warning one variable remains dropping unsupported columns. Association matrix construction assocSelect() now safely falls back 0 failed meaningless associations (e.g. empty chi-squared tables due sparse combinations unused factor levels).","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"features-added-2-0-1","dir":"Changelog","previous_headings":"","what":"Features Added","title":"corrselect 2.0.1","text":"assocSelect() now supports logical columns automatically converting factors.","code":""}]

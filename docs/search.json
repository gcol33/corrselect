[{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Advanced Topics","text":"vignette covers advanced topics power users, researchers, method developers: Understanding Algorithms - Exact vs greedy, complexity analysis Custom Engines - Integrate modeling package (INLA, mgcv, brms) Exact Subset Enumeration - Multiple maximal subsets Performance Optimization - Speed memory considerations Troubleshooting - Common issues solutions Target audience: Users comfortable R programming statistical methods Estimated time: 15-20 minutes","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exact-vs-greedy-when-to-use-each","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.1 Exact vs Greedy: When to Use Each","title":"Advanced Topics","text":"corrselect offers two algorithmic approaches corrPrune():","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exact-mode-graph-theoretic","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Exact Mode (Graph-Theoretic)","title":"Advanced Topics","text":"Algorithm: Eppstein–Löffler–Strash (ELS) Bron–Kerbosch Complexity: O(2^p) - exponential number predictors Guarantee: Finds largest maximal independent set Use exact mode : p ≤ 20 (feasible runtime) need guaranteed optimal solution Reproducibility critical ’re writing paper (justify optimality)","code":"library(corrselect) data(mtcars)  # Exact mode: guaranteed optimal exact_result <- corrPrune(mtcars, threshold = 0.7, mode = \"exact\") cat(\"Exact mode kept:\", ncol(exact_result), \"variables\\n\") #> Exact mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"greedy-mode-heuristic","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Greedy Mode (Heuristic)","title":"Advanced Topics","text":"Algorithm: Deterministic iterative removal Complexity: O(p² × k) k = iterations Guarantee: Near-optimal, deterministic Use greedy mode : p > 20 (exact becomes slow) Speed priority Near-optimal acceptable High-dimensional data (p > 100)","code":"# Greedy mode: fast approximation greedy_result <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\") cat(\"Greedy mode kept:\", ncol(greedy_result), \"variables\\n\") #> Greedy mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"auto-mode-recommended","dir":"Articles","previous_headings":"1. Understanding the Algorithms > 1.1 Exact vs Greedy: When to Use Each","what":"Auto Mode (Recommended)","title":"Advanced Topics","text":"Automatically selects based p:","code":"# Auto mode: smart switching (exact if p ≤ 20, greedy otherwise) auto_result <- corrPrune(mtcars, threshold = 0.7, mode = \"auto\") cat(\"Auto mode kept:\", ncol(auto_result), \"variables\\n\") #> Auto mode kept: 5 variables"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"complexity-analysis-with-benchmarks","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.2 Complexity Analysis with Benchmarks","title":"Advanced Topics","text":"Let’s measure runtime scaling:  Key insight: Exact mode becomes impractical beyond p ≈ 25. Greedy mode scales linearly.","code":"# Generate datasets with increasing p benchmark_corrPrune <- function(p_values) {   results <- data.frame(     p = integer(),     exact_time = numeric(),     greedy_time = numeric()   )    for (p in p_values) {     # Generate correlated data     set.seed(123)     cor_mat <- 0.5^abs(outer(1:p, 1:p, \"-\"))     data <- as.data.frame(MASS::mvrnorm(n = 100, mu = rep(0, p), Sigma = cor_mat))      # Exact mode (skip if p too large)     exact_time <- if (p <= 25) {       system.time({         corrPrune(data, threshold = 0.7, mode = \"exact\")       })[\"elapsed\"]     } else {       NA     }      # Greedy mode     greedy_time <- system.time({       corrPrune(data, threshold = 0.7, mode = \"greedy\")     })[\"elapsed\"]      results <- rbind(results, data.frame(       p = p,       exact_time = exact_time,       greedy_time = greedy_time     ))   }    results }  # Benchmark p_values <- c(10, 15, 20, 25, 50, 100) benchmark <- benchmark_corrPrune(p_values) print(benchmark) #>            p exact_time greedy_time #> elapsed   10          0        0.00 #> elapsed1  15          0        0.00 #> elapsed2  20          0        0.00 #> elapsed3  25          0        0.02 #> elapsed4  50         NA        0.00 #> elapsed5 100         NA        0.00 # Visualize scaling plot(benchmark$p, benchmark$exact_time,      type = \"b\", col = \"red\", lwd = 2,      xlab = \"Number of Predictors (p)\",      ylab = \"Time (seconds)\",      main = \"Exact vs Greedy Scaling\",      ylim = c(0, max(benchmark$exact_time, na.rm = TRUE) * 1.1),      log = \"y\") #> Warning in xy.coords(x, y, xlabel, ylabel, log): 4 y values <= 0 omitted from #> logarithmic plot #> Warning in plot.window(...): nonfinite axis=2 limits [GScale(-inf,-inf,..); #> log=TRUE] -- corrected now lines(benchmark$p, benchmark$greedy_time, type = \"b\", col = \"blue\", lwd = 2) legend(\"topleft\", legend = c(\"Exact\", \"Greedy\"),        col = c(\"red\", \"blue\"), lwd = 2) abline(v = 20, lty = 2, col = \"gray\") text(20, max(benchmark$exact_time, na.rm = TRUE), \"Auto switches here\", pos = 4)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"deterministic-tie-breaking","dir":"Articles","previous_headings":"1. Understanding the Algorithms","what":"1.3 Deterministic Tie-Breaking","title":"Advanced Topics","text":"multiple variables identical correlation profiles, corrselect uses deterministic tie-breaking: Tie-breaking rules: 1. Prefer variables lower mean absolute correlation others 2. still tied, prefer lexicographically first (alphabetical) ensures reproducibility across runs, machines, R versions.","code":"# Create data with identical correlations set.seed(123) x1 <- rnorm(100) x2 <- x1 + rnorm(100, sd = 0.1)  # Almost identical to x1 x3 <- x1 + rnorm(100, sd = 0.1)  # Also almost identical to x1 x4 <- rnorm(100)                  # Independent  data_ties <- data.frame(x1, x2, x3, x4)  # Run multiple times - always same result result1 <- corrPrune(data_ties, threshold = 0.95) result2 <- corrPrune(data_ties, threshold = 0.95)  cat(\"Run 1 selected:\", names(result1), \"\\n\") #> Run 1 selected: x2 x4 cat(\"Run 2 selected:\", names(result2), \"\\n\") #> Run 2 selected: x2 x4 cat(\"Identical:\", identical(names(result1), names(result2)), \"\\n\") #> Identical: TRUE"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"custom-engine-structure","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.1 Custom Engine Structure","title":"Advanced Topics","text":"custom engine named list two required functions:","code":"my_engine <- list(   # Required: How to fit the model   fit = function(formula, data, ...) {     # Your model fitting code     # Must return a fitted model object   },    # Required: How to compute diagnostics   diagnostics = function(model, fixed_effects) {     # Compute diagnostic scores for each fixed effect     # Higher values = worse (more likely to be removed)     # Must return a named numeric vector   },    # Optional: Name for error messages   name = \"my_custom_engine\"  # Defaults to \"custom\" )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-inla-engine-bayesian-spatial-models","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.2 Example: INLA Engine (Bayesian Spatial Models)","title":"Advanced Topics","text":"INLA popular package Bayesian inference. Let’s integrate : works: 1. fit function calls INLA fit model 2. diagnostics extracts posterior SDs fixed effects 3. modelPrune iteratively removes variables SD > 0.5","code":"# Custom engine for INLA inla_engine <- list(   name = \"inla\",    fit = function(formula, data, ...) {     # Fit INLA model     INLA::inla(       formula = formula,       data = data,       family = list(...)$family %||% \"gaussian\",       control.compute = list(config = TRUE),       ...     )   },    diagnostics = function(model, fixed_effects) {     # Use posterior SD as \"badness\" metric     # Higher SD = more uncertain = candidate for removal     summary_fixed <- model$summary.fixed     scores <- summary_fixed[, \"sd\"]     names(scores) <- rownames(summary_fixed)      # Return scores for fixed effects only     scores[fixed_effects]   } )  # Usage pruned <- modelPrune(   y ~ x1 + x2 + x3 + x4,   data = my_data,   engine = inla_engine,   limit = 0.5  # Remove if posterior SD > 0.5 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-mgcv-engine-gams","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.3 Example: mgcv Engine (GAMs)","title":"Advanced Topics","text":"Generalized Additive Models (GAMs) via mgcv:","code":"# Custom engine for mgcv GAMs mgcv_engine <- list(   name = \"mgcv_gam\",    fit = function(formula, data, ...) {     mgcv::gam(formula, data = data, ...)   },    diagnostics = function(model, fixed_effects) {     # Use p-values as badness metric     # Higher p-value = less significant = candidate for removal     summary_obj <- summary(model)      # Extract parametric term p-values     pvals <- summary_obj$p.pv      # Return p-values for fixed effects     pvals[fixed_effects]   } )  # Usage pruned <- modelPrune(   y ~ x1 + x2 + s(x3),  # s() for smooth terms   data = my_data,   engine = mgcv_engine,   limit = 0.05  # Remove if p > 0.05 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"example-custom-criterion-aic-based","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.4 Example: Custom Criterion (AIC-Based)","title":"Advanced Topics","text":"can define entirely custom pruning criteria:","code":"# AIC-based pruning engine aic_engine <- list(   name = \"aic_pruner\",    fit = function(formula, data, ...) {     lm(formula, data = data)   },    diagnostics = function(model, fixed_effects) {     # For each predictor, compute ΔAIC if removed     full_aic <- AIC(model)      scores <- numeric(length(fixed_effects))     names(scores) <- fixed_effects      for (var in fixed_effects) {       # Refit without this variable       reduced_formula <- update(formula(model), paste(\"~ . -\", var))       reduced_model <- lm(reduced_formula, data = model$model)        # ΔAIC: negative means removing improves model       # We negate so \"higher = worse\" convention holds       scores[var] <- -(AIC(reduced_model) - full_aic)     }      scores   } )  # Usage: Remove predictors with ΔAIC < -2 (improve AIC by > 2 when removed) pruned <- modelPrune(   y ~ x1 + x2 + x3,   data = my_data,   engine = aic_engine,   limit = -2 )"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"validation-and-error-handling","dir":"Articles","previous_headings":"2. Custom Engines for modelPrune()","what":"2.5 Validation and Error Handling","title":"Advanced Topics","text":"Custom engines validated automatically: Validation checks: fit diagnostics must functions diagnostics must return numeric vector Correct length (one value per fixed effect) Named vector correct names missing values","code":"# Invalid engine: missing 'diagnostics' bad_engine <- list(   fit = function(formula, data, ...) lm(formula, data = data)   # Missing 'diagnostics' )  tryCatch({   modelPrune(mpg ~ ., data = mtcars, engine = bad_engine, limit = 5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: Custom engine missing required fields: diagnostics #> Required: 'fit' and 'diagnostics'"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"when-you-need-all-maximal-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.1 When You Need ALL Maximal Subsets","title":"Advanced Topics","text":"corrPrune() returns single subset. Sometimes want maximal subsets:","code":"# corrPrune: Single subset single <- corrPrune(mtcars, threshold = 0.7) cat(\"corrPrune returned:\", ncol(single), \"variables\\n\") #> corrPrune returned: 5 variables  # corrSelect: ALL maximal subsets (use higher threshold to ensure subsets exist) all_subsets <- corrSelect(mtcars, threshold = 0.9) show(all_subsets) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.900 #>   Subsets:     2 valid combinations #>   Data Rows:   32 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] mpg, disp, hp, drat, wt, qsec...  0.527  0.888    10 #>   [ 2] mpg, cyl, hp, drat, wt, qsec,...  0.531  0.868    10"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"exploring-multiple-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.2 Exploring Multiple Subsets","title":"Advanced Topics","text":"multiple maximal subsets exist, can explore :","code":"if (length(all_subsets@subset_list) > 0) {   # Display first few subsets   cat(\"First few maximal subsets:\\n\")   for (i in seq_len(min(3, length(all_subsets@subset_list)))) {     cat(sprintf(\"\\nSubset %d (avg corr = %.3f):\\n\", i, all_subsets@avg_corr[i]))     cat(\" \", paste(all_subsets@subset_list[[i]], collapse = \", \"), \"\\n\")   }    # Analyze subset characteristics   subset_sizes <- lengths(all_subsets@subset_list)   cat(\"\\nSubset sizes:\\n\")   print(table(subset_sizes))    cat(\"\\nAverage correlations:\\n\")   print(summary(all_subsets@avg_corr)) } else {   cat(\"No subsets found at threshold 0.9\\n\") } #> First few maximal subsets: #>  #> Subset 1 (avg corr = 0.527): #>   mpg, disp, hp, drat, wt, qsec, vs, am, gear, carb  #>  #> Subset 2 (avg corr = 0.531): #>   mpg, cyl, hp, drat, wt, qsec, vs, am, gear, carb  #>  #> Subset sizes: #> subset_sizes #> 10  #>  2  #>  #> Average correlations: #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>  0.5269  0.5280  0.5290  0.5290  0.5301  0.5311"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"extracting-specific-subsets","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.3 Extracting Specific Subsets","title":"Advanced Topics","text":"","code":"if (length(all_subsets@subset_list) > 0) {   # Extract subset with lowest average correlation   best_idx <- which.min(all_subsets@avg_corr)   best_subset <- corrSubset(all_subsets, mtcars, which = best_idx)    cat(\"Best subset (lowest avg correlation):\\n\")   print(names(best_subset))    # Extract subset with most predictors   subset_sizes <- lengths(all_subsets@subset_list)   largest_idx <- which.max(subset_sizes)   largest_subset <- corrSubset(all_subsets, mtcars, which = largest_idx)    cat(\"\\nLargest subset:\\n\")   print(names(largest_subset)) } else {   cat(\"No subsets to extract at threshold 0.9\\n\") } #> Best subset (lowest avg correlation): #>  [1] \"mpg\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\" #>  #> Largest subset: #>  [1] \"mpg\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"advanced-domain-specific-subset-selection","dir":"Articles","previous_headings":"3. Exact Subset Enumeration","what":"3.4 Advanced: Domain-Specific Subset Selection","title":"Advanced Topics","text":"can define custom criteria choosing among multiple subsets:","code":"if (length(all_subsets@subset_list) > 0) {   # Custom criterion: Prefer subsets with specific variables   preferred_vars <- c(\"mpg\", \"hp\", \"wt\")    # Compute score: number of preferred variables in each subset   scores <- sapply(all_subsets@subset_list, function(vars) {     sum(preferred_vars %in% vars)   })    # Select subset with most preferred variables   best_idx <- which.max(scores)   cat(\"Subset with most preferred variables (score:\", scores[best_idx], \"):\\n\")   cat(paste(all_subsets@subset_list[[best_idx]], collapse = \", \"), \"\\n\")    # Extract as data frame   preferred_subset <- corrSubset(all_subsets, mtcars, which = best_idx)   print(head(preferred_subset)) } else {   cat(\"No subsets available for custom selection\\n\") } #> Subset with most preferred variables (score: 3 ): #> mpg, disp, hp, drat, wt, qsec, vs, am, gear, carb  #>                    mpg disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"precomputed-correlation-matrices","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.1 Precomputed Correlation Matrices","title":"Advanced Topics","text":"repeated pruning different thresholds, precompute correlation matrix: Use precomputed matrices : Testing multiple thresholds Cross-validation workflows Sensitivity analysis","code":"# Slow: Recomputes correlation every time system.time({   result1 <- corrPrune(mtcars, threshold = 0.7)   result2 <- corrPrune(mtcars, threshold = 0.8)   result3 <- corrPrune(mtcars, threshold = 0.9) }) #>    user  system elapsed  #>       0       0       0  # Fast: Compute correlation once, reuse cor_matrix <- cor(mtcars) system.time({   result1 <- MatSelect(cor_matrix, threshold = 0.7)   result2 <- MatSelect(cor_matrix, threshold = 0.8)   result3 <- MatSelect(cor_matrix, threshold = 0.9) }) #>    user  system elapsed  #>       0       0       0"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"memory-considerations-for-large-data","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.2 Memory Considerations for Large Data","title":"Advanced Topics","text":"large datasets (n > 10,000, p > 500):","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"memory-efficient-correlation-computation","dir":"Articles","previous_headings":"4. Performance Optimization > 4.2 Memory Considerations for Large Data","what":"Memory-Efficient Correlation Computation","title":"Advanced Topics","text":"","code":"# Standard (memory-intensive for large n) cor_matrix <- cor(large_data)  # Memory-efficient alternative (for very large n) # Process in chunks if needed compute_cor_chunked <- function(data, chunk_size = 1000) {   n <- nrow(data)   n_chunks <- ceiling(n / chunk_size)    # Use online algorithm or chunked computation   # (Implementation depends on your data size) }"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"sparse-correlation-matrices","dir":"Articles","previous_headings":"4. Performance Optimization > 4.2 Memory Considerations for Large Data","what":"Sparse Correlation Matrices","title":"Advanced Topics","text":"correlations low, consider sparse storage:","code":"# Convert to sparse format (requires Matrix package) library(Matrix)  # Compute correlation cor_mat <- cor(data)  # Threshold and convert to sparse cor_sparse <- cor_mat cor_sparse[abs(cor_sparse) < 0.3] <- 0  # Set low correlations to 0 cor_sparse <- Matrix(cor_sparse, sparse = TRUE)  # Memory savings object.size(cor_mat) object.size(cor_sparse)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"parallel-processing-strategies","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.3 Parallel Processing Strategies","title":"Advanced Topics","text":"multiple independent pruning operations: Note: corrselect doesn’t parallelize internally (reproducibility), can parallelize across multiple analyses.","code":"library(parallel)  # Create cluster cl <- makeCluster(detectCores() - 1)  # Export functions to cluster clusterEvalQ(cl, library(corrselect))  # Parallel pruning with different thresholds thresholds <- seq(0.5, 0.9, by = 0.1) results <- parLapply(cl, thresholds, function(thresh) {   corrPrune(my_data, threshold = thresh) })  # Clean up stopCluster(cl)"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"choosing-the-right-mode","dir":"Articles","previous_headings":"4. Performance Optimization","what":"4.4 Choosing the Right Mode","title":"Advanced Topics","text":"Decision tree mode selection:","code":"p ≤ 15:  Use \"exact\" (fast enough, guaranteed optimal) 15 < p ≤ 25:  Use \"exact\" if time permits, \"greedy\" if speed critical p > 25:  Use \"greedy\" or \"auto\" p > 100: Always use \"greedy\""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-no-valid-subsets-found","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: “No valid subsets found”","title":"Advanced Topics","text":"Cause: Threshold strict - variables exceed Solutions: 1. Increase threshold 2. Use force_in keep least one variable 3. Check data near-duplicates","code":"# Example: All correlations > 0.9 set.seed(123) x <- rnorm(100) high_cor_data <- data.frame(   x1 = x,   x2 = x + rnorm(100, sd = 0.01),   x3 = x + rnorm(100, sd = 0.01) )  tryCatch({   corrPrune(high_cor_data, threshold = 0.5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: No valid subsets found that satisfy the threshold constraint # Solution 1: Increase threshold result <- corrPrune(high_cor_data, threshold = 0.95) #> Error in corrPrune(high_cor_data, threshold = 0.95): No valid subsets found that satisfy the threshold constraint print(names(result)) #> Error: object 'result' not found  # Solution 2: Force keep one variable result <- corrPrune(high_cor_data, threshold = 0.5, force_in = \"x1\") #> Error in corrPrune(high_cor_data, threshold = 0.5, force_in = \"x1\"): No valid subsets found that satisfy the threshold constraint print(names(result)) #> Error: object 'result' not found"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-force_in-variables-conflict-with-threshold","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: force_in variables conflict with threshold","title":"Advanced Topics","text":"Cause: Variables force_in |correlation| > threshold Solution: Either increase threshold reduce force_in set","code":"# x1 and x2 are highly correlated tryCatch({   corrPrune(high_cor_data, threshold = 0.5, force_in = c(\"x1\", \"x2\")) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: Variables in 'force_in' violate the threshold constraint. Example: 'x1' and 'x2' have association 1.000 > 0.500"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"error-vif-computation-fails-in-modelprune","dir":"Articles","previous_headings":"5. Troubleshooting > 5.1 Common Errors and Solutions","what":"Error: VIF computation fails in modelPrune()","title":"Advanced Topics","text":"Cause: Perfect multicollinearity (R² = 1) Solution: Use corrPrune() first remove perfect collinearity:","code":"# Create perfect multicollinearity perfect_data <- data.frame(   y = rnorm(100),   x1 = rnorm(100),   x2 = rnorm(100) ) perfect_data$x3 <- perfect_data$x1 + perfect_data$x2  # Perfect collinearity  tryCatch({   modelPrune(y ~ ., data = perfect_data, limit = 5) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #>               y          x1          x2 #> 1   -0.71524219 -0.07355602 -0.60189285 #> 2   -0.75268897 -1.16865142 -0.99369859 #> 3   -0.93853870 -0.63474826  1.02678506 #> 4   -1.05251328 -0.02884155  0.75106130 #> 5   -0.43715953  0.67069597 -1.50916654 #> 6    0.33117917 -1.65054654 -0.09514745 #> 7   -2.01421050 -0.34975424 -0.89594782 #> 8    0.21198043  0.75640644 -2.07075107 #> 9    1.23667505 -0.53880916  0.15012013 #> 10   2.03757402  0.22729192 -0.07921171 #> 11   1.30117599  0.49222857 -0.09736927 #> 12   0.75677476  0.26783502  0.21615254 #> 13  -1.72673040  0.65325768  0.88246516 #> 14  -0.60150671 -0.12270866  0.20559750 #> 15  -0.35204646 -0.41367651 -0.61643584 #> 16   0.70352390 -2.64314895 -0.73479925 #> 17  -0.10567133 -0.09294102 -0.13180279 #> 18  -1.25864863  0.43028470  0.31001699 #> 19   1.68443571  0.53539884 -1.03968035 #> 20   0.91139129 -0.55527835 -0.18430887 #> 21   0.23743027  1.77950291  0.96726726 #> 22   1.21810861  0.28642442 -0.10828009 #> 23  -1.33877429  0.12631586 -0.69842067 #> 24   0.66082030  1.27226678 -0.27594517 #> 25  -0.52291238 -0.71846622  1.11464855 #> 26   0.68374552 -0.45033862  0.55004396 #> 27  -0.06082195  2.39745248  1.23667580 #> 28   0.63296071  0.01112919  0.13909786 #> 29   1.33551762  1.63356842  0.41027510 #> 30   0.00729009 -1.43850664 -0.55845691 #> 31   1.01755864 -0.19051680  0.60537067 #> 32  -1.18843404  0.37842390 -0.50633354 #> 33  -0.72160444  0.30003855 -1.42056550 #> 34   1.51921771 -1.00563626  0.12799297 #> 35   0.37738797  0.01925927  1.94585122 #> 36  -2.05222282 -1.07742065  0.80091434 #> 37  -1.36403745  0.71270333  1.16525339 #> 38  -0.20078102  1.08477509  0.35885572 #> 39   0.86577940 -2.22498770 -0.60855718 #> 40  -0.10188326  1.23569346 -0.20224086 #> 41   0.62418747 -1.24104450 -0.27324811 #> 42   0.95900538  0.45476927 -0.46869978 #> 43   1.67105483  0.65990264  0.70416728 #> 44   0.05601673 -0.19988983 -1.19736350 #> 45  -0.05198191 -0.64511396  0.86636613 #> 46  -1.75323736  0.16532102  0.86415249 #> 47   0.09932759  0.43881870 -1.19862236 #> 48  -0.57185006  0.88330282  0.63949200 #> 49  -0.97400958 -2.05233698  2.43022665 #> 50  -0.17990623 -1.63637927 -0.55721548 #> 51   1.01494317  1.43040234  0.84490424 #> 52  -1.99274849  1.04662885 -0.78220185 #> 53  -0.42727929  0.43528895  1.11071142 #> 54   0.11663728  0.71517841  0.24982472 #> 55  -0.89320757  0.91717492  1.65191539 #> 56   0.33390294 -2.66092280 -1.45897073 #> 57   0.41142992  1.11027710 -0.05129789 #> 58  -0.03303616 -0.48498760 -0.52692518 #> 59  -2.46589819  0.23061683 -0.19726487 #> 60   2.57145815 -0.29515780 -0.62957874 #> 61  -0.20529926  0.87196495 -0.83384358 #> 62   0.65119328 -0.34847245  0.57872237 #> 63   0.27376649  0.51850377 -1.08758071 #> 64   1.02467323 -0.39068498  1.48403093 #> 65   0.81765945 -1.09278721 -1.18620659 #> 66  -0.20979317  1.21001051  0.10107915 #> 67   0.37816777  0.74090001  0.53298929 #> 68  -0.94540883  1.72426224  0.58673534 #> 69   0.85692301  0.06515393 -0.30174666 #> 70  -0.46103834  1.12500275  0.07950200 #> 71   2.41677335  1.97541905  0.96126415 #> 72  -1.65104890 -0.28148212 -1.45646592 #> 73  -0.46398724 -1.32295111 -0.78173971 #> 74   0.82537986 -0.23935157  0.32040231 #> 75   0.51013255 -0.21404124 -0.44478198 #> 76  -0.58948104  0.15168050  1.37000399 #> 77  -0.99678074  1.71230498  0.67325386 #> 78   0.14447570 -0.32614389  0.07216675 #> 79  -0.01430741  0.37300466 -1.50775732 #> 80  -1.79028124 -0.22768406  0.02610023 #> 81   0.03455107  0.02045071 -0.31641587 #> 82   0.19023032  0.31405766 -0.10234651 #> 83   0.17472640  1.32821470 -1.18155923 #> 84  -1.05501704  0.12131838  0.49865804 #> 85   0.47613328  0.71284232 -1.03895644 #> 86   1.37857014  0.77886003 -0.22622198 #> 87   0.45623640  0.91477327  0.38142583 #> 88  -1.13558847 -0.57439455 -0.78351579 #> 89  -0.43564547  1.62688121  0.58299141 #> 90   0.34610362 -0.38095674 -1.31651040 #> 91  -0.64704563 -0.10578417 -2.80977468 #> 92  -2.15764634  1.40405027  0.46496799 #> 93   0.88425082  1.29408391  0.84053983 #> 94  -0.82947761 -1.08999187 -0.28584542 #> 95  -0.57356027 -0.87307100  0.50412625 #> 96   1.50390061 -1.35807906 -1.15591653 #> 97  -0.77414493  0.18184719 -0.12714861 #> 98   0.84573154  0.16484087 -1.94151838 #> 99  -1.26068288  0.36411469  1.18118089 #> 100 -0.35454240  0.55215771  1.85991086 # Two-step approach step1 <- corrPrune(perfect_data[, -1], threshold = 0.99) step2_data <- data.frame(y = perfect_data$y, step1) result <- modelPrune(y ~ ., data = step2_data, limit = 5) #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable #> Warning in summary.lm(fit): essentially perfect fit: summary may be unreliable print(attr(result, \"selected_vars\")) #> [1] \"x1\" \"x2\""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-corrprune-correlation-threshold","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"For corrPrune() (Correlation Threshold)","title":"Advanced Topics","text":"Conservative (strict): threshold = 0.5: low redundancy, may lose information Use : Interpretability critical, small sample size Moderate (recommended): threshold = 0.7: Balances redundancy information retention Use : Standard regression, general analysis Lenient: threshold = 0.9: removes near-duplicates Use : Large sample size, prediction focus","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-modelprune-vif-limit","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"For modelPrune() (VIF Limit)","title":"Advanced Topics","text":"Strict: limit = 2: low multicollinearity, may -prune Use : Small sample size, interpretability critical Moderate (recommended): limit = 5: Standard threshold literature Use : General regression analysis Lenient: limit = 10: Tolerates multicollinearity Use : Large sample size, prediction focus","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"empirical-approach-visualize-first","dir":"Articles","previous_headings":"5. Troubleshooting > 5.2 Threshold Selection Guidance","what":"Empirical Approach: Visualize First","title":"Advanced Topics","text":"Strategy: Choose threshold curve begins plateau.","code":"data(mtcars)  # Visualize correlation distribution cor_mat <- cor(mtcars) cor_vec <- cor_mat[upper.tri(cor_mat)]  par(mfrow = c(1, 2))  # Histogram of correlations hist(abs(cor_vec), breaks = 30,      main = \"Distribution of |Correlations|\",      xlab = \"|Correlation|\",      col = \"lightblue\") abline(v = c(0.5, 0.7, 0.9), col = c(\"red\", \"blue\", \"green\"), lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"0.5 (strict)\", \"0.7 (moderate)\", \"0.9 (lenient)\"),        col = c(\"red\", \"blue\", \"green\"), lwd = 2, lty = 2)  # Subset size vs threshold thresholds <- seq(0.3, 0.95, by = 0.05) sizes <- sapply(thresholds, function(t) {   tryCatch({     ncol(corrPrune(mtcars, threshold = t))   }, error = function(e) NA) })  plot(thresholds, sizes, type = \"b\",      xlab = \"Threshold\",      ylab = \"Number of Variables Retained\",      main = \"Threshold Sensitivity\",      col = \"blue\", lwd = 2) abline(h = ncol(mtcars), lty = 2, col = \"gray\") text(0.3, ncol(mtcars), \"Original\", pos = 3)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"single-predictor-after-pruning","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"Single Predictor After Pruning","title":"Advanced Topics","text":"","code":"# Very strict threshold may leave only 1 variable strict_result <- corrPrune(mtcars, threshold = 0.3) cat(\"Variables remaining:\", ncol(strict_result), \"\\n\") #> Variables remaining: 2  # Check if result is usable if (ncol(strict_result) < 2) {   cat(\"Warning: Only 1 variable remaining. Consider:\\n\")   cat(\"  1. Increasing threshold\\n\")   cat(\"  2. Using force_in to keep important variables\\n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"all-variables-removed","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"All Variables Removed","title":"Advanced Topics","text":"","code":"# Impossible threshold tryCatch({   corrPrune(mtcars, threshold = 0.0) }, error = function(e) {   cat(\"Error:\", e$message, \"\\n\") }) #> Error: `threshold` must be in the range (0, 1]."},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"mixed-type-data","dir":"Articles","previous_headings":"5. Troubleshooting > 5.3 Handling Edge Cases","what":"Mixed-Type Data","title":"Advanced Topics","text":"","code":"# Create mixed data mixed_data <- mtcars mixed_data$cyl <- factor(mixed_data$cyl) mixed_data$am <- factor(mixed_data$am)  # Use assocSelect for mixed types result <- assocSelect(mixed_data, threshold = 0.6) show(result) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_factor = eta, numeric_numeric = pearson, factor_numeric #>                = eta, factor_factor = cramersv #>   Threshold:   0.600 #>   Subsets:     20 valid combinations #>   Data Rows:   32 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] wt, vs, gear, carb                0.436  0.583     4 #>   [ 2] vs, am, carb                      0.265  0.570     3 #>   [ 3] wt, qsec, gear                    0.324  0.583     3 #>   [ 4] disp, carb, am                    0.348  0.591     3 #>   [ 5] drat, vs, carb                    0.367  0.570     3 #>   ... (15 more combinations)"},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-exploratory-analysis","dir":"Articles","previous_headings":"6. Best Practices > 6.1 Workflow Recommendations","what":"For Exploratory Analysis","title":"Advanced Topics","text":"","code":"# 1. Visualize correlations corrplot::corrplot(cor(data), method = \"circle\")  # 2. Try multiple thresholds results <- lapply(c(0.5, 0.7, 0.9), function(t) {   corrPrune(data, threshold = t) })  # 3. Compare subset sizes sapply(results, ncol)  # 4. Choose based on your needs final_data <- results[[2]]  # threshold = 0.7"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"for-publication-quality-analysis","dir":"Articles","previous_headings":"6. Best Practices > 6.1 Workflow Recommendations","what":"For Publication-Quality Analysis","title":"Advanced Topics","text":"","code":"# 1. Use exact mode for reproducibility and optimality data_pruned <- corrPrune(data, threshold = 0.7, mode = \"exact\")  # 2. Document in methods section cat(sprintf(   \"Variables were pruned using corrselect::corrPrune() with threshold = 0.7, \",   \"exact mode, retaining %d of %d original predictors.\",   ncol(data_pruned), ncol(data) ))  # 3. Report which variables were removed removed <- attr(data_pruned, \"removed_vars\") cat(\"Removed variables:\", paste(removed, collapse = \", \"))"},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"combining-with-other-methods","dir":"Articles","previous_headings":"6. Best Practices","what":"6.2 Combining with Other Methods","title":"Advanced Topics","text":"","code":"# Comprehensive variable selection pipeline pipeline <- function(data, response) {   # Step 1: Remove correlations   step1 <- corrPrune(data, threshold = 0.7, mode = \"auto\")    # Step 2: VIF cleanup   step2_data <- data.frame(response = response, step1)   step2 <- modelPrune(response ~ ., data = step2_data, limit = 5)    # Step 3: Feature importance (optional)   if (requireNamespace(\"Boruta\", quietly = TRUE)) {     boruta_result <- Boruta::Boruta(response ~ ., data = step2)     important <- Boruta::getSelectedAttributes(boruta_result)     final_data <- step2[, c(\"response\", important)]   } else {     final_data <- step2   }    final_data }"},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"algorithms","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Algorithms","title":"Advanced Topics","text":"Use exact mode p ≤ 20 (optimal, reproducible) Use greedy mode p > 20 (fast, near-optimal) Use auto mode let corrselect decide","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"custom-engines","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Custom Engines","title":"Advanced Topics","text":"Integrate modeling package (INLA, mgcv, brms) Define custom pruning criteria (AIC, BIC, p-values) Two required functions: fit diagnostics","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"optimization","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Optimization","title":"Advanced Topics","text":"Precompute correlation matrices multiple thresholds Use greedy mode large p Parallelize across analyses, within","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"troubleshooting-1","dir":"Articles","previous_headings":"7. Summary > Key Takeaways","what":"Troubleshooting","title":"Advanced Topics","text":"Visualize correlation distribution choosing threshold Use force_in protect important variables Two-step pruning (corrPrune → modelPrune) robustness","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"references","dir":"Articles","previous_headings":"","what":"8. References","title":"Advanced Topics","text":"Algorithms: Eppstein, D., Löffler, M., & Strash, D. (2010). Listing maximal cliques sparse graphs near-optimal time. Symposium Algorithms Computation. Bron, C., & Kerbosch, J. (1973). Algorithm 457: Finding cliques undirected graph. Communications ACM, 16(9), 575-577. Multicollinearity: O’Brien, R. M. (2007). caution regarding rules thumb variance inflation factors. Quality & Quantity, 41(5), 673-690. Belsley, D. ., Kuh, E., & Welsch, R. E. (1980). Regression Diagnostics. Wiley. Software: INLA: Rue, H., Martino, S., & Chopin, N. (2009). Approximate Bayesian inference latent Gaussian models. Journal Royal Statistical Society: Series B, 71(2), 319-392. mgcv: Wood, S. N. (2017). Generalized Additive Models: Introduction R (2nd ed.). Chapman Hall/CRC.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/advanced.html","id":"see-also","dir":"Articles","previous_headings":"8. References","what":"See Also","title":"Advanced Topics","text":"vignette(\"quickstart\") - 5-minute introduction vignette(\"workflows\") - Real-world examples vignette(\"comparison\") - vs caret, Boruta, glmnet vignette(\"corrselect_vignette\") - Original exact methods vignette ?corrPrune - Association-based pruning ?modelPrune - Model-based pruning ?corrSelect - Exact subset enumeration","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Comparison with Alternatives","text":"vignette compares corrselect common alternatives handling multicollinearity variable selection: caret::findCorrelation(): Greedy correlation-based removal Boruta: Random forest feature importance glmnet: LASSO/Ridge regularization Manual VIF removal: Iterative variance inflation factor pruning","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"test-dataset","dir":"Articles","previous_headings":"","what":"Test Dataset","title":"Comparison with Alternatives","text":"’ll use bioclim_example dataset 19 WorldClim bioclimatic variables: Let’s visualize correlation structure:","code":"data(bioclim_example) predictors <- bioclim_example[, -1]  # Exclude response response <- bioclim_example[, 1]  cat(\"Number of variables:\", ncol(predictors), \"\\n\") #> Number of variables: 19 cat(\"Sample size:\", nrow(predictors), \"\\n\") #> Sample size: 100 cat(\"Response variable: species_richness\\n\") #> Response variable: species_richness cor_matrix <- cor(predictors)  # Custom color palette col_pal <- colorRampPalette(c(\"#3B4992\", \"white\", \"#EE0000\"))(100)  # Correlation heatmap par(mar = c(1, 1, 2, 1)) image(1:ncol(cor_matrix), 1:nrow(cor_matrix), t(cor_matrix[nrow(cor_matrix):1, ]),       col = col_pal,       xlab = \"\", ylab = \"\", axes = FALSE,       main = \"Correlation Matrix (19 Bioclimatic Variables)\",       zlim = c(-1, 1)) axis(1, at = 1:ncol(cor_matrix), labels = colnames(cor_matrix), las = 2, cex.axis = 0.7) axis(2, at = ncol(cor_matrix):1, labels = colnames(cor_matrix), las = 2, cex.axis = 0.7)  # Add correlation values for (i in 1:ncol(cor_matrix)) {   for (j in 1:nrow(cor_matrix)) {     text(i, nrow(cor_matrix) - j + 1, sprintf(\"%.2f\", cor_matrix[j, i]), cex = 0.5)   } }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-1-caretfindcorrelation","dir":"Articles","previous_headings":"","what":"Comparison 1: caret::findCorrelation()","title":"Comparison with Alternatives","text":"caret’s findCorrelation() uses greedy heuristic remove correlated variables.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"how-it-works","dir":"Articles","previous_headings":"Comparison 1: caret::findCorrelation()","what":"How It Works","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"caret\", quietly = TRUE)) {   # Run caret   to_remove_caret <- caret::findCorrelation(cor_matrix, cutoff = 0.7)   result_caret <- predictors[, -to_remove_caret]    cat(\"Variables removed by caret:\", length(to_remove_caret), \"\\n\")   cat(\"Variables kept:\", ncol(result_caret), \"\\n\")   cat(\"Removed variables:\", colnames(predictors)[to_remove_caret], \"\\n\") } #> Variables removed by caret: 9  #> Variables kept: 10  #> Removed variables: BIO8 BIO7 BIO5 BIO4 BIO3 BIO9 BIO1 BIO11 BIO15"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"corrselectcorrprune-comparison","dir":"Articles","previous_headings":"Comparison 1: caret::findCorrelation()","what":"corrselect::corrPrune() Comparison","title":"Comparison with Alternatives","text":"","code":"# Run corrselect (exact mode) result_corrselect <- corrPrune(predictors, threshold = 0.7, mode = \"exact\")  cat(\"\\nVariables removed by corrselect:\", length(attr(result_corrselect, \"removed_vars\")), \"\\n\") #>  #> Variables removed by corrselect: 0 cat(\"Variables kept:\", ncol(result_corrselect), \"\\n\") #> Variables kept: 12 cat(\"Removed variables:\", attr(result_corrselect, \"removed_vars\"), \"\\n\") #> Removed variables:"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"visual-comparison","dir":"Articles","previous_headings":"Comparison 1: caret::findCorrelation()","what":"Visual Comparison","title":"Comparison with Alternatives","text":"","code":"# Extract correlations cor_orig <- cor(predictors) cor_corrselect <- cor(result_corrselect)  if (requireNamespace(\"caret\", quietly = TRUE)) {   cor_caret <- cor(result_caret)    # Overlaid histogram comparing all three   hist(abs(cor_orig[upper.tri(cor_orig)]),        breaks = 30,        main = \"Distribution of Absolute Correlations\",        xlab = \"Absolute Correlation\",        col = rgb(0.5, 0.5, 0.5, 0.4),        xlim = c(0, 1))    hist(abs(cor_caret[upper.tri(cor_caret)]),        breaks = 30,        col = rgb(0.8, 0.2, 0.2, 0.4),        add = TRUE)    hist(abs(cor_corrselect[upper.tri(cor_corrselect)]),        breaks = 30,        col = rgb(0.2, 0.5, 0.8, 0.4),        add = TRUE)    abline(v = 0.7, col = \"black\", lwd = 2, lty = 2)   legend(\"topright\",          legend = c(paste0(\"Original (\", ncol(predictors), \" vars)\"),                     paste0(\"caret (\", ncol(result_caret), \" vars)\"),                     paste0(\"corrselect (\", ncol(result_corrselect), \" vars)\"),                     \"Threshold\"),          fill = c(rgb(0.5, 0.5, 0.5, 0.4), rgb(0.8, 0.2, 0.2, 0.4),                   rgb(0.2, 0.5, 0.8, 0.4), NA),          border = c(\"black\", \"black\", \"black\", NA),          lty = c(NA, NA, NA, 2),          lwd = c(NA, NA, NA, 2),          bty = \"n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"key-differences","dir":"Articles","previous_headings":"Comparison 1: caret::findCorrelation()","what":"Key Differences","title":"Comparison with Alternatives","text":"caret: Quick exploratory analysis reproducibility critical. corrselect: Reproducible results maximal variable retention.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"reproducible-benchmarks","dir":"Articles","previous_headings":"Comparison 1: caret::findCorrelation()","what":"Reproducible Benchmarks","title":"Comparison with Alternatives","text":"Using cor_example dataset (20 variables known block structure): Timing comparison threshold = 0.7: Visualization timing results:  Scaling problem size:","code":"data(cor_example)  # Ensure matrix is exactly symmetric (fix any floating point asymmetries) cor_example <- (cor_example + t(cor_example)) / 2 diag(cor_example) <- 1  cat(\"Matrix dimensions:\", nrow(cor_example), \"x\", ncol(cor_example), \"\\n\") #> Matrix dimensions: 20 x 20 cat(\"Mean correlation:\", mean(abs(cor_example[upper.tri(cor_example)])), \"\\n\") #> Mean correlation: 0.2021275 if (requireNamespace(\"caret\", quietly = TRUE) &&     requireNamespace(\"microbenchmark\", quietly = TRUE)) {    # Benchmark with microbenchmark   mb <- microbenchmark::microbenchmark(     caret = {       to_remove <- caret::findCorrelation(cor_example, cutoff = 0.7)       cor_example[, -to_remove]     },     corrselect_greedy = {       MatSelect(cor_example, threshold = 0.7, mode = \"greedy\")     },     corrselect_exact = {       MatSelect(cor_example, threshold = 0.7, mode = \"exact\")     },     times = 50   )    print(mb) } #> Unit: microseconds #>               expr   min    lq    mean median    uq   max neval cld #>              caret 262.8 312.9 342.116 329.85 366.0 467.2    50  a  #>  corrselect_greedy 331.7 353.1 387.340 376.95 413.9 528.0    50   b #>   corrselect_exact 326.9 357.2 385.456 379.35 397.3 570.0    50   b if (requireNamespace(\"caret\", quietly = TRUE) &&     requireNamespace(\"microbenchmark\", quietly = TRUE)) {    # Convert to milliseconds   mb_df <- data.frame(     method = mb$expr,     time_ms = mb$time / 1e6   )    # Compute medians for plotting   method_levels <- c(\"caret\", \"corrselect_greedy\", \"corrselect_exact\")   method_labels <- c(\"caret\", \"corrselect (greedy)\", \"corrselect (exact)\")    medians <- sapply(method_levels, function(m) {     median(mb_df$time_ms[mb_df$method == m])   })    # Barplot   par(mar = c(8, 4, 4, 2))   bp <- barplot(medians,                 names.arg = method_labels,                 las = 2,                 col = c(rgb(0.8, 0.2, 0.2, 0.7),                         rgb(0.2, 0.5, 0.8, 0.7),                         rgb(0.4, 0.4, 0.4, 0.7)),                 ylab = \"Median Time (ms)\",                 main = \"Timing Comparison (p=20, threshold=0.7)\",                 cex.names = 0.8)    # Add median values on bars   text(bp, medians, labels = sprintf(\"%.2f ms\", medians),        pos = 3, cex = 0.8) } if (requireNamespace(\"caret\", quietly = TRUE)) {    set.seed(20250125)   p_values <- c(10, 20, 30, 40, 50)   times_caret <- numeric(length(p_values))   times_corrselect_greedy <- numeric(length(p_values))   times_corrselect_exact <- numeric(length(p_values))    for (i in seq_along(p_values)) {     p <- p_values[i]      # Generate test matrix     mat <- matrix(rnorm(p * (p + 50)), ncol = p)     cor_mat <- cor(mat)      # Time caret     times_caret[i] <- system.time({       caret::findCorrelation(cor_mat, cutoff = 0.7)     })[3]      # Time corrselect greedy     times_corrselect_greedy[i] <- system.time({       MatSelect(cor_mat, threshold = 0.7, mode = \"greedy\")     })[3]      # Time corrselect exact (skip for p > 30 to avoid long runtime)     if (p <= 30) {       times_corrselect_exact[i] <- system.time({         MatSelect(cor_mat, threshold = 0.7, mode = \"exact\")       })[3]     } else {       times_corrselect_exact[i] <- NA     }   }    # Plot scaling   plot(p_values, times_caret * 1000,        type = \"b\", col = rgb(0.8, 0.2, 0.2), pch = 19, lwd = 2,        xlab = \"Number of Variables (p)\",        ylab = \"Time (ms)\",        main = \"Scaling with Problem Size\",        log = \"y\", ylim = c(0.1, max(times_corrselect_exact * 1000, na.rm = TRUE)))    lines(p_values, times_corrselect_greedy * 1000,         type = \"b\", col = rgb(0.2, 0.5, 0.8), pch = 19, lwd = 2)    lines(p_values[!is.na(times_corrselect_exact)],         times_corrselect_exact[!is.na(times_corrselect_exact)] * 1000,         type = \"b\", col = rgb(0.4, 0.4, 0.4), pch = 19, lwd = 2)    legend(\"topleft\",          legend = c(\"caret\", \"corrselect (greedy)\", \"corrselect (exact)\"),          col = c(rgb(0.8, 0.2, 0.2), rgb(0.2, 0.5, 0.8), rgb(0.4, 0.4, 0.4)),          lwd = 2, pch = 19, bty = \"n\") } #> Warning in xy.coords(x, y, xlabel, ylabel, log): 5 y values <= 0 omitted from #> logarithmic plot #> Warning in plot.window(...): nonfinite axis=2 limits [GScale(-1,-inf,..); #> log=TRUE] -- corrected now"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-2-boruta","dir":"Articles","previous_headings":"","what":"Comparison 2: Boruta","title":"Comparison with Alternatives","text":"Boruta identifies important variables via random forest permutation tests. fundamentally different removing redundant variables.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"different-questions","dir":"Articles","previous_headings":"Comparison 2: Boruta","what":"Different Questions","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"Boruta\", quietly = TRUE)) {   library(Boruta)    # Boruta: which variables predict species richness?   set.seed(123)   boruta_result <- Boruta(species_richness ~ ., data = bioclim_example, maxRuns = 100)    cat(\"Boruta results:\\n\")   print(table(boruta_result$finalDecision))    important_vars <- names(boruta_result$finalDecision[boruta_result$finalDecision == \"Confirmed\"])   cat(\"\\nConfirmed important variables:\", important_vars, \"\\n\")   cat(\"Number of important variables:\", length(important_vars), \"\\n\") } # corrselect: which variables are redundant? corrselect_result <- corrPrune(predictors, threshold = 0.7) cat(\"\\ncorrselect results:\\n\") #>  #> corrselect results: cat(\"Non-redundant variables:\", ncol(corrselect_result), \"\\n\") #> Non-redundant variables: 12 cat(\"Variables:\", names(corrselect_result), \"\\n\") #> Variables: BIO1 BIO3 BIO6 BIO9 BIO11 BIO12 BIO13 BIO14 BIO16 BIO17 BIO18 BIO19"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"combined-workflow","dir":"Articles","previous_headings":"Comparison 2: Boruta","what":"Combined Workflow","title":"Comparison with Alternatives","text":"Boruta corrselect can used sequentially: Workflow components: corrPrune reduces variable set based correlation structure Boruta screens reduced set predictive importance Final model contains variables non-redundant statistically important addresses redundancy variable importance reproducible pruning RF-based importance tests required.","code":"# Remove redundant predictors (corrselect) data_pruned <- corrPrune(raw_data, threshold = 0.7)  # Identify important predictors (Boruta) boruta_result <- Boruta(response ~ ., data = data_pruned) final_vars <- names(boruta_result$finalDecision[boruta_result$finalDecision == \"Confirmed\"])  # Final model final_model <- lm(response ~ ., data = data_pruned[, c(\"response\", final_vars)])"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-3-glmnet-lassoridge","dir":"Articles","previous_headings":"","what":"Comparison 3: glmnet (LASSO/Ridge)","title":"Comparison with Alternatives","text":"glmnet performs variable selection via L1/L2 regularization, shrinking coefficients toward zero.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"how-it-works-1","dir":"Articles","previous_headings":"Comparison 3: glmnet (LASSO/Ridge)","what":"How It Works","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"glmnet\", quietly = TRUE)) {   library(glmnet)    # Prepare data   X <- as.matrix(predictors)   y <- response    # Fit LASSO with cross-validation   set.seed(123)   cv_lasso <- cv.glmnet(X, y, alpha = 1)    # Extract non-zero coefficients at lambda.1se   coef_lasso <- coef(cv_lasso, s = \"lambda.1se\")   selected_lasso <- rownames(coef_lasso)[coef_lasso[, 1] != 0][-1]  # Remove intercept    cat(\"glmnet selected variables:\", selected_lasso, \"\\n\")   cat(\"Number of variables:\", length(selected_lasso), \"\\n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"compare-prediction-performance","dir":"Articles","previous_headings":"Comparison 3: glmnet (LASSO/Ridge)","what":"Compare Prediction Performance","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"glmnet\", quietly = TRUE)) {   # Model 1: glmnet-selected variables (OLS)   model_glmnet <- lm(species_richness ~ .,                      data = bioclim_example[, c(\"species_richness\", selected_lasso)])    # Model 2: corrselect-selected variables (OLS)   model_corrselect <- lm(species_richness ~ .,                          data = cbind(species_richness = response, result_corrselect))    cat(\"\\nPrediction performance (R²):\\n\")   cat(\"glmnet variables:\", round(summary(model_glmnet)$r.squared, 3), \"\\n\")   cat(\"corrselect variables:\", round(summary(model_corrselect)$r.squared, 3), \"\\n\")    cat(\"\\nNumber of predictors:\\n\")   cat(\"glmnet:\", length(selected_lasso), \"\\n\")   cat(\"corrselect:\", ncol(result_corrselect), \"\\n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"visual-coefficient-comparison","dir":"Articles","previous_headings":"Comparison 3: glmnet (LASSO/Ridge)","what":"Visual: Coefficient Comparison","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"glmnet\", quietly = TRUE)) {   par(mfrow = c(1, 2), mar = c(8, 4, 3, 2))    # glmnet coefficients (shrinkage)   coef_vals <- coef_lasso[coef_lasso[, 1] != 0, ][-1]   barplot(sort(abs(coef_vals), decreasing = TRUE),           las = 2,           main = \"glmnet: Shrunk Coefficients\",           ylab = \"Absolute Coefficient Value\",           col = \"salmon\",           cex.names = 0.7)    # corrselect: unbiased OLS coefficients   coef_corrselect <- coef(model_corrselect)[-1]  # Remove intercept   barplot(sort(abs(coef_corrselect), decreasing = TRUE),           las = 2,           main = \"corrselect: Unbiased OLS Coefficients\",           ylab = \"Absolute Coefficient Value\",           col = \"lightblue\",           cex.names = 0.7) }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"key-differences-1","dir":"Articles","previous_headings":"Comparison 3: glmnet (LASSO/Ridge)","what":"Key Differences","title":"Comparison with Alternatives","text":"glmnet: Prediction-focused; coefficient interpretability secondary. corrselect: Interpretability focus; unbiased coefficients; exploratory analysis without response variable.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-4-modelprune-vs-manual-vif-removal","dir":"Articles","previous_headings":"","what":"Comparison 4: modelPrune() vs Manual VIF Removal","title":"Comparison with Alternatives","text":"regression models, VIF-based multicollinearity removal common. Let’s compare corrselect’s modelPrune() manual VIF removal.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"manual-vif-removal-traditional-approach","dir":"Articles","previous_headings":"Comparison 4: modelPrune() vs Manual VIF Removal","what":"Manual VIF Removal (Traditional Approach)","title":"Comparison with Alternatives","text":"","code":"# Manual iterative VIF removal manual_vif_removal <- function(formula, data, threshold = 5) {   require(car)    model <- lm(formula, data = data)   vif_vals <- car::vif(model)    iterations <- 0   while (max(vif_vals) > threshold && iterations < 100) {     iterations <- iterations + 1      # Remove variable with highest VIF     var_to_remove <- names(which.max(vif_vals))     cat(\"Iteration\", iterations, \": Removing\", var_to_remove, \"(VIF =\",         round(max(vif_vals), 2), \")\\n\")      # Update formula     formula_str <- paste(deparse(formula), collapse = \"\")     formula_str <- gsub(paste0(\"\\\\+\\\\s*\", var_to_remove), \"\", formula_str)     formula_str <- gsub(paste0(var_to_remove, \"\\\\s*\\\\+\"), \"\", formula_str)     formula <- as.formula(formula_str)      # Refit model     model <- lm(formula, data = data)     vif_vals <- car::vif(model)   }    list(model = model, iterations = iterations, vif = vif_vals) }  # Run manual VIF removal if (requireNamespace(\"car\", quietly = TRUE)) {   cat(\"Manual VIF removal (iterative):\\n\")   manual_result <- manual_vif_removal(species_richness ~ ., data = bioclim_example, threshold = 5)   cat(\"\\nFinal VIF values:\\n\")   print(round(manual_result$vif, 2))   cat(\"\\nTotal iterations:\", manual_result$iterations, \"\\n\") } #> Manual VIF removal (iterative): #> Loading required package: car #> Loading required package: carData #> Iteration 1 : Removing BIO2 (VIF = 5.83 ) #> Iteration 2 : Removing BIO2 (VIF = 5.83 ) #> Iteration 3 : Removing BIO2 (VIF = 5.83 ) #> Iteration 4 : Removing BIO2 (VIF = 5.83 ) #> Iteration 5 : Removing BIO2 (VIF = 5.83 ) #> Iteration 6 : Removing BIO2 (VIF = 5.83 ) #> Iteration 7 : Removing BIO2 (VIF = 5.83 ) #> Iteration 8 : Removing BIO2 (VIF = 5.83 ) #> Iteration 9 : Removing BIO2 (VIF = 5.83 ) #> Iteration 10 : Removing BIO2 (VIF = 5.83 ) #> Iteration 11 : Removing BIO2 (VIF = 5.83 ) #> Iteration 12 : Removing BIO2 (VIF = 5.83 ) #> Iteration 13 : Removing BIO2 (VIF = 5.83 ) #> Iteration 14 : Removing BIO2 (VIF = 5.83 ) #> Iteration 15 : Removing BIO2 (VIF = 5.83 ) #> Iteration 16 : Removing BIO2 (VIF = 5.83 ) #> Iteration 17 : Removing BIO2 (VIF = 5.83 ) #> Iteration 18 : Removing BIO2 (VIF = 5.83 ) #> Iteration 19 : Removing BIO2 (VIF = 5.83 ) #> Iteration 20 : Removing BIO2 (VIF = 5.83 ) #> Iteration 21 : Removing BIO2 (VIF = 5.83 ) #> Iteration 22 : Removing BIO2 (VIF = 5.83 ) #> Iteration 23 : Removing BIO2 (VIF = 5.83 ) #> Iteration 24 : Removing BIO2 (VIF = 5.83 ) #> Iteration 25 : Removing BIO2 (VIF = 5.83 ) #> Iteration 26 : Removing BIO2 (VIF = 5.83 ) #> Iteration 27 : Removing BIO2 (VIF = 5.83 ) #> Iteration 28 : Removing BIO2 (VIF = 5.83 ) #> Iteration 29 : Removing BIO2 (VIF = 5.83 ) #> Iteration 30 : Removing BIO2 (VIF = 5.83 ) #> Iteration 31 : Removing BIO2 (VIF = 5.83 ) #> Iteration 32 : Removing BIO2 (VIF = 5.83 ) #> Iteration 33 : Removing BIO2 (VIF = 5.83 ) #> Iteration 34 : Removing BIO2 (VIF = 5.83 ) #> Iteration 35 : Removing BIO2 (VIF = 5.83 ) #> Iteration 36 : Removing BIO2 (VIF = 5.83 ) #> Iteration 37 : Removing BIO2 (VIF = 5.83 ) #> Iteration 38 : Removing BIO2 (VIF = 5.83 ) #> Iteration 39 : Removing BIO2 (VIF = 5.83 ) #> Iteration 40 : Removing BIO2 (VIF = 5.83 ) #> Iteration 41 : Removing BIO2 (VIF = 5.83 ) #> Iteration 42 : Removing BIO2 (VIF = 5.83 ) #> Iteration 43 : Removing BIO2 (VIF = 5.83 ) #> Iteration 44 : Removing BIO2 (VIF = 5.83 ) #> Iteration 45 : Removing BIO2 (VIF = 5.83 ) #> Iteration 46 : Removing BIO2 (VIF = 5.83 ) #> Iteration 47 : Removing BIO2 (VIF = 5.83 ) #> Iteration 48 : Removing BIO2 (VIF = 5.83 ) #> Iteration 49 : Removing BIO2 (VIF = 5.83 ) #> Iteration 50 : Removing BIO2 (VIF = 5.83 ) #> Iteration 51 : Removing BIO2 (VIF = 5.83 ) #> Iteration 52 : Removing BIO2 (VIF = 5.83 ) #> Iteration 53 : Removing BIO2 (VIF = 5.83 ) #> Iteration 54 : Removing BIO2 (VIF = 5.83 ) #> Iteration 55 : Removing BIO2 (VIF = 5.83 ) #> Iteration 56 : Removing BIO2 (VIF = 5.83 ) #> Iteration 57 : Removing BIO2 (VIF = 5.83 ) #> Iteration 58 : Removing BIO2 (VIF = 5.83 ) #> Iteration 59 : Removing BIO2 (VIF = 5.83 ) #> Iteration 60 : Removing BIO2 (VIF = 5.83 ) #> Iteration 61 : Removing BIO2 (VIF = 5.83 ) #> Iteration 62 : Removing BIO2 (VIF = 5.83 ) #> Iteration 63 : Removing BIO2 (VIF = 5.83 ) #> Iteration 64 : Removing BIO2 (VIF = 5.83 ) #> Iteration 65 : Removing BIO2 (VIF = 5.83 ) #> Iteration 66 : Removing BIO2 (VIF = 5.83 ) #> Iteration 67 : Removing BIO2 (VIF = 5.83 ) #> Iteration 68 : Removing BIO2 (VIF = 5.83 ) #> Iteration 69 : Removing BIO2 (VIF = 5.83 ) #> Iteration 70 : Removing BIO2 (VIF = 5.83 ) #> Iteration 71 : Removing BIO2 (VIF = 5.83 ) #> Iteration 72 : Removing BIO2 (VIF = 5.83 ) #> Iteration 73 : Removing BIO2 (VIF = 5.83 ) #> Iteration 74 : Removing BIO2 (VIF = 5.83 ) #> Iteration 75 : Removing BIO2 (VIF = 5.83 ) #> Iteration 76 : Removing BIO2 (VIF = 5.83 ) #> Iteration 77 : Removing BIO2 (VIF = 5.83 ) #> Iteration 78 : Removing BIO2 (VIF = 5.83 ) #> Iteration 79 : Removing BIO2 (VIF = 5.83 ) #> Iteration 80 : Removing BIO2 (VIF = 5.83 ) #> Iteration 81 : Removing BIO2 (VIF = 5.83 ) #> Iteration 82 : Removing BIO2 (VIF = 5.83 ) #> Iteration 83 : Removing BIO2 (VIF = 5.83 ) #> Iteration 84 : Removing BIO2 (VIF = 5.83 ) #> Iteration 85 : Removing BIO2 (VIF = 5.83 ) #> Iteration 86 : Removing BIO2 (VIF = 5.83 ) #> Iteration 87 : Removing BIO2 (VIF = 5.83 ) #> Iteration 88 : Removing BIO2 (VIF = 5.83 ) #> Iteration 89 : Removing BIO2 (VIF = 5.83 ) #> Iteration 90 : Removing BIO2 (VIF = 5.83 ) #> Iteration 91 : Removing BIO2 (VIF = 5.83 ) #> Iteration 92 : Removing BIO2 (VIF = 5.83 ) #> Iteration 93 : Removing BIO2 (VIF = 5.83 ) #> Iteration 94 : Removing BIO2 (VIF = 5.83 ) #> Iteration 95 : Removing BIO2 (VIF = 5.83 ) #> Iteration 96 : Removing BIO2 (VIF = 5.83 ) #> Iteration 97 : Removing BIO2 (VIF = 5.83 ) #> Iteration 98 : Removing BIO2 (VIF = 5.83 ) #> Iteration 99 : Removing BIO2 (VIF = 5.83 ) #> Iteration 100 : Removing BIO2 (VIF = 5.83 ) #>  #> Final VIF values: #>  BIO1  BIO2  BIO3  BIO4  BIO5  BIO6  BIO7  BIO8  BIO9 BIO10 BIO11 BIO12 BIO13  #>  3.42  5.83  5.19  5.09  5.18  4.47  5.74  5.67  4.38  5.00  3.11  1.84  2.61  #> BIO14 BIO15 BIO16 BIO17 BIO18 BIO19  #>  3.18  3.03  2.59  3.01  3.14  1.80  #>  #> Total iterations: 100"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"modelprune-comparison","dir":"Articles","previous_headings":"Comparison 4: modelPrune() vs Manual VIF Removal","what":"modelPrune() Comparison","title":"Comparison with Alternatives","text":"","code":"# Run modelPrune modelprune_result <- modelPrune(species_richness ~ ., data = bioclim_example, limit = 5)  cat(\"\\nmodelPrune results:\\n\") #>  #> modelPrune results: cat(\"Variables removed:\", attr(modelprune_result, \"removed_vars\"), \"\\n\") #> Variables removed: BIO2 BIO7 BIO5 cat(\"Variables kept:\", length(attr(modelprune_result, \"selected_vars\")), \"\\n\") #> Variables kept: 16  # Extract final model final_model <- attr(modelprune_result, \"final_model\") if (requireNamespace(\"car\", quietly = TRUE)) {   cat(\"\\nFinal VIF values:\\n\")   print(round(car::vif(final_model), 2)) } #>  #> Final VIF values: #>  BIO1  BIO3  BIO4  BIO6  BIO8  BIO9 BIO10 BIO11 BIO12 BIO13 BIO14 BIO15 BIO16  #>  2.09  3.68  3.81  2.57  4.03  4.27  4.96  3.06  1.76  2.51  3.11  3.01  2.43  #> BIO17 BIO18 BIO19  #>  2.88  2.82  1.70"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"visual-vif-comparison","dir":"Articles","previous_headings":"Comparison 4: modelPrune() vs Manual VIF Removal","what":"Visual: VIF Comparison","title":"Comparison with Alternatives","text":"","code":"if (requireNamespace(\"car\", quietly = TRUE)) {   # Compute VIF for original model   model_full <- lm(species_richness ~ ., data = bioclim_example)   vif_before <- car::vif(model_full)    # VIF after modelPrune   vif_after <- car::vif(final_model)    # Combined barplot   par(mar = c(8, 4, 4, 2))   all_vars <- unique(c(names(vif_before), names(vif_after)))   vif_combined <- data.frame(     before = vif_before[match(all_vars, names(vif_before))],     after = vif_after[match(all_vars, names(vif_after))]   )   vif_combined[is.na(vif_combined)] <- 0   vif_combined <- vif_combined[order(vif_combined$before, decreasing = TRUE), ]    # Show top 15   n_show <- min(15, nrow(vif_combined))   barplot(t(as.matrix(vif_combined[1:n_show, ])),           beside = TRUE,           las = 2,           main = \"VIF Before and After modelPrune()\",           ylab = \"VIF\",           col = c(rgb(0.8, 0.2, 0.2, 0.7), rgb(0.2, 0.5, 0.8, 0.7)),           cex.names = 0.6,           names.arg = rownames(vif_combined)[1:n_show])   abline(h = 5, col = \"black\", lwd = 2, lty = 2)   legend(\"topright\",          legend = c(\"Before\", \"After\", \"Limit = 5\"),          fill = c(rgb(0.8, 0.2, 0.2, 0.7), rgb(0.2, 0.5, 0.8, 0.7), NA),          border = c(\"black\", \"black\", NA),          lty = c(NA, NA, 2),          lwd = c(NA, NA, 2),          bty = \"n\") }"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"comparison-summary","dir":"Articles","previous_headings":"Comparison 4: modelPrune() vs Manual VIF Removal","what":"Comparison Summary","title":"Comparison with Alternatives","text":"Compared manual VIF removal, modelPrune(): Automated: manual iteration required Optimized: Uses graph algorithms find optimal subset force_in support: Protect important variables removal Transparent: Clear documentation removed variables Consistent: Always returns result","code":""},{"path":[]},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"design-characteristics","dir":"Articles","previous_headings":"Overview of Approaches","what":"Design Characteristics","title":"Comparison with Alternatives","text":"corrselect: Reproducible multicollinearity removal Maximal variable retention correlation constraint (exact mode) Model-agnostic preprocessing Mixed-type data (numeric, factors, ordered) Protected variables (force_in) Unbiased coefficient estimates (shrinkage) Alternatives: caret: Quick exploration; reproducibility required Boruta: Feature importance screening; redundancy removal glmnet: Prediction-focused; coefficient shrinkage Manual VIF: Educational contexts; full manual control","code":""},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"combined-approach-example","dir":"Articles","previous_headings":"Overview of Approaches","what":"Combined Approach Example","title":"Comparison with Alternatives","text":"","code":"# Example workflow combining multiple approaches data_cleaned <- corrPrune(raw_data, threshold = 0.7)          # Remove redundancy model_data <- modelPrune(response ~ ., data_cleaned, limit = 5)  # Ensure VIF < 5 final_model <- lm(response ~ ., data = model_data)           # Interpretable model"},{"path":"https://gcol33.github.io/corrselect/articles/comparison.html","id":"see-also","dir":"Articles","previous_headings":"Overview of Approaches","what":"See Also","title":"Comparison with Alternatives","text":"vignette(\"quickstart\") - Quick introduction corrselect vignette(\"workflows\") - Real-world workflow examples vignette(\"advanced\") - Advanced features customization vignette(\"theory\") - Theoretical foundations formulation","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Correlation Subset Selection with corrselect","text":"corrselect identifies maximal subsets variables whose pairwise correlations stay chosen threshold. process reduces multicollinearity redundancy modeling, preserving interpretability. Unlike greedy stepwise approaches, corrselect exhaustively searches valid subsets using fast, exact algorithms. fully model-agnostic, making suitable preprocessing step regression, clustering, feature selection, analyses. Given threshold t∈(0,1)t \\(0,1), functions corrSelect() (data-frame interface) MatSelect() (matrix interface) enumerate maximal subsets SS variables satisfying: ∀,j∈S,≠j:|rij|<t \\forall , j \\S,\\ \\neq j: \\ |r_{ij}| < t rijr_{ij} denotes chosen correlation measure variables ii jj. Enumeration relies two exact graph-theoretic algorithms: Eppstein–Löffler–Strash (ELS), degeneracy-ordered backtracking algorithm optimized sparse graphs. Bron–Kerbosch (BK), classical recursive clique-finding method, optional pivoting reduce search space. Results returned CorrCombo S4 object containing subset’s variable names summary statistics (avg_corr, min_corr, max_corr). can extract subsets original data via corrSubset(). procedure depend downstream model, cleanly separates “feature curation” “model fitting” supports multiple correlation measures (pearson, spearman, kendall, bicor, distance, maximal).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"simulated-numeric-example","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Simulated numeric example","title":"Correlation Subset Selection with corrselect","text":"","code":"set.seed(42) n <- 100 df <- data.frame(   A = rnorm(n),   B = rnorm(n),   C = rnorm(n),   D = rnorm(n),   E = rnorm(n) ) df$F <- df$A * 0.9 + rnorm(n, sd = 0.1)  # strongly correlated with A"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"basic-selection","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Basic selection","title":"Correlation Subset Selection with corrselect","text":"","code":"res <- corrSelect(df, threshold = 0.7) res #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 as.data.frame(res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E corrSubset(res, df, which = 1)[1:10,] #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"forcing-variables-into-all-subsets","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Forcing variables into all subsets","title":"Correlation Subset Selection with corrselect","text":"","code":"res2 <- corrSelect(df, threshold = 0.7, force_in = \"A\") res2 #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   100 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"using-a-different-correlation-method","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Using a different correlation method","title":"Correlation Subset Selection with corrselect","text":"","code":"res3 <- corrSelect(df, threshold = 0.6, cor_method = \"spearman\") res3 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.600 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"matrix-interface-matselect","dir":"Articles","previous_headings":"","what":"Matrix Interface (MatSelect)","title":"Correlation Subset Selection with corrselect","text":"already computed correlation matrix want apply method precomputed correlations: Selecting subsets: Force variable 1 every subset:","code":"mat <- cor(df) res4 <- MatSelect(mat, threshold = 0.7) res4 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.500 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5, force_in = 1) #> CorrCombo object #> ----------------- #>   Method:      els #>   Threshold:   0.500 #>   Subsets:     1 valid combinations #>   Data Rows:   6 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"mixed-data-types-assocselect","dir":"Articles","previous_headings":"","what":"Mixed Data Types (assocSelect)","title":"Correlation Subset Selection with corrselect","text":"","code":"df_ass <- data.frame(   height = rnorm(15, 170, 10),   weight = rnorm(15, 70, 12),   group  = factor(rep(LETTERS[1:3], each = 5)),   score  = ordered(sample(c(\"low\",\"med\",\"high\"), 15, TRUE)) )  # keep every subset whose internal associations ≤ 0.6 res5 <- assocSelect(df_ass, threshold = 0.6) res5 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.600 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.267  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"changing-correlation-method","dir":"Articles","previous_headings":"","what":"Changing Correlation Method","title":"Correlation Subset Selection with corrselect","text":"default, corrSelect() uses Pearson correlation. can choose alternatives cor_method argument: \"pearson\": linear correlation (default) \"spearman\": rank-based monotonic association \"kendall\": Kendall’s tau \"bicor\": robust biweight midcorrelation (WGCNA::bicor) \"distance\": distance correlation (energy::dcor) \"maximal\": maximal information coefficient (minerva::mine) Example:","code":"res6 <- corrSelect(df, threshold = 0.7, cor_method = \"spearman\") res6 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"handling-mixed-data-types","dir":"Articles","previous_headings":"","what":"Handling Mixed Data Types","title":"Correlation Subset Selection with corrselect","text":"function assocSelect() extends corrSelect() support mixed data types — including numeric, factor, ordered variables — using appropriate association measures variable pair. Instead single correlation matrix, constructs generalized association matrix using following logic: defaults numeric-numeric, numeric-ordered, ordered-ordered associations can changed via arguments: combinations use fixed methods (eta cramersv) appropriate measuring association strength.","code":"assocSelect(df_ass,   method_num_num = \"kendall\",   method_num_ord = \"spearman\",   method_ord_ord = \"kendall\" ) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = kendall, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.270  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"example-with-mixed-types","dir":"Articles","previous_headings":"Handling Mixed Data Types","what":"Example with Mixed Types","title":"Correlation Subset Selection with corrselect","text":"pairwise association bounded [0,1] treated analogously correlation.","code":"df_ass <- data.frame(   height = rnorm(10),   weight = rnorm(10),   group  = factor(sample(c(\"A\", \"B\"), 10, replace = TRUE)),   score  = ordered(sample(1:3, 10, replace = TRUE)) )  res7 <- assocSelect(df_ass, threshold = 1, method = \"bron-kerbosch\", use_pivot = TRUE) res7 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   1.000 #>   Subsets:     1 valid combinations #>   Data Rows:   10 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.336  0.495     4"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"theory","dir":"Articles","previous_headings":"","what":"Theory","title":"Correlation Subset Selection with corrselect","text":"Given symmetric correlation matrix R∈ℝp×pR \\\\mathbb{R}^{p \\times p}, seek maximal subsets S⊆{1,…,p}S \\subseteq \\{1, \\dots, p\\} : ∀,j∈S,≠j:|Rij|<t \\forall , j \\S,\\ \\neq j: \\ |R_{ij}| < t fixed threshold t∈(0,1)t \\(0, 1). equivalent finding maximal cliques thresholded correlation graph, : Nodes represent variables Edges connect nodes whose absolute correlation threshold maximal clique corresponds variable subset extended without violating correlation limit.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"els-eppsteinlöfflerstrash","dir":"Articles","previous_headings":"Algorithms","what":"ELS (Eppstein–Löffler–Strash)","title":"Correlation Subset Selection with corrselect","text":"ELS algorithm efficiently enumerates maximal cliques sparse graph using degeneracy ordering: Compute degeneracy ordering v1,…,vpv_1, \\dots, v_p. ii, extend current clique SS {vi}\\{v_i\\} within candidate set C={vi+1,…,vp}C = \\{v_{+1}, \\dots, v_p\\}. Recursively build cliques, pruning vertices can added. Formally, define: extend(S,C)={S,C=∅,⋃v∈Cextend(S∪{v},C\\(N(v)∪{v})),otherwise. \\text{extend}(S, C) = \\begin{cases} S, & C = \\emptyset, \\\\ \\bigcup_{v \\C} \\text{extend}(S \\cup \\{v\\},\\ C \\setminus (N(v) \\cup \\{v\\})), & \\text{otherwise}. \\end{cases} ELS avoids redundant exploration, achieving good performance typical correlation graphs.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"bronkerbosch-with-pivoting","dir":"Articles","previous_headings":"Algorithms","what":"Bron–Kerbosch (with Pivoting)","title":"Correlation Subset Selection with corrselect","text":"classical Bron–Kerbosch algorithm enumerates maximal cliques via recursive backtracking optional pivoting: Let RR = current clique, PP = prospective nodes, XX = excluded nodes. : BK(R,P,X)={report(R),P=X=∅,v∈P\\N(u):BK(R∪{v},P∩N(v),X∩N(v)),P←P\\{v},X←X∪{v}. \\text{BK}(R, P, X) = \\begin{cases} \\text{report}(R), & P = X = \\emptyset, \\\\ \\text{} v \\P \\setminus N(u): \\\\ \\quad \\text{BK}(R \\cup \\{v\\},\\ P \\cap N(v),\\ X \\cap N(v)), \\ \\quad P \\leftarrow P \\setminus \\{v\\},\\ X \\leftarrow X \\cup \\{v\\}. \\end{cases} Choosing pivot u∈P∪Xu \\P \\cup X iterating P\\N(u)P \\setminus N(u) reduces recursive calls.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"why-corrselect","dir":"Articles","previous_headings":"","what":"Why corrselect?","title":"Correlation Subset Selection with corrselect","text":"existing R tools: Filter one variable time (e.g. findCorrelation) Use greedy backward-selection heuristics enumerate valid subsets corrselect uniquely provides: Exact enumeration maximal subsets Support multiple correlation measures Optional forcing variables Full inspection via CorrCombo objects Fast C++ implementations via Rcpp makes ideal pipelines interpretability completeness essential.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"inspecting-results","dir":"Articles","previous_headings":"","what":"Inspecting Results","title":"Correlation Subset Selection with corrselect","text":"Convert results downstream use: Extract individual subsets: Summarize correlation metrics:","code":"df_res <- as.data.frame(res) head(df_res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E lapply(corrSubset(res, df, which = 1:2), function(x) head(x, 10)) #> $Subset1 #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279 #>  #> $Subset2 #>              A          B          C            D           E #> 1   1.37095845  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.56469817  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.36312841 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.63286260  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.40426832 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.10612452  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.51152200 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.09465904 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   2.01842371  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10 -0.06271410  0.1191610 -0.1853780 -0.033487525 -1.90915279 # Number and size of subsets length(res@subset_list) #> [1] 2 summary(lengths(res@subset_list)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       5       5       5       5       5       5  # Summaries of within-subset correlations summary(res@max_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.185   0.185   0.185   0.185   0.185   0.185 summary(res@avg_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.08162 0.08185 0.08208 0.08208 0.08232 0.08255"},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"corrcombo-object-structure","dir":"Articles","previous_headings":"","what":"CorrCombo Object Structure","title":"Correlation Subset Selection with corrselect","text":"CorrCombo S4 object contains: subset_list: list character vectors (variable names) avg_corr, min_corr, max_corr: numeric vectors correlation metrics threshold, forced_in, search_type, cor_method, n_rows_used Attribute use_pivot (applicable) Inspect slots:","code":"str(res@subset_list) #> List of 2 #>  $ : chr [1:5] \"F\" \"B\" \"C\" \"D\" ... #>  $ : chr [1:5] \"A\" \"B\" \"C\" \"D\" ..."},{"path":"https://gcol33.github.io/corrselect/articles/corrselect_vignette.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Correlation Subset Selection with corrselect","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13 ucrt) #> Platform: x86_64-w64-mingw32/x64 #> Running under: Windows 11 x64 (build 26200) #>  #> Matrix products: default #>   LAPACK version 3.12.1 #>  #> locale: #> [1] LC_COLLATE=English_United States.utf8  #> [2] LC_CTYPE=English_United States.utf8    #> [3] LC_MONETARY=English_United States.utf8 #> [4] LC_NUMERIC=C                           #> [5] LC_TIME=English_United States.utf8     #>  #> time zone: Europe/Luxembourg #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] corrselect_3.0.0 #>  #> loaded via a namespace (and not attached): #>  [1] digest_0.6.37     desc_1.4.3        R6_2.6.1          fastmap_1.2.0     #>  [5] xfun_0.53         cachem_1.1.0      knitr_1.50        htmltools_0.5.8.1 #>  [9] rmarkdown_2.30    lifecycle_1.0.4   cli_3.6.5         sass_0.4.10       #> [13] pkgdown_2.1.3     textshaping_1.0.3 jquerylib_0.1.4   systemfonts_1.2.3 #> [17] compiler_4.5.1    tools_4.5.1       ragg_1.5.0        evaluate_1.0.5    #> [21] bslib_0.9.0       Rcpp_1.1.0        yaml_2.3.10       jsonlite_2.0.0    #> [25] rlang_1.1.6       fs_1.6.6          htmlwidgets_1.6.4"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"what-corrselect-does","dir":"Articles","previous_headings":"","what":"What corrselect Does","title":"Quick Start","text":"corrselect identifies removes redundant variables based pairwise correlation association. Given threshold τ\\tau, finds subsets pairwise associations satisfy |aij|<τ|a_{ij}| < \\tau (see vignette(\"theory\") mathematical formulation).","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"interface-hierarchy","dir":"Articles","previous_headings":"","what":"Interface Hierarchy","title":"Quick Start","text":"corrselect provides three levels interface:","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"level-1-simple-pruning","dir":"Articles","previous_headings":"Interface Hierarchy","what":"Level 1: Simple Pruning","title":"Quick Start","text":"corrPrune() - Removes redundant predictors based pairwise correlation: Returns single pruned dataset response variable required Fast greedy exact search modelPrune() - Reduces VIF regression models: Returns single pruned dataset response Iteratively removes high-VIF predictors Works lm, glm, lme4, glmmTMB","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"level-2-structured-subset-selection","dir":"Articles","previous_headings":"Interface Hierarchy","what":"Level 2: Structured Subset Selection","title":"Quick Start","text":"corrSelect() - Returns maximal subsets (numeric data): Enumerates maximal valid subsets satisfying threshold (see vignette(\"theory\")) Provides full metadata (size, avg_corr, max_corr, min_corr) Exact greedy search assocSelect() - Returns maximal subsets (mixed-type data): Handles numeric, factor, ordered variables Uses appropriate association measures per variable pair Exact greedy search","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"level-3-low-level-matrix-interface","dir":"Articles","previous_headings":"Interface Hierarchy","what":"Level 3: Low-Level Matrix Interface","title":"Quick Start","text":"MatSelect() - Direct matrix input: Accepts precomputed correlation/association matrices data preprocessing Useful repeated analyses","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"pruning-example-corrprune","dir":"Articles","previous_headings":"","what":"Pruning Example: corrPrune()","title":"Quick Start","text":"Variables removed: corrPrune() selects among multiple maximal subsets: multiple maximal subsets exist (common), corrPrune() returns subset lowest average absolute correlation. selection criterion balances three goals: Minimize redundancy: Lower average correlation means independent variables Maximize information: Prefers diverse variable combinations tightly clustered ones Deterministic behavior: Always returns result data Example: explore maximal subsets instead just optimal one, use corrSelect() (see ). Visualization:","code":"library(corrselect) data(bioclim_example)  # Remove correlated predictors (threshold = 0.7) pruned <- corrPrune(   data = bioclim_example[, -1],  # Exclude response   threshold = 0.7 )  # Variables retained ncol(pruned) #> [1] 12 head(names(pruned)) #> [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\" head(attr(pruned, \"removed_vars\")) #> NULL # If two maximal subsets exist: # Subset A: {bio1, bio4, bio12} with avg_corr = 0.35 # Subset B: {bio2, bio5, bio15} with avg_corr = 0.42 # corrPrune() returns Subset A (lower average correlation) cor_before <- cor(bioclim_example[, -1]) cor_after <- cor(pruned)  hist(abs(cor_before[upper.tri(cor_before)]),      breaks = 30,      main = \"Distribution of Absolute Correlations\",      xlab = \"Absolute Correlation\",      col = rgb(0.8, 0.2, 0.2, 0.5),      xlim = c(0, 1),      ylim = c(0, max(table(cut(abs(cor_before[upper.tri(cor_before)]), breaks = 30))) * 1.2))  hist(abs(cor_after[upper.tri(cor_after)]),      breaks = 30,      col = rgb(0.2, 0.5, 0.8, 0.5),      add = TRUE)  abline(v = 0.7, col = \"black\", lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"Before\", \"After\", \"Threshold\"),        fill = c(rgb(0.8, 0.2, 0.2, 0.5), rgb(0.2, 0.5, 0.8, 0.5), NA),        border = c(\"black\", \"black\", NA),        lty = c(NA, NA, 2),        lwd = c(NA, NA, 2),        bty = \"n\")"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"model-based-pruning-modelprune","dir":"Articles","previous_headings":"","what":"Model-Based Pruning: modelPrune()","title":"Quick Start","text":"Variables removed: Final model: VIF comparison:","code":"# Prune based on VIF (limit = 5) model_data <- modelPrune(   formula = species_richness ~ .,   data = bioclim_example,   limit = 5 )  # Predictors retained length(attr(model_data, \"selected_vars\")) #> [1] 16 attr(model_data, \"removed_vars\") #> [1] \"BIO2\" \"BIO7\" \"BIO5\" final_model <- attr(model_data, \"final_model\") summary(final_model)$coefficients[1:5, ]  # First 5 coefficients #>                 Estimate Std. Error    t value     Pr(>|t|) #> (Intercept) -255.6180854 37.1881215 -6.8736488 1.075474e-09 #> BIO1           0.6123452  0.1356203  4.5151441 2.071774e-05 #> BIO3          -0.0912390  0.1823538 -0.5003405 6.181594e-01 #> BIO4          -0.1464343  0.1909057 -0.7670503 4.452280e-01 #> BIO6           0.1896414  0.1620747  1.1700869 2.453149e-01 full_model <- lm(species_richness ~ ., data = bioclim_example)  X_full <- model.matrix(full_model)[, -1] vif_before <- sapply(colnames(X_full), function(var) {   1 / (1 - summary(lm(X_full[, var] ~ X_full[, -which(colnames(X_full) == var)]))$r.squared) })  X_pruned <- model.matrix(final_model)[, -1] vif_after <- sapply(colnames(X_pruned), function(var) {   1 / (1 - summary(lm(X_pruned[, var] ~ X_pruned[, -which(colnames(X_pruned) == var)]))$r.squared) })  par(mar = c(8, 4, 4, 2)) all_vars <- unique(c(names(vif_before), names(vif_after))) vif_combined <- data.frame(   before = vif_before[match(all_vars, names(vif_before))],   after = vif_after[match(all_vars, names(vif_after))] ) vif_combined[is.na(vif_combined)] <- 0 vif_combined <- vif_combined[order(vif_combined$before, decreasing = TRUE), ]  n_show <- min(15, nrow(vif_combined)) barplot(t(as.matrix(vif_combined[1:n_show, ])),         beside = TRUE,         las = 2,         main = \"VIF Before and After modelPrune()\",         ylab = \"VIF\",         col = c(rgb(0.8, 0.2, 0.2, 0.7), rgb(0.2, 0.5, 0.8, 0.7)),         cex.names = 0.6,         names.arg = rownames(vif_combined)[1:n_show]) abline(h = 5, col = \"black\", lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"Before\", \"After\", \"Limit\"),        fill = c(rgb(0.8, 0.2, 0.2, 0.7), rgb(0.2, 0.5, 0.8, 0.7), NA),        border = c(\"black\", \"black\", NA),        lty = c(NA, NA, 2),        lwd = c(NA, NA, 2),        bty = \"n\")"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"subset-selection-corrselect","dir":"Articles","previous_headings":"","what":"Subset Selection: corrSelect()","title":"Quick Start","text":"corrSelect() returns maximal subsets, just one: Inspect subsets: Extract specific subset:","code":"results <- corrSelect(bioclim_example[, -1], threshold = 0.7) show(results) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     42 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] BIO1, BIO3, BIO6, BIO9, BIO11...  0.192  0.689    12 #>   [ 2] BIO1, BIO3, BIO5, BIO9, BIO11...  0.195  0.689    12 #>   [ 3] BIO1, BIO3, BIO6, BIO8, BIO11...  0.195  0.689    12 #>   [ 4] BIO1, BIO4, BIO6, BIO9, BIO11...  0.196  0.689    12 #>   [ 5] BIO1, BIO3, BIO6, BIO9, BIO11...  0.196  0.688    12 #>   ... (37 more combinations) as.data.frame(results)[1:5, ]  # First 5 subsets #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.192]      BIO1      BIO3      BIO6      BIO9     BIO11 #> Subset02 [avg=0.195]      BIO1      BIO3      BIO5      BIO9     BIO11 #> Subset03 [avg=0.195]      BIO1      BIO3      BIO6      BIO8     BIO11 #> Subset04 [avg=0.196]      BIO1      BIO4      BIO6      BIO9     BIO11 #> Subset05 [avg=0.196]      BIO1      BIO3      BIO6      BIO9     BIO11 #>                      VarName06 VarName07 VarName08 VarName09 VarName10 #> Subset01 [avg=0.192]     BIO12     BIO13     BIO14     BIO16     BIO17 #> Subset02 [avg=0.195]     BIO12     BIO13     BIO14     BIO16     BIO17 #> Subset03 [avg=0.195]     BIO12     BIO13     BIO14     BIO16     BIO17 #> Subset04 [avg=0.196]     BIO12     BIO13     BIO14     BIO16     BIO17 #> Subset05 [avg=0.196]     BIO12     BIO13     BIO15     BIO16     BIO17 #>                      VarName11 VarName12 #> Subset01 [avg=0.192]     BIO18     BIO19 #> Subset02 [avg=0.195]     BIO18     BIO19 #> Subset03 [avg=0.195]     BIO18     BIO19 #> Subset04 [avg=0.196]     BIO18     BIO19 #> Subset05 [avg=0.196]     BIO18     BIO19 subset_data <- corrSubset(results, bioclim_example[, -1], which = 1) head(names(subset_data)) #> [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"mixed-type-data-assocselect","dir":"Articles","previous_headings":"","what":"Mixed-Type Data: assocSelect()","title":"Quick Start","text":"","code":"data(survey_example)  # Exclude ID and response survey_predictors <- survey_example[, !(names(survey_example) %in%                                          c(\"respondent_id\", \"overall_satisfaction\"))]  # Handle mixed types results_mixed <- assocSelect(survey_predictors, threshold = 0.6) show(results_mixed) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_factor = eta, numeric_ordered = spearman, factor_ordered #>                = cramersv, ordered_ordered = spearman #>   Threshold:   0.600 #>   Subsets:     900 valid combinations #>   Data Rows:   200 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] age, gender, education, satis...  0.175  0.555     6 #>   [ 2] age, gender, education, satis...  0.175  0.555     6 #>   [ 3] age, gender, education, satis...  0.176  0.555     6 #>   [ 4] age, gender, education, satis...  0.176  0.563     6 #>   [ 5] age, gender, education, satis...  0.176  0.591     6 #>   ... (895 more combinations)"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"protecting-variables","dir":"Articles","previous_headings":"","what":"Protecting Variables","title":"Quick Start","text":"","code":"# Check available variable names head(names(bioclim_example[, -1])) #> [1] \"BIO1\" \"BIO2\" \"BIO3\" \"BIO4\" \"BIO5\" \"BIO6\"  # Force a variable to remain in all subsets first_var <- names(bioclim_example)[2]  # First predictor pruned_force <- corrPrune(   data = bioclim_example[, -1],   threshold = 0.7,   force_in = first_var )  # Verify forced variable is present first_var %in% names(pruned_force) #> [1] TRUE"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"threshold-selection","dir":"Articles","previous_headings":"","what":"Threshold Selection","title":"Quick Start","text":"Visualize correlation distribution:  Test multiple thresholds:","code":"cor_mat <- cor(bioclim_example[, -1]) cor_vec <- cor_mat[upper.tri(cor_mat)]  hist(abs(cor_vec), breaks = 30,      main = \"Distribution of Absolute Correlations\",      xlab = \"Absolute Correlation\",      col = rgb(0.2, 0.5, 0.8, 0.6),      border = \"white\") abline(v = c(0.5, 0.7, 0.9), col = c(\"#d73027\", \"#4575b4\", \"#91cf60\"), lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"0.5 (strict)\", \"0.7 (moderate)\", \"0.9 (lenient)\"),        col = c(\"#d73027\", \"#4575b4\", \"#91cf60\"), lwd = 2, lty = 2, bty = \"n\") thresholds <- seq(0.3, 0.95, by = 0.05) sizes <- sapply(thresholds, function(t) {   tryCatch(ncol(corrPrune(bioclim_example[, -1], threshold = t)), error = function(e) NA) })  plot(thresholds, sizes, type = \"b\",      xlab = \"Threshold\",      ylab = \"Variables Retained\",      main = \"Threshold Sensitivity\",      col = rgb(0.2, 0.5, 0.8), lwd = 2, pch = 19) abline(h = ncol(bioclim_example) - 1, lty = 2, col = \"gray50\")"},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"interface-selection","dir":"Articles","previous_headings":"","what":"Interface Selection","title":"Quick Start","text":"corrPrune() modelPrune(): Single pruned dataset Fast execution Preprocessing pipelines corrSelect() assocSelect(): maximal subsets Full metadata per subset Documented enumeration reproducible research MatSelect(): Precomputed matrices Repeated analyses different thresholds","code":""},{"path":"https://gcol33.github.io/corrselect/articles/quickstart.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See Also","title":"Quick Start","text":"vignette(\"workflows\") - Complete workflows across domains vignette(\"advanced\") - Algorithmic control custom engines vignette(\"comparison\") - Comparison caret, Boruta, glmnet vignette(\"theory\") - Theoretical foundations formulation ?corrPrune, ?modelPrune, ?corrSelect, ?assocSelect, ?MatSelect","code":""},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Correlation Subset Selection with corrselect","text":"corrselect identifies maximal subsets variables whose pairwise correlations stay chosen threshold. process reduces multicollinearity redundancy modeling, preserving interpretability. Unlike greedy stepwise approaches, corrselect exhaustively searches valid subsets using fast, exact algorithms. fully model-agnostic, making suitable preprocessing step regression, clustering, feature selection, analyses. Given threshold t∈(0,1)t \\(0,1), functions corrSelect() (data-frame interface) MatSelect() (matrix interface) enumerate maximal subsets SS variables satisfying: ∀,j∈S,≠j:|rij|<t \\forall , j \\S,\\ \\neq j: \\ |r_{ij}| < t rijr_{ij} denotes chosen correlation measure variables ii jj. Enumeration relies two exact graph-theoretic algorithms: Eppstein–Löffler–Strash (ELS), degeneracy-ordered backtracking algorithm optimized sparse graphs. Bron–Kerbosch (BK), classical recursive clique-finding method, optional pivoting reduce search space. Results returned CorrCombo S4 object containing subset’s variable names summary statistics (avg_corr, min_corr, max_corr). can extract subsets original data via corrSubset(). procedure depend downstream model, cleanly separates “feature curation” “model fitting” supports multiple correlation measures (pearson, spearman, kendall, bicor, distance, maximal).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"simulated-numeric-example","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Simulated numeric example","title":"Correlation Subset Selection with corrselect","text":"","code":"set.seed(42) n <- 100 df <- data.frame(   A = rnorm(n),   B = rnorm(n),   C = rnorm(n),   D = rnorm(n),   E = rnorm(n) ) df$F <- df$A * 0.9 + rnorm(n, sd = 0.1)  # strongly correlated with A"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"basic-selection","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Basic selection","title":"Correlation Subset Selection with corrselect","text":"","code":"res <- corrSelect(df, threshold = 0.7) res #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 as.data.frame(res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E corrSubset(res, df, which = 1)[1:10,] #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"forcing-variables-into-all-subsets","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Forcing variables into all subsets","title":"Correlation Subset Selection with corrselect","text":"","code":"res2 <- corrSelect(df, threshold = 0.7, force_in = \"A\") res2 #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: pearson #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   100 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"using-a-different-correlation-method","dir":"Articles","previous_headings":"Quick Start (CorrSelect)","what":"Using a different correlation method","title":"Correlation Subset Selection with corrselect","text":"","code":"res3 <- corrSelect(df, threshold = 0.6, cor_method = \"spearman\") res3 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.600 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"matrix-interface-matselect","dir":"Articles","previous_headings":"","what":"Matrix Interface (MatSelect)","title":"Correlation Subset Selection with corrselect","text":"already computed correlation matrix want apply method precomputed correlations: Selecting subsets: Force variable 1 every subset:","code":"mat <- cor(df) res4 <- MatSelect(mat, threshold = 0.7) res4 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Threshold:   0.500 #>   Subsets:     2 valid combinations #>   Data Rows:   6 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.082  0.185     5 #>   [ 2] A, B, C, D, E                     0.083  0.185     5 MatSelect(mat, threshold = 0.5, force_in = 1) #> CorrCombo object #> ----------------- #>   Method:      els #>   Threshold:   0.500 #>   Subsets:     1 valid combinations #>   Data Rows:   6 used in correlation #>   Forced-in:   A #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B, C, D, E                     0.083  0.185     5"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"mixed-data-types-assocselect","dir":"Articles","previous_headings":"","what":"Mixed Data Types (assocSelect)","title":"Correlation Subset Selection with corrselect","text":"","code":"df_ass <- data.frame(   height = rnorm(15, 170, 10),   weight = rnorm(15, 70, 12),   group  = factor(rep(LETTERS[1:3], each = 5)),   score  = ordered(sample(c(\"low\",\"med\",\"high\"), 15, TRUE)) )  # keep every subset whose internal associations ≤ 0.6 res5 <- assocSelect(df_ass, threshold = 0.6) res5 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.600 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.267  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"changing-correlation-method","dir":"Articles","previous_headings":"","what":"Changing Correlation Method","title":"Correlation Subset Selection with corrselect","text":"default, corrSelect() uses Pearson correlation. can choose alternatives cor_method argument: \"pearson\": linear correlation (default) \"spearman\": rank-based monotonic association \"kendall\": Kendall’s tau \"bicor\": robust biweight midcorrelation (WGCNA::bicor) \"distance\": distance correlation (energy::dcor) \"maximal\": maximal information coefficient (minerva::mine) Example:","code":"res6 <- corrSelect(df, threshold = 0.7, cor_method = \"spearman\") res6 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: spearman #>   Threshold:   0.700 #>   Subsets:     2 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] F, B, C, D, E                     0.088  0.191     5 #>   [ 2] A, B, C, D, E                     0.090  0.206     5"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"handling-mixed-data-types","dir":"Articles","previous_headings":"","what":"Handling Mixed Data Types","title":"Correlation Subset Selection with corrselect","text":"function assocSelect() extends corrSelect() support mixed data types — including numeric, factor, ordered variables — using appropriate association measures variable pair. Instead single correlation matrix, constructs generalized association matrix using following logic: defaults numeric-numeric, numeric-ordered, ordered-ordered associations can changed via arguments: combinations use fixed methods (eta cramersv) appropriate measuring association strength.","code":"assocSelect(df_ass,   method_num_num = \"kendall\",   method_num_ord = \"spearman\",   method_ord_ord = \"kendall\" ) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = kendall, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.700 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.270  0.554     4"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"example-with-mixed-types","dir":"Articles","previous_headings":"Handling Mixed Data Types","what":"Example with Mixed Types","title":"Correlation Subset Selection with corrselect","text":"pairwise association bounded [0,1] treated analogously correlation.","code":"df_ass <- data.frame(   height = rnorm(10),   weight = rnorm(10),   group  = factor(sample(c(\"A\", \"B\"), 10, replace = TRUE)),   score  = ordered(sample(1:3, 10, replace = TRUE)) )  res7 <- assocSelect(df_ass, threshold = 1, method = \"bron-kerbosch\", use_pivot = TRUE) res7 #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   1.000 #>   Subsets:     1 valid combinations #>   Data Rows:   10 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.336  0.495     4"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"theory","dir":"Articles","previous_headings":"","what":"Theory","title":"Correlation Subset Selection with corrselect","text":"Given symmetric correlation matrix R∈ℝp×pR \\\\mathbb{R}^{p \\times p}, seek maximal subsets S⊆{1,…,p}S \\subseteq \\{1, \\dots, p\\} : ∀,j∈S,≠j:|Rij|<t \\forall , j \\S,\\ \\neq j: \\ |R_{ij}| < t fixed threshold t∈(0,1)t \\(0, 1). equivalent finding maximal cliques thresholded correlation graph, : Nodes represent variables Edges connect nodes whose absolute correlation threshold maximal clique corresponds variable subset extended without violating correlation limit.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"els-eppsteinlöfflerstrash","dir":"Articles","previous_headings":"Algorithms","what":"ELS (Eppstein–Löffler–Strash)","title":"Correlation Subset Selection with corrselect","text":"ELS algorithm efficiently enumerates maximal cliques sparse graph using degeneracy ordering: Compute degeneracy ordering v1,…,vpv_1, \\dots, v_p. ii, extend current clique SS {vi}\\{v_i\\} within candidate set C={vi+1,…,vp}C = \\{v_{+1}, \\dots, v_p\\}. Recursively build cliques, pruning vertices can added. Formally, define: extend(S,C)={S,C=∅,⋃v∈Cextend(S∪{v},C\\(N(v)∪{v})),otherwise. \\text{extend}(S, C) = \\begin{cases} S, & C = \\emptyset, \\\\ \\bigcup_{v \\C} \\text{extend}(S \\cup \\{v\\},\\ C \\setminus (N(v) \\cup \\{v\\})), & \\text{otherwise}. \\end{cases} ELS avoids redundant exploration, achieving good performance typical correlation graphs.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"bronkerbosch-with-pivoting","dir":"Articles","previous_headings":"Algorithms","what":"Bron–Kerbosch (with Pivoting)","title":"Correlation Subset Selection with corrselect","text":"classical Bron–Kerbosch algorithm enumerates maximal cliques via recursive backtracking optional pivoting: Let RR = current clique, PP = prospective nodes, XX = excluded nodes. : BK(R,P,X)={report(R),P=X=∅,v∈P\\N(u):BK(R∪{v},P∩N(v),X∩N(v)),P←P\\{v},X←X∪{v}. \\text{BK}(R, P, X) = \\begin{cases} \\text{report}(R), & P = X = \\emptyset, \\\\ \\text{} v \\P \\setminus N(u): \\\\ \\quad \\text{BK}(R \\cup \\{v\\},\\ P \\cap N(v),\\ X \\cap N(v)), \\ \\quad P \\leftarrow P \\setminus \\{v\\},\\ X \\leftarrow X \\cup \\{v\\}. \\end{cases} Choosing pivot u∈P∪Xu \\P \\cup X iterating P\\N(u)P \\setminus N(u) reduces recursive calls.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"why-corrselect","dir":"Articles","previous_headings":"","what":"Why corrselect?","title":"Correlation Subset Selection with corrselect","text":"existing R tools: Filter one variable time (e.g. findCorrelation) Use greedy backward-selection heuristics enumerate valid subsets corrselect uniquely provides: Exact enumeration maximal subsets Support multiple correlation measures Optional forcing variables Full inspection via CorrCombo objects Fast C++ implementations via Rcpp makes ideal pipelines interpretability completeness essential.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"inspecting-results","dir":"Articles","previous_headings":"","what":"Inspecting Results","title":"Correlation Subset Selection with corrselect","text":"Convert results downstream use: Extract individual subsets: Summarize correlation metrics:","code":"df_res <- as.data.frame(res) head(df_res) #>                      VarName01 VarName02 VarName03 VarName04 VarName05 #> Subset01 [avg=0.082]         F         B         C         D         E #> Subset02 [avg=0.083]         A         B         C         D         E lapply(corrSubset(res, df, which = 1:2), function(x) head(x, 10)) #> $Subset1 #>              F          B          C            D           E #> 1   1.33677667  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.41675087  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.32656994 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.58317730  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.29182614 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.11532450  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.25744892 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.18188872 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   1.69450003  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10  0.02717808  0.1191610 -0.1853780 -0.033487525 -1.90915279 #>  #> $Subset2 #>              A          B          C            D           E #> 1   1.37095845  1.2009654 -2.0009292 -0.004620768  1.33491259 #> 2  -0.56469817  1.0447511  0.3337772  0.760242168 -0.86927176 #> 3   0.36312841 -1.0032086  1.1713251  0.038990913  0.05548695 #> 4   0.63286260  1.8484819  2.0595392  0.735072142  0.04906691 #> 5   0.40426832 -0.6667734 -1.3768616 -0.146472627 -0.57835573 #> 6  -0.10612452  0.1055138 -1.1508556 -0.057887335 -0.99873866 #> 7   1.51152200 -0.4222559 -0.7058214  0.482369466 -0.00243278 #> 8  -0.09465904 -0.1223502 -1.0540558  0.992943637  0.65551188 #> 9   2.01842371  0.1881930 -0.6457437 -1.246395498  1.47684228 #> 10 -0.06271410  0.1191610 -0.1853780 -0.033487525 -1.90915279 # Number and size of subsets length(res@subset_list) #> [1] 2 summary(lengths(res@subset_list)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>       5       5       5       5       5       5  # Summaries of within-subset correlations summary(res@max_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>   0.185   0.185   0.185   0.185   0.185   0.185 summary(res@avg_corr) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.08162 0.08185 0.08208 0.08208 0.08232 0.08255"},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"corrcombo-object-structure","dir":"Articles","previous_headings":"","what":"CorrCombo Object Structure","title":"Correlation Subset Selection with corrselect","text":"CorrCombo S4 object contains: subset_list: list character vectors (variable names) avg_corr, min_corr, max_corr: numeric vectors correlation metrics threshold, forced_in, search_type, cor_method, n_rows_used Attribute use_pivot (applicable) Inspect slots:","code":"str(res@subset_list) #> List of 2 #>  $ : chr [1:5] \"F\" \"B\" \"C\" \"D\" ... #>  $ : chr [1:5] \"A\" \"B\" \"C\" \"D\" ..."},{"path":"https://gcol33.github.io/corrselect/articles/theory.html","id":"session-info","dir":"Articles","previous_headings":"","what":"Session Info","title":"Correlation Subset Selection with corrselect","text":"","code":"sessionInfo() #> R version 4.5.1 (2025-06-13 ucrt) #> Platform: x86_64-w64-mingw32/x64 #> Running under: Windows 11 x64 (build 26200) #>  #> Matrix products: default #>   LAPACK version 3.12.1 #>  #> locale: #> [1] LC_COLLATE=English_United States.utf8  #> [2] LC_CTYPE=English_United States.utf8    #> [3] LC_MONETARY=English_United States.utf8 #> [4] LC_NUMERIC=C                           #> [5] LC_TIME=English_United States.utf8     #>  #> time zone: Europe/Luxembourg #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #> [1] corrselect_3.0.0 #>  #> loaded via a namespace (and not attached): #>  [1] digest_0.6.37     desc_1.4.3        R6_2.6.1          fastmap_1.2.0     #>  [5] xfun_0.53         cachem_1.1.0      knitr_1.50        htmltools_0.5.8.1 #>  [9] rmarkdown_2.30    lifecycle_1.0.4   cli_3.6.5         sass_0.4.10       #> [13] pkgdown_2.1.3     textshaping_1.0.3 jquerylib_0.1.4   systemfonts_1.2.3 #> [17] compiler_4.5.1    tools_4.5.1       ragg_1.5.0        evaluate_1.0.5    #> [21] bslib_0.9.0       Rcpp_1.1.0        yaml_2.3.10       jsonlite_2.0.0    #> [25] rlang_1.1.6       fs_1.6.6          htmlwidgets_1.6.4"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Complete Workflows: Real-World Examples","text":"vignette demonstrates workflows using corrselect across four domains: Ecological modeling bioclimatic variables Survey data redundant items High-dimensional gene expression data Longitudinal data mixed models","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"interface-hierarchy","dir":"Articles","previous_headings":"","what":"Interface Hierarchy","title":"Complete Workflows: Real-World Examples","text":"corrselect provides three interface levels: Level 1: corrPrune() / modelPrune() Returns single pruned dataset corrPrune(): Based pairwise correlation modelPrune(): Based VIF regression models Level 2: corrSelect() / assocSelect() Returns maximal subsets satisfying threshold Provides metadata subset corrSelect(): Numeric data assocSelect(): Mixed-type data (numeric, factor, ordered) Level 3: MatSelect() Accepts precomputed correlation/association matrices data preprocessing overhead","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"ecological-modeling","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling","what":"Ecological Modeling","title":"Complete Workflows: Real-World Examples","text":"Species distribution model using 19 WorldClim bioclimatic variables. Many variables correlated (e.g., different temperature metrics).","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"load-data","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"Load data","title":"Complete Workflows: Real-World Examples","text":"Visualize correlation structure:","code":"library(corrselect) data(bioclim_example)  # Data structure dim(bioclim_example) #> [1] 100  20 head(names(bioclim_example)) #> [1] \"species_richness\" \"BIO1\"             \"BIO2\"             \"BIO3\"             #> [5] \"BIO4\"             \"BIO5\"  # Response variable summary(bioclim_example$species_richness) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #>     5.0    96.0   118.5   120.2   144.2   206.0 # Correlation matrix cor_matrix <- cor(bioclim_example[, -1])  # Histogram of correlations hist(cor_matrix[upper.tri(cor_matrix)],      breaks = 30,      main = \"Distribution of Pairwise Correlations\",      xlab = \"Correlation\",      col = \"lightblue\",      border = \"white\") abline(v = 0.7, col = \"red\", lwd = 2, lty = 2) text(0.7, par(\"usr\")[4] * 0.9, \"threshold = 0.7\", pos = 4, col = \"red\")"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"correlation-based-pruning","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"Correlation-based pruning","title":"Complete Workflows: Real-World Examples","text":"Correlation distribution:","code":"# Remove highly correlated predictors bio_clean <- corrPrune(   data = bioclim_example[, -1],  # Exclude response   threshold = 0.7,   mode = \"auto\" )  # How much did we reduce? cat(sprintf(\"Reduced from %d → %d variables\\n\",             ncol(bioclim_example) - 1,             ncol(bio_clean))) #> Reduced from 19 → 12 variables  # Which variables were kept? head(attr(bio_clean, \"selected_vars\"), 10) #>  [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\" \"BIO13\" \"BIO14\" \"BIO16\" #> [10] \"BIO17\" # Before and after correlations cor_before <- cor(bioclim_example[, -1]) cor_after <- cor(bio_clean)  # Overlaid histogram hist(abs(cor_before[upper.tri(cor_before)]),      breaks = 30,      main = \"Distribution of Absolute Correlations\",      xlab = \"Absolute Correlation\",      col = rgb(0.8, 0.2, 0.2, 0.5),      xlim = c(0, 1))  hist(abs(cor_after[upper.tri(cor_after)]),      breaks = 30,      col = rgb(0.2, 0.5, 0.8, 0.5),      add = TRUE)  abline(v = 0.7, col = \"black\", lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"Before\", \"After\", \"Threshold\"),        fill = c(rgb(0.8, 0.2, 0.2, 0.5), rgb(0.2, 0.5, 0.8, 0.5), NA),        border = c(\"black\", \"black\", NA),        lty = c(NA, NA, 2),        lwd = c(NA, NA, 2),        bty = \"n\")"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"fit-model","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"Fit model","title":"Complete Workflows: Real-World Examples","text":"","code":"# Add response back bio_clean_full <- data.frame(   species_richness = bioclim_example$species_richness,   bio_clean )  # Fit linear model model_initial <- lm(species_richness ~ ., data = bio_clean_full)  # Quick summary cat(sprintf(\"R² = %.3f\\n\", summary(model_initial)$r.squared)) #> R² = 0.909 cat(sprintf(\"Adj R² = %.3f\\n\", summary(model_initial)$adj.r.squared)) #> Adj R² = 0.896"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"vif-based-pruning","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"VIF-based pruning","title":"Complete Workflows: Real-World Examples","text":"","code":"# Further pruning based on VIF bio_final <- modelPrune(   formula = species_richness ~ .,   data = bio_clean_full,   limit = 5 )  # Final predictor set final_vars <- attr(bio_final, \"selected_vars\") cat(sprintf(\"Final model: %d predictors\\n\", length(final_vars))) #> Final model: 12 predictors print(final_vars) #>  [1] \"BIO1\"  \"BIO3\"  \"BIO6\"  \"BIO9\"  \"BIO11\" \"BIO12\" \"BIO13\" \"BIO14\" \"BIO16\" #> [10] \"BIO17\" \"BIO18\" \"BIO19\""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"model-comparison","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"Model comparison","title":"Complete Workflows: Real-World Examples","text":"Predictor reduction model quality:","code":"# Get final model final_model <- attr(bio_final, \"final_model\")  # Compare comparison <- data.frame(   Model = c(\"Full model\", \"After corrPrune\", \"After modelPrune\"),   R2 = c(     summary(lm(species_richness ~ ., data = bioclim_example))$r.squared,     summary(model_initial)$r.squared,     summary(final_model)$r.squared   ),   Adj_R2 = c(     summary(lm(species_richness ~ ., data = bioclim_example))$adj.r.squared,     summary(model_initial)$adj.r.squared,     summary(final_model)$adj.r.squared   ),   AIC = c(     AIC(lm(species_richness ~ ., data = bioclim_example)),     AIC(model_initial),     AIC(final_model)   ) )  print(comparison) #>              Model        R2    Adj_R2      AIC #> 1       Full model 0.9856050 0.9821862 615.9339 #> 2  After corrPrune 0.9088563 0.8962848 786.4894 #> 3 After modelPrune 0.9088563 0.8962848 786.4894 par(mfrow = c(1, 2))  # Number of predictors barplot(c(19, length(attr(bio_clean, \"selected_vars\")), length(final_vars)),         names.arg = c(\"Full\\n(19 vars)\", \"corrPrune\\n(~8 vars)\", \"modelPrune\\n(~6 vars)\"),         main = \"Number of Predictors\",         ylab = \"Count\",         col = c(\"salmon\", \"lightblue\", \"lightgreen\"),         ylim = c(0, 20))  # Model quality (Adjusted R²) barplot(comparison$Adj_R2,         names.arg = c(\"Full\", \"corrPrune\", \"modelPrune\"),         main = \"Adjusted R²\",         ylab = \"Value\",         col = c(\"salmon\", \"lightblue\", \"lightgreen\"),         ylim = c(0, 1))"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"coefficient-stability","dir":"Articles","previous_headings":"Workflow 1: Ecological Modeling > Ecological Modeling","what":"Coefficient stability","title":"Complete Workflows: Real-World Examples","text":"","code":"# Extract coefficients (excluding intercept) coef_full <- coef(lm(species_richness ~ ., data = bioclim_example))[-1] coef_final <- coef(final_model)[-1]  # Plot for variables present in final model common_vars <- intersect(names(coef_full), names(coef_final))  par(mfrow = c(1, 2)) barplot(coef_full[common_vars],         las = 2,         main = \"Full Model\",         ylab = \"Coefficient\",         col = \"salmon\",         cex.names = 0.6)  barplot(coef_final[common_vars],         las = 2,         main = \"Final Model (8 vars)\",         ylab = \"Coefficient\",         col = \"lightblue\",         cex.names = 0.6)"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"survey-data-analysis","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis","what":"Survey Data Analysis","title":"Complete Workflows: Real-World Examples","text":"Questionnaire 30 Likert-scale items measuring satisfaction, engagement, loyalty. Many items redundant.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"load-data-1","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis > Survey Data Analysis","what":"Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(survey_example)  # Data structure dim(survey_example) #> [1] 200  35 str(survey_example[, 1:10])  # First 10 columns #> 'data.frame':    200 obs. of  10 variables: #>  $ respondent_id       : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ age                 : num  38 32 18 18 19 39 33 26 26 42 ... #>  $ gender              : Factor w/ 3 levels \"Female\",\"Male\",..: 2 3 1 2 2 1 1 2 2 1 ... #>  $ education           : Ord.factor w/ 4 levels \"High School\"<..: 3 1 4 2 2 1 1 1 2 3 ... #>  $ overall_satisfaction: num  58 40 44 40 58 67 61 49 51 52 ... #>  $ satisfaction_1      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 5 3 4 5 5 4 4 5 ... #>  $ satisfaction_2      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 4 6 6 4 4 3 ... #>  $ satisfaction_3      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 3 4 5 3 4 4 ... #>  $ satisfaction_4      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 4 4 5 4 3 2 4 ... #>  $ satisfaction_5      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 7 4 5 5 5 4 3 6 4 6 ..."},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"prune-with-protected-variables","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis > Survey Data Analysis","what":"Prune with protected variables","title":"Complete Workflows: Real-World Examples","text":"","code":"# Exclude respondent_id, overall_satisfaction, and factor variables survey_predictors <- survey_example[, !(names(survey_example) %in%                                          c(\"respondent_id\", \"overall_satisfaction\",                                            \"gender\", \"education\"))]  # Convert ordered factors (Likert items 1-7) to numeric for correlation analysis survey_numeric <- as.data.frame(lapply(survey_predictors, function(x) {   if (is.ordered(x)) as.numeric(as.character(x)) else as.numeric(x) }))  # Prune with protected variables survey_clean <- corrPrune(   data = survey_numeric,   threshold = 0.6,   force_in = \"age\" )  # How many items remain? cat(sprintf(\"Reduced from %d → %d variables\\n\",             ncol(survey_numeric),             ncol(survey_clean))) #> Reduced from 31 → 4 variables  # Which items were kept? selected <- attr(survey_clean, \"selected_vars\") print(selected) #> [1] \"age\"            \"satisfaction_5\" \"engagement_1\"   \"loyalty_5\""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"construct-coverage","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis > Survey Data Analysis","what":"Construct coverage","title":"Complete Workflows: Real-World Examples","text":"Items per construct:","code":"# Count items per construct satisfaction_kept <- sum(grepl(\"satisfaction_\", selected)) engagement_kept <- sum(grepl(\"engagement_\", selected)) loyalty_kept <- sum(grepl(\"loyalty_\", selected))  cat(sprintf(\"Satisfaction: %d/10 items kept\\n\", satisfaction_kept)) #> Satisfaction: 1/10 items kept cat(sprintf(\"Engagement: %d/10 items kept\\n\", engagement_kept)) #> Engagement: 1/10 items kept cat(sprintf(\"Loyalty: %d/10 items kept\\n\", loyalty_kept)) #> Loyalty: 1/10 items kept par(mfrow = c(1, 2))  # Items kept per construct construct_data <- rbind(   c(10, 10, 10),   c(satisfaction_kept, engagement_kept, loyalty_kept) )  barplot(construct_data,         beside = TRUE,         names.arg = c(\"Satisfaction\", \"Engagement\", \"Loyalty\"),         col = c(\"lightgray\", \"lightblue\"),         legend.text = c(\"Original (10)\", \"After pruning\"),         args.legend = list(x = \"topright\", bty = \"n\"),         main = \"Items per Construct\",         ylab = \"Number of Items\",         ylim = c(0, 12))  # Percentage reduction barplot(c(ncol(survey_numeric), ncol(survey_clean)),         names.arg = c(\"Before\", \"After\"),         col = c(\"salmon\", \"lightgreen\"),         main = \"Total Variables\",         ylab = \"Count\",         ylim = c(0, max(ncol(survey_numeric)) * 1.2)) text(0.7, ncol(survey_numeric) + 1, ncol(survey_numeric), pos = 3) text(1.9, ncol(survey_clean) + 1, ncol(survey_clean), pos = 3)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"model-satisfaction","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis > Survey Data Analysis","what":"Model satisfaction","title":"Complete Workflows: Real-World Examples","text":"","code":"# Add response back survey_model_data <- data.frame(   overall_satisfaction = survey_example$overall_satisfaction,   survey_clean )  # Fit regression model model_survey <- lm(overall_satisfaction ~ ., data = survey_model_data)  # Summary summary(model_survey) #>  #> Call: #> lm(formula = overall_satisfaction ~ ., data = survey_model_data) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -16.463  -4.384   0.374   4.494  17.338  #>  #> Coefficients: #>                Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    25.13579    2.16083  11.632   <2e-16 *** #> age             0.01805    0.04329   0.417    0.677     #> satisfaction_5  4.89449    0.35881  13.641   <2e-16 *** #> engagement_1    0.45383    0.32950   1.377    0.170     #> loyalty_5       0.34698    0.31296   1.109    0.269     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 6.661 on 195 degrees of freedom #> Multiple R-squared:  0.6605, Adjusted R-squared:  0.6535  #> F-statistic: 94.82 on 4 and 195 DF,  p-value: < 2.2e-16"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"model-comparison-1","dir":"Articles","previous_headings":"Workflow 2: Survey Data Analysis > Survey Data Analysis","what":"Model comparison","title":"Complete Workflows: Real-World Examples","text":"","code":"# Full model (all 30 items + demographics) full_survey_data <- data.frame(   overall_satisfaction = survey_example$overall_satisfaction,   survey_predictors )  model_full_survey <- lm(overall_satisfaction ~ ., data = full_survey_data)  # Compare data.frame(   Model = c(\"Full (33 vars)\", \"Pruned (10 vars)\"),   R2 = c(summary(model_full_survey)$r.squared,          summary(model_survey)$r.squared),   Adj_R2 = c(summary(model_full_survey)$adj.r.squared,              summary(model_survey)$adj.r.squared),   Num_Predictors = c(33, 10) ) #>              Model        R2    Adj_R2 Num_Predictors #> 1   Full (33 vars) 0.9790144 0.7679931             33 #> 2 Pruned (10 vars) 0.6604503 0.6534852             10"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"high-dimensional-data","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data","what":"High-Dimensional Data","title":"Complete Workflows: Real-World Examples","text":"Gene expression data: 200 genes across 100 samples (p >> n).","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"load-data-2","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data > High-Dimensional Data","what":"Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(genes_example)  # Data structure dim(genes_example) #> [1] 100 202  # Disease prevalence table(genes_example$disease_status) #>  #> Healthy Disease  #>       2      98"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"greedy-pruning","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data > High-Dimensional Data","what":"Greedy pruning","title":"Complete Workflows: Real-World Examples","text":"Dimensionality reduction:","code":"# Extract gene expression data (exclude ID and outcome) gene_expr <- genes_example[, -(1:2)]  # Greedy pruning system.time({   genes_pruned <- corrPrune(     data = gene_expr,     threshold = 0.8,     mode = \"greedy\"  # Fast for large p   ) }) #>    user  system elapsed  #>       0       0       0  # Reduction cat(sprintf(\"Reduced from %d → %d genes\\n\",             ncol(gene_expr),             ncol(genes_pruned))) #> Reduced from 200 → 177 genes # Barplot showing reduction reduction_data <- c(ncol(gene_expr), ncol(genes_pruned)) barplot(reduction_data,         names.arg = c(\"Original\", \"After Pruning\"),         main = \"Gene Dimensionality Reduction\",         ylab = \"Number of Genes\",         col = c(\"salmon\", \"lightblue\"),         ylim = c(0, max(reduction_data) * 1.2)) text(0.7, reduction_data[1] + 10, paste(reduction_data[1], \"genes\"), pos = 3) text(1.9, reduction_data[2] + 10, paste(reduction_data[2], \"genes\\n(\",      round(100 * reduction_data[2] / reduction_data[1], 1), \"% retained)\"), pos = 3)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"exact-vs-greedy-comparison","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data > High-Dimensional Data","what":"Exact vs greedy comparison","title":"Complete Workflows: Real-World Examples","text":"","code":"# Subset for comparison gene_subset <- gene_expr[, 1:50]  # Exact mode system.time({   exact_result <- corrPrune(gene_subset, threshold = 0.8, mode = \"exact\") }) #>    user  system elapsed  #>  445.81    3.79  453.44  # Greedy mode system.time({   greedy_result <- corrPrune(gene_subset, threshold = 0.8, mode = \"greedy\") }) #>    user  system elapsed  #>       0       0       0  # Compare sizes cat(sprintf(\"Exact mode: %d genes kept\\n\", ncol(exact_result))) #> Exact mode: 28 genes kept cat(sprintf(\"Greedy mode: %d genes kept\\n\", ncol(greedy_result))) #> Greedy mode: 27 genes kept"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"classification","dir":"Articles","previous_headings":"Workflow 3: High-Dimensional Data > High-Dimensional Data","what":"Classification","title":"Complete Workflows: Real-World Examples","text":"","code":"# Prepare classification data classification_data <- data.frame(   disease_status = genes_example$disease_status,   genes_pruned )  # Logistic regression model_genes <- glm(disease_status ~ .,                    data = classification_data,                    family = binomial())  # Prediction accuracy predictions <- ifelse(predict(model_genes, type = \"response\") > 0.5,                      \"Disease\", \"Healthy\") accuracy <- mean(predictions == genes_example$disease_status)  cat(sprintf(\"Classification accuracy: %.1f%%\\n\", accuracy * 100)) #> Classification accuracy: 100.0%"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"mixed-models","dir":"Articles","previous_headings":"Workflow 4: Mixed Models","what":"Mixed Models","title":"Complete Workflows: Real-World Examples","text":"Longitudinal data: 50 subjects, 10 timepoints , 20 correlated predictors.","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"load-data-3","dir":"Articles","previous_headings":"Workflow 4: Mixed Models > Mixed Models","what":"Load data","title":"Complete Workflows: Real-World Examples","text":"","code":"data(longitudinal_example)  # Data structure dim(longitudinal_example) #> [1] 500  25 head(longitudinal_example) #>   obs_id subject site time  outcome          x1         x2          x3 #> 1      1       1    1    1 12.10893 -0.62045078 -0.8629274 -0.39625483 #> 2      2       1    1    2 13.97195  0.04255998  0.4086801  0.27069591 #> 3      3       1    1    3 15.71622  0.20445067 -1.0457672  1.69557480 #> 4      4       1    1    4 12.61343  0.38437289  2.0301256 -1.17894923 #> 5      5       1    1    5 15.73139 -0.06402543  1.1645219 -0.19757260 #> 6      6       1    1    6 13.19571  0.65208588 -1.5040345  0.07671762 #>           x4         x5          x6         x7         x8           x9 #> 1 -0.4557709 -1.2550770 -0.35966846 -1.9288176  0.8393628  0.151111346 #> 2 -0.7652493 -1.2136755 -0.05181211 -0.4759841  0.9063848  1.429621637 #> 3  0.5569423 -1.4962408  0.23986408 -1.7077822  1.0343806  0.797974670 #> 4  0.1604224 -0.8192580 -0.94858863 -1.9314095 -0.0639552  0.887413164 #> 5 -1.3331022 -0.6162473 -0.61339605 -0.9439486 -0.1220047 -0.796244469 #> 6  0.5205094 -0.8547461  0.24120308 -1.3083776  0.8716209  0.005423635 #>          x10        x11       x12         x13        x14        x15         x16 #> 1  0.9681971 -0.1384342 0.2598923  0.37082493 -0.1829715 -1.1853721 -0.72703262 #> 2  2.0989531  0.6303914 0.6211064 -0.91103843 -0.1125705 -0.3458058 -0.44331165 #> 3  0.2329831 -0.8618361 2.0854289  0.02634099 -1.3522055 -1.2151804  0.00311954 #> 4  1.5491815  1.7595441 0.8198899  0.18115372 -0.5638401 -1.3637072 -0.55274223 #> 5  2.3485234 -0.1267969 2.6230203 -1.13918808 -1.1559678 -0.3214032 -0.87713586 #> 6 -0.1860167 -0.4620834 1.6075140 -1.81586413 -0.0172986 -0.1041232 -0.56268259 #>           x17        x18        x19       x20 #> 1  0.91333399  1.2398417  1.2973339 1.0590334 #> 2 -0.09799793 -1.3670758 -1.0050198 0.9990451 #> 3 -0.14957945 -0.8573087  0.9004974 0.5399732 #> 4  0.55650397  0.7458841  0.7415159 1.7067212 #> 5  0.36401595 -0.4019171  1.1669136 0.7799264 #> 6  0.30234421 -0.6646296 -0.6615620 1.5092899  # Study design cat(sprintf(\"Subjects: %d\\n\", length(unique(longitudinal_example$subject)))) #> Subjects: 50 cat(sprintf(\"Sites: %d\\n\", length(unique(longitudinal_example$site)))) #> Sites: 5 cat(sprintf(\"Observations per subject: %d\\n\",             nrow(longitudinal_example) / length(unique(longitudinal_example$subject)))) #> Observations per subject: 10"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"prune-fixed-effects","dir":"Articles","previous_headings":"Workflow 4: Mixed Models > Mixed Models","what":"Prune fixed effects","title":"Complete Workflows: Real-World Examples","text":"","code":"# Note: This example requires lme4 package library(lme4)  # Define formula with random effects # Note: Only fixed effects (x1-x5) will be pruned #       Random effects (1|subject), (1|site) are preserved  pruned_mixed <- modelPrune(   formula = outcome ~ x1 + x2 + x3 + x4 + x5 + (1|subject) + (1|site),   data = longitudinal_example,   engine = \"lme4\",   limit = 5 )  # Which fixed effects were kept? selected_fixed <- attr(pruned_mixed, \"selected_vars\") cat(\"Fixed effects kept:\\n\") print(selected_fixed)  # Which were removed? removed_fixed <- attr(pruned_mixed, \"removed_vars\") cat(\"\\nFixed effects removed:\\n\") print(removed_fixed)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"final-model","dir":"Articles","previous_headings":"Workflow 4: Mixed Models > Mixed Models","what":"Final model","title":"Complete Workflows: Real-World Examples","text":"","code":"final_mixed <- attr(pruned_mixed, \"final_model\") summary(final_mixed)"},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"vif-verification","dir":"Articles","previous_headings":"Workflow 4: Mixed Models > Mixed Models","what":"VIF verification","title":"Complete Workflows: Real-World Examples","text":"","code":"# Note: This example requires lme4 package library(lme4)  # Fit full model full_formula <- as.formula(paste(\"outcome ~\",                                  paste(paste0(\"x\", 1:5), collapse = \" + \"),                                  \"+ (1|subject) + (1|site)\"))  model_full_mixed <- lmer(full_formula, data = longitudinal_example)  # Extract fixed effects design matrices X_full <- getME(model_full_mixed, \"X\") X_pruned <- getME(final_mixed, \"X\")  # Compute VIF compute_vif <- function(X) {   X_scaled <- scale(X[, -1])  # Remove intercept   sapply(1:ncol(X_scaled), function(i) {     r2 <- summary(lm(X_scaled[, i] ~ X_scaled[, -i]))$r.squared     1 / (1 - r2)   }) }  vif_full <- compute_vif(X_full) vif_pruned <- compute_vif(X_pruned)  # Compare data.frame(   Predictor = colnames(X_pruned)[-1],   VIF_Before = vif_full,   VIF_After = vif_pruned )"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"see-also","dir":"Articles","previous_headings":"","what":"See Also","title":"Complete Workflows: Real-World Examples","text":"vignette(\"quickstart\") - Interface overview vignette(\"advanced\") - Custom engines algorithmic control vignette(\"comparison\") - Comparison alternatives vignette(\"theory\") - Mathematical foundations","code":""},{"path":"https://gcol33.github.io/corrselect/articles/workflows.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Complete Workflows: Real-World Examples","text":"Thresholds: O’Brien, R. M. (2007). caution regarding rules thumb variance inflation factors. Quality & Quantity, 41(5), 673-690. Dormann, C. F., et al. (2013). Collinearity: review methods deal . Ecography, 36(1), 27-46. Methods: - See package documentation JOSS paper algorithm details","code":""},{"path":"https://gcol33.github.io/corrselect/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Gilles Colling. Author, maintainer.","code":""},{"path":"https://gcol33.github.io/corrselect/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Colling G (2025). corrselect: Correlation-Based Variable Subset Selection. R package version 1.0.0, https://github.com/gcol33/corrselect.","code":"@Manual{,   title = {corrselect: Correlation-Based Variable Subset Selection},   author = {Gilles Colling},   year = {2025},   note = {R package version 1.0.0},   url = {https://github.com/gcol33/corrselect}, }"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"CLAUDE.md","text":"corrselect R package performs exhaustive, model-agnostic variable subset selection based pairwise correlation association. identifies maximal subsets variables whose pairwise correlations/associations remain user-defined threshold, helping reduce multicollinearity maintaining interpretability.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"build-and-install","dir":"","previous_headings":"Development Commands","what":"Build and Install","title":"CLAUDE.md","text":"","code":"# Load package for development devtools::load_all()  # Install package locally devtools::install()  # If modifying C++ code, clean DLL first devtools::clean_dll() devtools::install()  # Regenerate documentation (after roxygen2 changes) devtools::document()"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"testing","dir":"","previous_headings":"Development Commands","what":"Testing","title":"CLAUDE.md","text":"","code":"# Run full test suite devtools::test()  # Run complete package check (includes tests, examples, documentation) devtools::check()  # Run specific test file during development testthat::test_file(\"tests/testthat/test-corrSelect.R\")  # Run test directory testthat::test_dir(\"tests/testthat\")"},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"documentation","dir":"","previous_headings":"Development Commands","what":"Documentation","title":"CLAUDE.md","text":"","code":"# Build vignettes devtools::build_vignettes()  # Build pkgdown site locally (output in docs/) pkgdown::build_site()"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"high-level-design","dir":"","previous_headings":"Architecture","what":"High-Level Design","title":"CLAUDE.md","text":"package provides three main user-facing functions converge common C++ backend: corrSelect() - Data frame interface numeric correlation assocSelect() - Data frame interface mixed-type data (numeric, factor, ordered) MatSelect() - Direct correlation/association matrix interface three functions: - Preprocess input (handle missing data, validate types) - Compute validate correlation/association matrix - Call C++ backend findAllMaxSets() enumerate maximal subsets - Return CorrCombo S4 object results","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"c-backend-architecture","dir":"","previous_headings":"Architecture","what":"C++ Backend Architecture","title":"CLAUDE.md","text":"Entry point: src/corrselect_main.cpp::findAllMaxSets() C++ layer implements two exact graph-theoretic algorithms enumerating maximal cliques graph edges represent “sufficiently low correlation”: Recommended using force_in (variables must appear subsets) Exact enumeration maximal independent sets Optional pivoting performance (use_pivot = TRUE) Default algorithm force_in specified Key types (src/corrselect_types.h): - Combo = std::vector<int> (variable indices) - ComboList = std::vector<Combo> (collection subsets) Utilities (src/utils.cpp, src/utils.h): - Matrix validation - Correlation statistics (mean, min, max subsets)","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"r-layer-architecture","dir":"","previous_headings":"Architecture","what":"R Layer Architecture","title":"CLAUDE.md","text":"Data frame preprocessing: - corrSelect(): Filters numeric columns , removes NA rows, computes correlation matrix using cor_method parameter - assocSelect(): Handles mixed types computing appropriate metrics pair type (Pearson, Spearman, Kendall, Eta-squared, Cramér’s V) CorrCombo S4 class (R/CorrCombo.R): - Stores discovered subsets metadata - Slots: subset_list, avg_corr, min_corr, max_corr, threshold, forced_in, search_type, cor_method, n_rows_used, names - Custom show() method user-friendly output - .data.frame() method tidy data extraction Helper functions: - corrSubset() (R/corrSubset.R): Extracts specific subsets original data, option keep non-numeric columns (keepExtra = TRUE) - findAllMaxSets() (R/findAllMaxSets.R): R wrapper calling C++ via Rcpp","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"algorithm-selection-logic","dir":"","previous_headings":"Architecture","what":"Algorithm Selection Logic","title":"CLAUDE.md","text":"Default method selection corrSelect() assocSelect(): - force_in provided → use ELS algorithm - Otherwise → use Bron-Kerbosch algorithm Users can override explicitly setting method = \"els\" method = \"bron-kerbosch\".","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"association-metrics-for-mixed-data","dir":"","previous_headings":"Architecture","what":"Association Metrics for Mixed Data","title":"CLAUDE.md","text":"assocSelect() automatically selects metrics based variable pair types: External correlation methods require additional packages: - bicor: WGCNA package - distance: energy package - maximal: minerva package","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"file-organization","dir":"","previous_headings":"","what":"File Organization","title":"CLAUDE.md","text":"","code":"R/                           # R source files ├── corrSelect.R            # Numeric data frame interface ├── assocSelect.R           # Mixed-type data frame interface ├── MatSelect.R             # Matrix interface ├── CorrCombo.R             # S4 class definition and methods ├── corrSubset.R            # Subset extraction helper └── findAllMaxSets.R        # R wrapper for C++ entry point  src/                         # C++ source files (Rcpp) ├── corrselect_main.cpp     # Main entry point and algorithm dispatch ├── corrselect_types.h      # Type definitions (Combo, ComboList) ├── method_els.{cpp,h}      # Eppstein-Löffler-Strash implementation ├── method_bronkerbosch.{cpp,h}  # Bron-Kerbosch implementation ├── utils.{cpp,h}           # Matrix validation and correlation stats └── RcppExports.cpp         # Generated Rcpp bindings  tests/testthat/             # Unit tests ├── test-corrSelect.R ├── test-assocSelect.R ├── test-CorrCombo.R ├── test-corrMatSelect-els.R ├── test-corrMatSelect-bron-kerbosch.R └── test-corrSubset.R  vignettes/                   # Long-form documentation man/                         # Generated documentation (roxygen2) docs/                        # Generated pkgdown website claude/                      # Claude Code working files (git-ignored)                              # Store generated .md files and notes here"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"index-conversion","dir":"","previous_headings":"Important Conventions","what":"Index Conversion","title":"CLAUDE.md","text":"R layer: 1-based indexing (standard R convention) C++ layer: 0-based indexing (standard C++ convention) Conversion happens corrselect_main.cpp: subtract 1 entering C++, add 1 returning R","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"force-in-variables","dir":"","previous_headings":"Important Conventions","what":"Force-In Variables","title":"CLAUDE.md","text":"force_in parameter can : - Character vector variable names (R layer converts indices) - Numeric vector column indices (user must provide 1-based) variables appear every returned subset. converted 0-based indices passed C++.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"result-ordering","dir":"","previous_headings":"Important Conventions","what":"Result Ordering","title":"CLAUDE.md","text":"Results sorted : 1. Size (descending) - larger subsets first 2. Average absolute correlation (ascending) - lower correlation preferred happens C++ returning R.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"missing-data-handling","dir":"","previous_headings":"Important Conventions","what":"Missing Data Handling","title":"CLAUDE.md","text":"corrSelect() assocSelect() remove rows NA values computing correlation matrix. warning issued rows dropped. number rows actually used stored CorrCombo object’s n_rows_used slot.","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"CLAUDE.md","text":"Keep tests fast reproducible Always use set.seed() random data Include edge cases (empty data, single variable, correlated, uncorrelated) Test algorithms (ELS Bron-Kerbosch) Test force_in functionality Test mixed-type data scenarios assocSelect tests","code":""},{"path":"https://gcol33.github.io/corrselect/CLAUDE.html","id":"documentation-1","dir":"","previous_headings":"","what":"Documentation","title":"CLAUDE.md","text":"exported functions use roxygen2 documentation : - @param descriptions - @return type structure - @details algorithm specifics - @examples executable - @seealso cross-references Vignettes provide: - Usage examples real-world scenarios - Performance comparisons algorithms - Guidance threshold selection - Mixed-type data workflows","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Code of Conduct","text":"aim maintain open, friendly, professional environment within corrselect project. Everyone taking part (contributors, maintainers, users) feel welcome respected, regardless background, identity, experience level.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Code of Conduct","text":"Examples behavior helps create good environment: Communicating clearly respectfully open different opinions approaches Offering constructive feedback Helping others learn contribute Staying focused collaboration shared goals Examples behavior acceptable: Personal attacks insulting language Disrespectful dismissive comments Sharing private information without consent form harassment hostility toward others","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"responsibilities","dir":"","previous_headings":"","what":"Responsibilities","title":"Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior taking fair action necessary. may edit, remove, reject contributions violate Code Conduct disrupt collaboration.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Code of Conduct","text":"Code Conduct applies project spaces, including discussions, issues, pull requests, community interactions related corrselect.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Code of Conduct","text":"experience witness behavior violates Code Conduct, please contact maintainer privately. Reports handled discretion, maintainers take appropriate action needed.","code":""},{"path":"https://gcol33.github.io/corrselect/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.1, simplified better fit tone open scientific software project. Contact: gilles.colling051@gmail.com","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contribution Guidelines","title":"Contribution Guidelines","text":"First , thank much taking time contribute corrselect project! document provides guidelines contributing corrselect—codebase documentation. guidelines meant guide , restrict . doubt, use best judgment feel free propose improvements issue pull request.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table Of Contents","title":"Contribution Guidelines","text":"Code Conduct Obtaining source Setting R environment Installing source Testing Install dependencies Building documentation Design docs Project organization Contributing workflow Style guidelines Pull request checklist Reporting bugs","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contribution Guidelines","text":"project everyone participating governed Code Conduct (CODE_OF_CONDUCT.md). participating, expected uphold code maintain respectful, inclusive environment.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Contribution Guidelines","text":"installation guide focused development. regular installation, please see README.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"obtaining-the-source","dir":"","previous_headings":"Installation","what":"Obtaining the source","title":"Contribution Guidelines","text":"Clone corrselect repository: work development branch:","code":"git clone https://github.com/gcol33/corrselect.git cd corrselect git checkout dev git pull origin dev"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"setting-up-your-r-environment","dir":"","previous_headings":"Installation","what":"Setting up your R environment","title":"Contribution Guidelines","text":"corrselect R package uses C++ code via Rcpp. Install required tools R (≥ 4.0) Rtools (Windows) Xcode Command Line Tools (macOS) Git editor IDE (RStudio, VS Code, etc.) Install development dependencies Load development build","code":"install.packages(c(\"devtools\", \"roxygen2\", \"testthat\", \"rmarkdown\", \"knitr\", \"pkgdown\")) devtools::load_all()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"installing-from-source","dir":"","previous_headings":"Installation","what":"Installing from source","title":"Contribution Guidelines","text":"Build install package locally: modify C++ code, rebuild DLL reinstalling: Regenerate documentation :","code":"devtools::install() devtools::clean_dll() devtools::install() devtools::document()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"testing","dir":"","previous_headings":"","what":"Testing","title":"Contribution Guidelines","text":"corrselect uses testthat testing. tests located tests/testthat/. Run full test suite: Run complete package check: Run subset tests development: Guidelines: - Keep tests fast reproducible. - Use set.seed() random data. - Include edge cases expected failures. - Prefer small examples large datasets.","code":"devtools::test() devtools::check() testthat::test_dir(\"tests/testthat\") testthat::test_file(\"tests/testthat/test-corrSelect.R\")"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"install-dependencies","dir":"","previous_headings":"Documentation","what":"Install dependencies","title":"Contribution Guidelines","text":"","code":"install.packages(c(\"rmarkdown\", \"knitr\", \"pkgdown\"))"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"building-the-documentation","dir":"","previous_headings":"Documentation","what":"Building the documentation","title":"Contribution Guidelines","text":"Build vignettes: Build pkgdown site locally: generated site saved docs/ directory. Open docs/index.html browser view .","code":"devtools::build_vignettes() pkgdown::build_site()"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"design-of-the-docs","dir":"","previous_headings":"Documentation","what":"Design of the docs","title":"Contribution Guidelines","text":"Function documentation: man/ (generated roxygen2) Tutorials examples: vignettes/ Website configuration: _pkgdown.yml Package overview: README.md Changelog: NEWS.md","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"project-organization","dir":"","previous_headings":"","what":"Project organization","title":"Contribution Guidelines","text":"","code":"corrselect/ ├── .github/                <- Continuous integration workflows ├── .gitignore ├── .Rbuildignore ├── corrselect.Rproj ├── DESCRIPTION             <- Package metadata ├── NAMESPACE               <- Function exports and imports ├── LICENSE ├── LICENSE.md ├── NEWS.md ├── README.md ├── _pkgdown.yml ├── R/                      <- R source files ├── src/                    <- C++ source files (Rcpp) ├── man/                    <- Generated documentation ├── inst/                   <- Installed files (e.g., CITATION, extdata) ├── vignettes/              <- Long-form documentation and usage examples ├── tests/ │   └── testthat/           <- Unit tests ├── docs/                   <- pkgdown website (generated) ├── doc/                    <- Built vignettes for local preview (ignored in Git) ├── Meta/                   <- Metadata created during package build (ignored) └── corrselect.Rcheck/      <- Artifacts from local package checks (ignored)"},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"contributing-workflow","dir":"","previous_headings":"","what":"Contributing workflow","title":"Contribution Guidelines","text":"Create feature branch Make focused commits clear messages. Run tests checks committing: Update documentation roxygen2 NEWS.md. Update vignettes/examples user-facing behavior changes. Open pull request short description change. Respond review feedback constructively.","code":"git checkout -b feature/my-feature devtools::test() devtools::check()"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"r-code","dir":"","previous_headings":"Style guidelines","what":"R code","title":"Contribution Guidelines","text":"Use descriptive names consistent indentation. Prefer vectorized operations loops. Validate inputs early clear error messages. Document exported functions roxygen2.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"c-code","dir":"","previous_headings":"Style guidelines","what":"C++ code","title":"Contribution Guidelines","text":"Keep headers minimal separate interface implementation. Use RAII possible. Comment algorithmic details numerical behavior. Avoid unnecessary memory allocations.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"tests","dir":"","previous_headings":"Style guidelines","what":"Tests","title":"Contribution Guidelines","text":"Add update tests functionality changes. Keep tests minimal reproducible. Avoid external dependencies unless essential.","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"pull-request-checklist","dir":"","previous_headings":"","what":"Pull request checklist","title":"Contribution Guidelines","text":"Tests pass (devtools::test() devtools::check()) Documentation updated (roxygen + NEWS.md) Vignettes/examples updated needed unrelated formatting changes PR description clearly explains change","code":""},{"path":"https://gcol33.github.io/corrselect/CONTRIBUTING.html","id":"reporting-bugs","dir":"","previous_headings":"","what":"Reporting bugs","title":"Contribution Guidelines","text":"reporting issue, please include: - minimal reproducible example (reprex) - Output sessionInfo() - Expected vs. actual results - Threshold method used (e.g., \"els\" \"bron-kerbosch\") - R operating system version - Toolchain info relevant (e.g., Rtools Windows) contributing corrselect, agree code released license package.","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"corrselect","dir":"","previous_headings":"","what":"Correlation-Based and Model-Based Predictor Pruning","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Fast Flexible Predictor Pruning Data Analysis Modeling corrselect package provides simple, high-level functions predictor pruning using association-based model-based approaches. Whether need reduce multicollinearity modeling clean correlated predictors dataset, corrselect offers fast, deterministic solutions minimal code.","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"library(corrselect) data(mtcars)  # Association-based pruning (model-free) pruned <- corrPrune(mtcars, threshold = 0.7) names(pruned)  # Model-based pruning (VIF) pruned <- modelPrune(mpg ~ ., data = mtcars, limit = 5) attr(pruned, \"selected_vars\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"statement-of-need","dir":"","previous_headings":"","what":"Statement of Need","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Variable selection central task statistics machine learning, particularly working high-dimensional collinear data. many applications, users aim retain sets variables weakly associated one another avoid redundancy reduce overfitting. Common approaches greedy filtering regularized regression either discard useful features guarantee bounded pairwise associations. package addresses admissible set problem: selecting maximal subsets variables pair exceeds user-defined threshold. generalizes mixed-type data, supports multiple association metrics, allows constrained subset selection via force_in (e.g. always include key predictors). features make package useful domains like: ecological bioclimatic modeling, trait-based species selection, interpretable machine learning pipelines.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"high-level-pruning-functions","dir":"","previous_headings":"Features","what":"High-Level Pruning Functions","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Model-free, works raw data Automatic correlation/association measure selection Fast greedy mode large datasets (p > 100) Exact mode guaranteed optimal solutions (p ≤ 20) Protect important variables force_in VIF-based iterative removal Supports lm, glm, lme4, glmmTMB engines Custom engine support modeling package (INLA, mgcv, brms, etc.) Prunes fixed effects mixed models Returns fitted model pruned predictors","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"advanced-subset-enumeration","dir":"","previous_headings":"Features","what":"Advanced Subset Enumeration","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Eppstein–Löffler–Strash (ELS) Bron–Kerbosch (optional pivoting) Used internally corrPrune(mode = \"exact\") \"pearson\", \"spearman\", \"kendall\" \"bicor\" (WGCNA), \"distance\" (energy), \"maximal\" (minerva) \"eta\", \"cramersv\" mixed-type data force_in: protect variables removal Deterministic tie-breaking reproducibility","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Install from GitHub remotes::install_github(\"gcol33/corrselect\")"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"association-based-pruning-corrprune","dir":"","previous_headings":"Usage Examples","what":"Association-Based Pruning (corrPrune)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"library(corrselect) data(mtcars)  # Basic: Remove correlated predictors pruned <- corrPrune(mtcars, threshold = 0.7) names(pruned)  # Protect important variables pruned <- corrPrune(mtcars, threshold = 0.7, force_in = \"mpg\")  # Use exact mode (slower, guaranteed optimal) pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"exact\")  # Use greedy mode (faster for large datasets) pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\")  # Check what was removed attr(pruned, \"selected_vars\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"model-based-pruning-modelprune","dir":"","previous_headings":"Usage Examples","what":"Model-Based Pruning (modelPrune)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Linear model with VIF threshold pruned <- modelPrune(mpg ~ cyl + disp + hp + wt, data = mtcars, limit = 5) attr(pruned, \"removed_vars\")  # GLM with binomial family mtcars$am_binary <- as.factor(mtcars$am) pruned <- modelPrune(am_binary ~ cyl + disp + hp,                      data = mtcars, engine = \"glm\",                      family = binomial(), limit = 5)  # Mixed model (requires lme4) if (requireNamespace(\"lme4\", quietly = TRUE)) {   df <- data.frame(     y = rnorm(100),     x1 = rnorm(100),     x2 = rnorm(100),     group = rep(1:10, each = 10)   )   pruned <- modelPrune(y ~ x1 + x2 + (1|group),                        data = df, engine = \"lme4\", limit = 5) }  # Custom engine (advanced: works with any modeling package) # Example: INLA-based pruning if (requireNamespace(\"INLA\", quietly = TRUE)) {   inla_engine <- list(     name = \"inla\",     fit = function(formula, data, ...) {       INLA::inla(formula = formula, data = data,                  family = \"gaussian\", ...)     },     diagnostics = function(model, fixed_effects) {       # Use posterior SD as badness metric       scores <- model$summary.fixed[, \"sd\"]       names(scores) <- rownames(model$summary.fixed)       scores[fixed_effects]     }   )    pruned <- modelPrune(y ~ x1 + x2, data = df,                        engine = inla_engine, limit = 0.5) }"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"exact-subset-enumeration-advanced","dir":"","previous_headings":"Usage Examples","what":"Exact Subset Enumeration (Advanced)","title":"Correlation-Based and Model-Based Predictor Pruning","text":"","code":"# Find ALL maximal subsets res <- corrSelect(mtcars, threshold = 0.7) show(res)  # Extract a specific subset subset1 <- corrSubset(res, mtcars, which = 1)  # Convert to data frame as.data.frame(res)"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"choosing-between-corrprune-and-modelprune","dir":"","previous_headings":"","what":"Choosing Between corrPrune and modelPrune","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Tip: Use corrPrune() first reduce dimensionality, modelPrune() final cleanup within modeling framework.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/index.html","id":"mixed-type-data","dir":"","previous_headings":"Advanced Features","what":"Mixed-Type Data","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Use assocSelect() exact enumeration mixed data types:","code":"df <- data.frame(   height = rnorm(30, 170, 10),   weight = rnorm(30, 70, 12),   group  = factor(sample(c(\"A\",\"B\"), 30, TRUE)),   rating = ordered(sample(c(\"low\",\"med\",\"high\"), 30, TRUE)) )  res <- assocSelect(df, threshold = 0.6) show(res)"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"precomputed-correlation-matrices","dir":"","previous_headings":"Advanced Features","what":"Precomputed Correlation Matrices","title":"Correlation-Based and Model-Based Predictor Pruning","text":"Work directly correlation matrices:","code":"mat <- cor(mtcars) res <- MatSelect(mat, threshold = 0.7, method = \"els\")"},{"path":"https://gcol33.github.io/corrselect/index.html","id":"joss-paper","dir":"","previous_headings":"","what":"JOSS Paper","title":"Correlation-Based and Model-Based Predictor Pruning","text":"repository includes short paper prepared submission Journal Open Source Software (JOSS). can find manuscript references paper/ directory: paper/paper.md – main text paper/paper.bib – bibliography","code":""},{"path":"https://gcol33.github.io/corrselect/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Correlation-Based and Model-Based Predictor Pruning","text":"MIT (see LICENSE.md file)","code":""},{"path":"https://gcol33.github.io/corrselect/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Gilles Colling Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"Converts CorrCombo object data frame variable combinations.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"","code":"# S3 method for class 'CorrCombo' as.data.frame(x, row.names = NULL, optional = FALSE, ...)"},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"x CorrCombo object. row.names Optional row names output data frame. optional Logical. Passed data.frame(). ... Additional arguments passed data.frame().","code":""},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"data frame row corresponds subset variables. Columns named VarName01, VarName02, ..., size largest subset. Subsets shorter maximum length padded NA.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/as.data.frame.CorrCombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce CorrCombo to a Data Frame — as.data.frame.CorrCombo","text":"","code":"set.seed(1) mat <- matrix(rnorm(100), ncol = 10) colnames(mat) <- paste0(\"V\", 1:10) res <- corrSelect(cor(mat), threshold = 0.5) as.data.frame(res) #>                      VarName01 VarName02 VarName03 #> Subset01 [avg=0.261]        V3        V7       V10 #> Subset02 [avg=0.295]        V1        V7       V10 #> Subset03 [avg=0.300]        V8        V9       V10 #> Subset04 [avg=0.331]        V2        V7       V10 #> Subset05 [avg=0.343]        V9        V7       V10 #> Subset06 [avg=0.350]        V3        V8       V10 #> Subset07 [avg=0.374]        V2        V8       V10 #> Subset08 [avg=0.384]        V6        V7       V10 #> Subset09 [avg=0.388]        V6        V8       V10 #> Subset10 [avg=0.086]        V3        V4      <NA> #> Subset11 [avg=0.098]        V5        V8      <NA> #> Subset12 [avg=0.208]        V1        V4      <NA> #> Subset13 [avg=0.220]        V2        V4      <NA> #> Subset14 [avg=0.295]        V9        V4      <NA> #> Subset15 [avg=0.319]        V6        V4      <NA> #> Subset16 [avg=0.407]        V5        V7      <NA>"},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"Identifies combinations variables common data type (numeric, ordered factors, unordered) factors—whose pair-wise association exceed user-supplied threshold. routine wraps MatSelect() handles pre-processing (type conversion, missing-row removal, constant-column checks) typical data-frame/tibble/data-table inputs.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"","code":"assocSelect(   df,   threshold = 0.7,   method = NULL,   force_in = NULL,   method_num_num = c(\"pearson\", \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\"),   method_num_ord = c(\"spearman\", \"kendall\"),   method_ord_ord = c(\"spearman\", \"kendall\"),   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"df data frame (tibble / data.table). May contain mix : numeric / integer (treated numeric) ordered factors unordered factors (character vectors coerced factors) threshold Numeric \\((0,1)\\). Maximum allowed pair-wise absolute association. Default 0.7. method Character; subset-search algorithm. One \"els\" \"bron-kerbosch\".  NULL (default) function selects automatically: ELS force_in supplied, otherwise Bron–Kerbosch. force_in Optional character vector column indices specifying variables must appear every returned subset. method_num_num Association measure numeric–numeric pairs. One \"pearson\" (default), \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\". method_num_ord Association measure numeric–ordered pairs. One \"spearman\" (default) \"kendall\". method_ord_ord Association measure ordered–ordered pairs. One \"spearman\" (default) \"kendall\". ... Additional arguments passed unchanged MatSelect() (e.g., use_pivot = TRUE Bron–Kerbosch).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"CorrCombo S4 object containing: valid subsets, summary association statistics, metadata (algorithm used, rows kept, forced-variables, etc.). object’s show() method prints association metrics actually used data set.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"single call can therefore screen data set mixes continuous categorical features return every subset whose internal associations “sufficiently low” metric(s) choose. Rows containing NA dropped warning; constant columns treated zero association every variable. default association measure variable-type combination : numeric – numeric method_num_num (default \"pearson\") numeric – ordered method_num_ord numeric – unordered \"eta\" (ANOVA \\(\\eta^{2}\\)) ordered – ordered method_ord_ord ordered – unordered \"cramersv\" unordered – unordered \"cramersv\" association measures rescaled \\([0,1]\\) thresholding. External packages required \"bicor\" (WGCNA), \"distance\" (energy), \"maximal\" (minerva); informative error thrown missing.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/assocSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Association (Mixed-Type Data Frame Interface) — assocSelect","text":"","code":"set.seed(42) df <- data.frame(   height = rnorm(15, 170, 10),   weight = rnorm(15, 70, 12),   group  = factor(rep(LETTERS[1:3], each = 5)),   score  = ordered(sample(c(\"low\",\"med\",\"high\"), 15, TRUE)) )  ## keep every subset whose internal associations <= 0.6 assocSelect(df, threshold = 0.6) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: mixed #>   AssocMethod: numeric_numeric = pearson, numeric_factor = eta, numeric_ordered #>                = spearman, factor_ordered = cramersv #>   Threshold:   0.600 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.219  0.475     4  ## use Kendall for all rank-based comparisons and force 'height' to appear assocSelect(df,             threshold       = 0.5,             method_num_num  = \"kendall\",             method_num_ord  = \"kendall\",             method_ord_ord  = \"kendall\",             force_in        = \"height\") #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: mixed #>   AssocMethod: numeric_numeric = kendall, numeric_factor = eta, numeric_ordered #>                = kendall, factor_ordered = cramersv #>   Threshold:   0.500 #>   Subsets:     1 valid combinations #>   Data Rows:   15 used in correlation #>   Forced-in:   height #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] height, weight, group, score      0.193  0.365     4"},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"simulated dataset 19 WorldClim bioclimatic variables (https://www.worldclim.org/data/bioclim.html) measured 100 geographic locations, species richness response variable. Variables organized correlated blocks representing temperature (BIO1-BIO11) precipitation (BIO12-BIO19).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"","code":"bioclim_example"},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"data frame 100 rows 20 variables: species_richness Integer. Number species observed (response variable) BIO1 Numeric. Annual Mean Temperature BIO2 Numeric. Mean Diurnal Range BIO3 Numeric. Isothermality BIO4 Numeric. Temperature Seasonality BIO5 Numeric. Max Temperature Warmest Month BIO6 Numeric. Min Temperature Coldest Month BIO7 Numeric. Temperature Annual Range BIO8 Numeric. Mean Temperature Wettest Quarter BIO9 Numeric. Mean Temperature Driest Quarter BIO10 Numeric. Mean Temperature Warmest Quarter BIO11 Numeric. Mean Temperature Coldest Quarter BIO12 Numeric. Annual Precipitation BIO13 Numeric. Precipitation Wettest Month BIO14 Numeric. Precipitation Driest Month BIO15 Numeric. Precipitation Seasonality BIO16 Numeric. Precipitation Wettest Quarter BIO17 Numeric. Precipitation Driest Quarter BIO18 Numeric. Precipitation Warmest Quarter BIO19 Numeric. Precipitation Coldest Quarter","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"Simulated data based 19 WorldClim bioclimatic variables","code":""},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"dataset demonstrates common problem ecological modeling: bioclimatic predictors highly correlated within groups (temperature variables BIO1-BIO11 highly correlated; precipitation variables BIO12-BIO19 moderately correlated), leading multicollinearity issues. species richness response depends subset predictors. Use case: Demonstrating corrPrune() modelPrune() reducing correlated environmental predictors fitting species distribution models.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/bioclim_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Bioclimatic Data for Ecological Modeling — bioclim_example","text":"","code":"data(bioclim_example)  # The 19 WorldClim bioclimatic variables (https://www.worldclim.org/data/bioclim.html) # Many are highly correlated, making them ideal for pruning  # Remove highly correlated variables pruned <- corrPrune(bioclim_example[, -1], threshold = 0.7) ncol(pruned)  # Reduced from 19 to ~8 variables #> [1] 12  # Model-based pruning with VIF model_data <- modelPrune(species_richness ~ .,                          data = bioclim_example,                          limit = 5) attr(model_data, \"selected_vars\") #>  [1] \"BIO1\"  \"BIO3\"  \"BIO4\"  \"BIO6\"  \"BIO8\"  \"BIO9\"  \"BIO10\" \"BIO11\" \"BIO12\" #> [10] \"BIO13\" \"BIO14\" \"BIO15\" \"BIO16\" \"BIO17\" \"BIO18\" \"BIO19\""},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":null,"dir":"Reference","previous_headings":"","what":"CorrCombo S4 class — CorrCombo","title":"CorrCombo S4 class — CorrCombo","text":"Holds result corrSelect MatSelect: list valid variable combinations correlation statistics. class stores subsets variables meet specified correlation constraint, along metadata algorithm used, correlation method(s), variables forced every subset, summary statistics combination.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CorrCombo S4 class — CorrCombo","text":"","code":"# S4 method for class 'CorrCombo' show(object)"},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CorrCombo S4 class — CorrCombo","text":"object CorrCombo object printed.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"CorrCombo S4 class — CorrCombo","text":"subset_list list character vectors. vector valid subset (variable names). avg_corr numeric vector. Average absolute correlation within subset. min_corr numeric vector. Minimum pairwise absolute correlation subset. max_corr numeric vector. Maximum pairwise absolute correlation within subset. names Character vector variable names used decoding. threshold Numeric scalar. correlation threshold used selection. forced_in Character vector. Variable names forced subset. search_type Character string. One \"els\" \"bron-kerbosch\". cor_method Character string. Either single method (e.g. \"pearson\") \"mixed\" multiple methods used. n_rows_used Integer. Number rows used computing correlation matrix (removing missing values).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/CorrCombo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CorrCombo S4 class — CorrCombo","text":"","code":"show(new(\"CorrCombo\",   subset_list = list(c(\"A\", \"B\"), c(\"A\", \"C\")),   avg_corr = c(0.2, 0.3),   min_corr = c(0.1, 0.2),   max_corr = c(0.3, 0.4),   names = c(\"A\", \"B\", \"C\"),   threshold = 0.5,   forced_in = character(),   search_type = \"els\",   cor_method = \"mixed\",   n_rows_used = as.integer(5) )) #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: mixed #>   Threshold:   0.500 #>   Subsets:     2 valid combinations #>   Data Rows:   5 used in correlation #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] A, B                              0.200  0.300     2 #>   [ 2] A, C                              0.300  0.400     2"},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":null,"dir":"Reference","previous_headings":"","what":"Association-Based Predictor Pruning — corrPrune","title":"Association-Based Predictor Pruning — corrPrune","text":"corrPrune() performs model-free variable subset selection iteratively removing predictors pairwise associations fall specified threshold. returns single pruned data frame predictors satisfy association constraint.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Association-Based Predictor Pruning — corrPrune","text":"","code":"corrPrune(   data,   threshold = 0.7,   measure = \"auto\",   mode = \"auto\",   force_in = NULL,   by = NULL,   group_q = 1,   max_exact_p = 20,   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Association-Based Predictor Pruning — corrPrune","text":"data data.frame containing candidate predictors. threshold Numeric scalar. Maximum allowed pairwise association (default: 0.7). Must non-negative. measure Character string specifying association measure use. Options: \"auto\" (default), \"pearson\", \"spearman\", \"kendall\", \"cramersv\", \"eta\", etc. \"auto\", Pearson correlation used -numeric data, appropriate measures selected mixed-type data. mode Character string specifying search algorithm. Options: \"auto\" (default): uses exact search number predictors ≤ max_exact_p, otherwise uses greedy search \"exact\": exhaustive search maximal subsets (may slow large p) \"greedy\": fast approximate search using iterative removal force_in Character vector variable names must retained final subset. Default: NULL. Character vector naming one grouping variables. provided, associations computed separately within group, aggregated using quantile specified group_q. Default: NULL (grouping). group_q Numeric scalar (0, 1]. Quantile used aggregate associations across groups provided. Default: 1 (maximum, ensuring threshold holds groups). Use 0.9 90th percentile, etc. max_exact_p Integer. Maximum number predictors exact mode used mode = \"auto\". Default: 20. ... Additional arguments (reserved future use).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Association-Based Predictor Pruning — corrPrune","text":"data.frame containing pruned subset predictors. result following attributes: selected_vars Character vector retained variable names mode Character string indicating mode used (\"exact\" \"greedy\") measure Character string indicating association measure used threshold threshold value used","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Association-Based Predictor Pruning — corrPrune","text":"corrPrune() identifies subset predictors whose pairwise associations threshold. function works several stages: Variable type detection: Identifies numeric vs. categorical predictors Association measurement: Computes appropriate pairwise associations Grouping (optional): specified, computes associations within group aggregates using specified quantile Feasibility check: Verifies force_in variables satisfy threshold constraint Subset selection: Uses either exact greedy search find valid subset Grouped Pruning: provided, function ensures selected predictors satisfy threshold constraint across groups. example, group_q = 1 (default), returned predictors pairwise associations threshold groups. group_q = 0.9, satisfy constraint least 90% groups. Mode Selection: Exact mode guarantees finding maximal subsets returns largest one (deterministic tie-breaking). Greedy mode faster approximate, using deterministic removal strategy based association scores.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrPrune.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Association-Based Predictor Pruning — corrPrune","text":"","code":"# Basic numeric data pruning data(mtcars) pruned <- corrPrune(mtcars, threshold = 0.7) names(pruned) #> [1] \"mpg\"  \"drat\" \"qsec\" \"gear\" \"carb\"  # Force certain variables to be included pruned <- corrPrune(mtcars, threshold = 0.7, force_in = \"mpg\")  # Use greedy mode for faster computation pruned <- corrPrune(mtcars, threshold = 0.7, mode = \"greedy\")"},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"Identifies combinations numeric variables data frame pairwise absolute correlations fall specified threshold. function wrapper around MatSelect() accepts data frames, tibbles, data tables automatic preprocessing.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"","code":"corrSelect(   df,   threshold = 0.7,   method = NULL,   force_in = NULL,   cor_method = c(\"pearson\", \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\"),   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"df data frame. numeric columns used. threshold numeric value (0, 1). Maximum allowed absolute correlation. Defaults 0.7. method Character. Selection algorithm use. One \"els\" \"bron-kerbosch\". specified, function chooses automatically: \"els\" force_in provided, otherwise \"bron-kerbosch\". force_in Optional character vector numeric indices columns force subsets. cor_method Character string indicating correlation method use. One \"pearson\" (default), \"spearman\", \"kendall\", \"bicor\", \"distance\", \"maximal\". ... Additional arguments passed MatSelect(), e.g., use_pivot.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"object class CorrCombo, containing selected subsets correlation statistics.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"numeric columns used correlation analysis. Non‐numeric columns (factors, characters, logicals, etc.) ignored, names types printed inform user. can optionally reattached later using corrSubset() keepExtra = TRUE. Rows missing values removed computing correlations. warning issued rows dropped. cor_method controls correlation matrix computed: \"pearson\": Standard linear correlation. \"spearman\": Rank-based monotonic correlation. \"kendall\": Kendall's tau. \"bicor\": Biweight midcorrelation (WGCNA::bicor). \"distance\": Distance correlation (energy::dcor). \"maximal\": Maximal information coefficient (minerva::mine). \"bicor\", \"distance\", \"maximal\", corresponding package must installed.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Correlation (Data Frame Interface) — corrSelect","text":"","code":"set.seed(42) n <- 100  # Create 20 variables: 5 blocks of correlated variables + some noise block1 <- matrix(rnorm(n * 4), ncol = 4) block2 <- matrix(rnorm(n), ncol = 1) block2 <- matrix(rep(block2, 4), ncol = 4) + matrix(rnorm(n * 4, sd = 0.1), ncol = 4) block3 <- matrix(rnorm(n * 4), ncol = 4) block4 <- matrix(rnorm(n * 4), ncol = 4) block5 <- matrix(rnorm(n * 4), ncol = 4)  df <- as.data.frame(cbind(block1, block2, block3, block4, block5)) colnames(df) <- paste0(\"V\", 1:20)  # Add a non-numeric column to be ignored df$label <- factor(sample(c(\"A\", \"B\"), n, replace = TRUE))  # Basic usage corrSelect(df, threshold = 0.8) #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.800 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.075  0.241    17 #>   [ 2] V1, V2, V3, V4, V6, V9, ...       0.075  0.259    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.075  0.269    17 #>   [ 4] V1, V2, V3, V4, V5, V9, ...       0.076  0.288    17  # Try Bron–Kerbosch with pivoting corrSelect(df, threshold = 0.6, method = \"bron-kerbosch\", use_pivot = TRUE) #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      bron-kerbosch #>   Correlation: pearson #>   Threshold:   0.600 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Pivot:       TRUE #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.075  0.241    17 #>   [ 2] V1, V2, V3, V4, V6, V9, ...       0.075  0.259    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.075  0.269    17 #>   [ 4] V1, V2, V3, V4, V5, V9, ...       0.076  0.288    17  # Force in a specific variable and use Spearman correlation corrSelect(df, threshold = 0.6, force_in = \"V10\", cor_method = \"spearman\") #> The following variables were excluded from the correlation analysis: #>   - label: unordered factor (excluded) #> CorrCombo object #> ----------------- #>   Method:      els #>   Correlation: spearman #>   Threshold:   0.600 #>   Subsets:     4 valid combinations #>   Data Rows:   100 used in correlation #>   Forced-in:   V10 #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V1, V2, V3, V4, V7, V9, ...       0.076  0.239    17 #>   [ 2] V1, V2, V3, V4, V5, V9, ...       0.076  0.269    17 #>   [ 3] V1, V2, V3, V4, V8, V9, ...       0.076  0.246    17 #>   [ 4] V1, V2, V3, V4, V6, V9, ...       0.076  0.252    17"},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Variable Subsets from a CorrCombo Object — corrSubset","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"Extracts one variable subsets CorrCombo object data frames. Typically used corrSelect MatSelect obtain filtered versions original dataset containing low‐correlation variable combinations.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"","code":"corrSubset(res, df, which = \"best\", keepExtra = FALSE)"},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"res CorrCombo object returned corrSelect MatSelect. df data frame matrix. Must contain variables listed res@names. Columns res@names ignored unless keepExtra = TRUE. Subsets extract. One : \"best\" (default) 1: top‐ranked subset. single integer (e.g. 2): nth ranked subset. vector integers (e.g. 1:3): multiple subsets. \"\": available subsets. Subsets ranked decreasing size, increasing average correlation. keepExtra Logical. TRUE, columns df res@names (e.g., factors, characters) retained. Defaults FALSE.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"data frame single subset extracted, list data frames multiple subsets extracted. data frame contains selected variables (optionally extras).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"warning issued rows contain missing values selected variables.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/corrSubset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Variable Subsets from a CorrCombo Object — corrSubset","text":"","code":"# Simulate input data set.seed(123) df <- as.data.frame(matrix(rnorm(100), nrow = 10)) colnames(df) <- paste0(\"V\", 1:10)  # Compute correlation matrix cmat <- cor(df)  # Select subsets using corrSelect res <- corrSelect(cmat, threshold = 0.5)  # Extract the best subset (default) corrSubset(res, df) #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469  # Extract the second-best subset corrSubset(res, df, which = 2) #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469  # Extract the first three subsets corrSubset(res, df, which = 1:3) #> $Subset1 #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset2 #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset3 #>            V2          V5          V6          V7 #> 1   1.2240818 -0.69470698  0.25331851  0.37963948 #> 2   0.3598138 -0.20791728 -0.02854676 -0.50232345 #> 3   0.4007715 -1.26539635 -0.04287046 -0.33320738 #> 4   0.1106827  2.16895597  1.36860228 -1.01857538 #> 5  -0.5558411  1.20796200 -0.22577099 -1.07179123 #> 6   1.7869131 -1.12310858  1.51647060  0.30352864 #> 7   0.4978505 -0.40288484 -1.54875280  0.44820978 #> 8  -1.9666172 -0.46665535  0.58461375  0.05300423 #> 9   0.7013559  0.77996512  0.12385424  0.92226747 #> 10 -0.4727914 -0.08336907  0.21594157  2.05008469 #>   # Extract all subsets corrSubset(res, df, which = \"all\") #> $Subset1 #>            V2          V5        V10          V7 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset2 #>             V1          V5        V10          V7 #> 1  -0.56047565 -0.69470698  0.9935039  0.37963948 #> 2  -0.23017749 -0.20791728  0.5483970 -0.50232345 #> 3   1.55870831 -1.26539635  0.2387317 -0.33320738 #> 4   0.07050839  2.16895597 -0.6279061 -1.01857538 #> 5   0.12928774  1.20796200  1.3606524 -1.07179123 #> 6   1.71506499 -1.12310858 -0.6002596  0.30352864 #> 7   0.46091621 -0.40288484  2.1873330  0.44820978 #> 8  -1.26506123 -0.46665535  1.5326106  0.05300423 #> 9  -0.68685285  0.77996512 -0.2357004  0.92226747 #> 10 -0.44566197 -0.08336907 -1.0264209  2.05008469 #>  #> $Subset3 #>            V2          V5          V6          V7 #> 1   1.2240818 -0.69470698  0.25331851  0.37963948 #> 2   0.3598138 -0.20791728 -0.02854676 -0.50232345 #> 3   0.4007715 -1.26539635 -0.04287046 -0.33320738 #> 4   0.1106827  2.16895597  1.36860228 -1.01857538 #> 5  -0.5558411  1.20796200 -0.22577099 -1.07179123 #> 6   1.7869131 -1.12310858  1.51647060  0.30352864 #> 7   0.4978505 -0.40288484 -1.54875280  0.44820978 #> 8  -1.9666172 -0.46665535  0.58461375  0.05300423 #> 9   0.7013559  0.77996512  0.12385424  0.92226747 #> 10 -0.4727914 -0.08336907  0.21594157  2.05008469 #>  #> $Subset4 #>             V1          V5          V6          V7 #> 1  -0.56047565 -0.69470698  0.25331851  0.37963948 #> 2  -0.23017749 -0.20791728 -0.02854676 -0.50232345 #> 3   1.55870831 -1.26539635 -0.04287046 -0.33320738 #> 4   0.07050839  2.16895597  1.36860228 -1.01857538 #> 5   0.12928774  1.20796200 -0.22577099 -1.07179123 #> 6   1.71506499 -1.12310858  1.51647060  0.30352864 #> 7   0.46091621 -0.40288484 -1.54875280  0.44820978 #> 8  -1.26506123 -0.46665535  0.58461375  0.05300423 #> 9  -0.68685285  0.77996512  0.12385424  0.92226747 #> 10 -0.44566197 -0.08336907  0.21594157  2.05008469 #>  #> $Subset5 #>             V4          V5        V10 #> 1   0.42646422 -0.69470698  0.9935039 #> 2  -0.29507148 -0.20791728  0.5483970 #> 3   0.89512566 -1.26539635  0.2387317 #> 4   0.87813349  2.16895597 -0.6279061 #> 5   0.82158108  1.20796200  1.3606524 #> 6   0.68864025 -1.12310858 -0.6002596 #> 7   0.55391765 -0.40288484  2.1873330 #> 8  -0.06191171 -0.46665535  1.5326106 #> 9  -0.30596266  0.77996512 -0.2357004 #> 10 -0.38047100 -0.08336907 -1.0264209 #>  #> $Subset6 #>              V9          V5        V10 #> 1   0.005764186 -0.69470698  0.9935039 #> 2   0.385280401 -0.20791728  0.5483970 #> 3  -0.370660032 -1.26539635  0.2387317 #> 4   0.644376549  2.16895597 -0.6279061 #> 5  -0.220486562  1.20796200  1.3606524 #> 6   0.331781964 -1.12310858 -0.6002596 #> 7   1.096839013 -0.40288484  2.1873330 #> 8   0.435181491 -0.46665535  1.5326106 #> 9  -0.325931586  0.77996512 -0.2357004 #> 10  1.148807618 -0.08336907 -1.0264209 #>  #> $Subset7 #>            V3          V5        V10 #> 1  -1.0678237 -0.69470698  0.9935039 #> 2  -0.2179749 -0.20791728  0.5483970 #> 3  -1.0260044 -1.26539635  0.2387317 #> 4  -0.7288912  2.16895597 -0.6279061 #> 5  -0.6250393  1.20796200  1.3606524 #> 6  -1.6866933 -1.12310858 -0.6002596 #> 7   0.8377870 -0.40288484  2.1873330 #> 8   0.1533731 -0.46665535  1.5326106 #> 9  -1.1381369  0.77996512 -0.2357004 #> 10  1.2538149 -0.08336907 -1.0264209 #>  #> $Subset8 #>             V4          V5          V6 #> 1   0.42646422 -0.69470698  0.25331851 #> 2  -0.29507148 -0.20791728 -0.02854676 #> 3   0.89512566 -1.26539635 -0.04287046 #> 4   0.87813349  2.16895597  1.36860228 #> 5   0.82158108  1.20796200 -0.22577099 #> 6   0.68864025 -1.12310858  1.51647060 #> 7   0.55391765 -0.40288484 -1.54875280 #> 8  -0.06191171 -0.46665535  0.58461375 #> 9  -0.30596266  0.77996512  0.12385424 #> 10 -0.38047100 -0.08336907  0.21594157 #>  #> $Subset9 #>            V8          V6          V7 #> 1  -0.4910312  0.25331851  0.37963948 #> 2  -2.3091689 -0.02854676 -0.50232345 #> 3   1.0057385 -0.04287046 -0.33320738 #> 4  -0.7092008  1.36860228 -1.01857538 #> 5  -0.6880086 -0.22577099 -1.07179123 #> 6   1.0255714  1.51647060  0.30352864 #> 7  -0.2847730 -1.54875280  0.44820978 #> 8  -1.2207177  0.58461375  0.05300423 #> 9   0.1813035  0.12385424  0.92226747 #> 10 -0.1388914  0.21594157  2.05008469 #>  #> $Subset10 #>              V9          V5          V6 #> 1   0.005764186 -0.69470698  0.25331851 #> 2   0.385280401 -0.20791728 -0.02854676 #> 3  -0.370660032 -1.26539635 -0.04287046 #> 4   0.644376549  2.16895597  1.36860228 #> 5  -0.220486562  1.20796200 -0.22577099 #> 6   0.331781964 -1.12310858  1.51647060 #> 7   1.096839013 -0.40288484 -1.54875280 #> 8   0.435181491 -0.46665535  0.58461375 #> 9  -0.325931586  0.77996512  0.12385424 #> 10  1.148807618 -0.08336907  0.21594157 #>   # Extract best subset and retain additional numeric column df$CopyV1 <- df$V1 corrSubset(res, df, which = 1, keepExtra = TRUE) #>            V2          V5        V10          V7      CopyV1 #> 1   1.2240818 -0.69470698  0.9935039  0.37963948 -0.56047565 #> 2   0.3598138 -0.20791728  0.5483970 -0.50232345 -0.23017749 #> 3   0.4007715 -1.26539635  0.2387317 -0.33320738  1.55870831 #> 4   0.1106827  2.16895597 -0.6279061 -1.01857538  0.07050839 #> 5  -0.5558411  1.20796200  1.3606524 -1.07179123  0.12928774 #> 6   1.7869131 -1.12310858 -0.6002596  0.30352864  1.71506499 #> 7   0.4978505 -0.40288484  2.1873330  0.44820978  0.46091621 #> 8  -1.9666172 -0.46665535  1.5326106  0.05300423 -1.26506123 #> 9   0.7013559  0.77996512 -0.2357004  0.92226747 -0.68685285 #> 10 -0.4727914 -0.08336907 -1.0264209  2.05008469 -0.44566197"},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Correlation Matrix with Block Structure — cor_example","title":"Example Correlation Matrix with Block Structure — cor_example","text":"20x20 correlation matrix known block structure designed demonstrating threshold selection, algorithm comparison, visualization examples vignettes.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Correlation Matrix with Block Structure — cor_example","text":"","code":"cor_example"},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Correlation Matrix with Block Structure — cor_example","text":"20x20 numeric correlation matrix row column names V1-V20. matrix four distinct correlation blocks: Block 1 (V1-V5) High correlation: mean = 0.81, range = (0.75, 0.95) Block 2 (V6-V10) Moderate correlation: mean = 0.57, range = (0.5, 0.7) Block 3 (V11-V15) Low correlation: mean = 0.28, range = (0.2, 0.4) Block 4 (V16-V20) Minimal correlation: mean = 0.06, range = (0.0, 0.15) -block correlations low (range = (0.0, 0.3)). matrix guaranteed positive definite.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Correlation Matrix with Block Structure — cor_example","text":"Generated data-raw/create_cor_example.R using seed 20250125.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Correlation Matrix with Block Structure — cor_example","text":"dataset provides controlled correlation structure useful : Threshold sensitivity analysis (comparing results τ = 0.5, 0.7, 0.9) Algorithm comparison (exact vs greedy modes) Visualization examples (heatmaps, correlation distributions) Reproducible benchmarks across vignettes Expected behavior different thresholds: τ = 0.5: Block 1 requires pruning (pairs > 0.75) τ = 0.7: Blocks 1-2 require pruning τ = 0.9: Block 1 requires pruning","code":""},{"path":"https://gcol33.github.io/corrselect/reference/cor_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Correlation Matrix with Block Structure — cor_example","text":"","code":"data(cor_example)  # Matrix dimensions dim(cor_example) #> [1] 20 20  # Visualize structure if (requireNamespace(\"corrplot\", quietly = TRUE)) {   corrplot::corrplot(cor_example, method = \"color\", type = \"upper\",                      tl.col = \"black\", tl.cex = 0.7) }   # Distribution of correlations hist(cor_example[upper.tri(cor_example)],      breaks = 30,      main = \"Distribution of Correlations in cor_example\",      xlab = \"Correlation\",      col = \"steelblue\")   # Use with MatSelect library(corrselect) results <- MatSelect(cor_example, threshold = 0.7, method = \"els\") show(results) #> CorrCombo object #> ----------------- #>   Method:      els #>   Threshold:   0.700 #>   Subsets:     5 valid combinations #>   Data Rows:   20 used in correlation #>  #> Top combinations: #>   No.  Variables                          Avg    Max    Size #>   ------------------------------------------------------------ #>   [ 1] V2, V6, V7, V8, V9, V10, ...      0.173  0.627    16 #>   [ 2] V4, V6, V7, V8, V9, V10, ...      0.176  0.627    16 #>   [ 3] V1, V6, V7, V8, V9, V10, ...      0.181  0.627    16 #>   [ 4] V3, V6, V7, V8, V9, V10, ...      0.182  0.627    16 #>   [ 5] V5, V6, V7, V8, V9, V10, ...      0.183  0.627    16"},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Gene Expression Data for Bioinformatics — genes_example","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"simulated gene expression dataset 200 genes measured across 100 samples, organized co-expression modules binary disease outcome.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"","code":"genes_example"},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"data frame 100 rows 202 variables: sample_id Character. Unique sample identifier disease_status Factor. Disease status (Healthy, Disease) GENE001, GENE002, GENE003, GENE004, GENE005, GENE006, GENE007, GENE008, GENE009, GENE010, GENE011, GENE012, GENE013, GENE014, GENE015, GENE016, GENE017, GENE018, GENE019, GENE020, GENE021, GENE022, GENE023, GENE024, GENE025, GENE026, GENE027, GENE028, GENE029, GENE030, GENE031, GENE032, GENE033, GENE034, GENE035, GENE036, GENE037, GENE038, GENE039, GENE040, GENE041, GENE042, GENE043, GENE044, GENE045, GENE046, GENE047, GENE048, GENE049, GENE050, GENE051, GENE052, GENE053, GENE054, GENE055, GENE056, GENE057, GENE058, GENE059, GENE060, GENE061, GENE062, GENE063, GENE064, GENE065, GENE066, GENE067, GENE068, GENE069, GENE070, GENE071, GENE072, GENE073, GENE074, GENE075, GENE076, GENE077, GENE078, GENE079, GENE080, GENE081, GENE082, GENE083, GENE084, GENE085, GENE086, GENE087, GENE088, GENE089, GENE090, GENE091, GENE092, GENE093, GENE094, GENE095, GENE096, GENE097, GENE098, GENE099, GENE100, GENE101, GENE102, GENE103, GENE104, GENE105, GENE106, GENE107, GENE108, GENE109, GENE110, GENE111, GENE112, GENE113, GENE114, GENE115, GENE116, GENE117, GENE118, GENE119, GENE120, GENE121, GENE122, GENE123, GENE124, GENE125, GENE126, GENE127, GENE128, GENE129, GENE130, GENE131, GENE132, GENE133, GENE134, GENE135, GENE136, GENE137, GENE138, GENE139, GENE140, GENE141, GENE142, GENE143, GENE144, GENE145, GENE146, GENE147, GENE148, GENE149, GENE150, GENE151, GENE152, GENE153, GENE154, GENE155, GENE156, GENE157, GENE158, GENE159, GENE160, GENE161, GENE162, GENE163, GENE164, GENE165, GENE166, GENE167, GENE168, GENE169, GENE170, GENE171, GENE172, GENE173, GENE174, GENE175, GENE176, GENE177, GENE178, GENE179, GENE180, GENE181, GENE182, GENE183, GENE184, GENE185, GENE186, GENE187, GENE188, GENE189, GENE190, GENE191, GENE192, GENE193, GENE194, GENE195, GENE196, GENE197, GENE198, GENE199, GENE200 Numeric. Gene expression values (log-transformed)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"Simulated data based typical gene expression microarray structures","code":""},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"dataset simulates high-dimensional, low-sample scenario common genomics. Genes organized four co-expression modules: Module 1 (GENE001-GENE050): Highly correlated (r ≈ 0.80), disease-associated Module 2 (GENE051-GENE100): Moderately correlated (r ≈ 0.60) Module 3 (GENE101-GENE150): Weakly correlated (r ≈ 0.40) Module 4 (GENE151-GENE200): Independent (r ≈ 0) Disease outcome depends subset genes Module 1. Use case: Demonstrating corrPrune() mode = \"greedy\" handling high-dimensional data efficiently.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/genes_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Gene Expression Data for Bioinformatics — genes_example","text":"","code":"data(genes_example)  # Greedy pruning for high-dimensional data gene_data <- genes_example[, -(1:2)]  # Exclude ID and outcome pruned <- corrPrune(gene_data, threshold = 0.8, mode = \"greedy\") ncol(pruned)  # Reduced from 200 to ~50 genes #> [1] 177  # Use pruned genes for classification pruned_with_outcome <- data.frame(   disease_status = genes_example$disease_status,   pruned )"},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Longitudinal Data for Clinical Research — longitudinal_example","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"simulated longitudinal study dataset 50 subjects measured 10 timepoints , 20 correlated predictors nested random effects (subject site).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"","code":"longitudinal_example"},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"data frame 500 rows 25 variables: obs_id Integer. Observation identifier (1-500) subject Factor. Subject identifier (1-50) site Factor. Study site identifier (1-5) time Integer. Measurement timepoint (1-10) outcome Numeric. Continuous outcome variable x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20 Numeric. Correlated predictor variables","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"Simulated data based typical clinical trial designs","code":""},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"dataset represents typical longitudinal study repeated measures. Predictors correlated within subjects: Predictors x1-x10: Highly correlated (r ≈ 0.75) Predictors x11-x20: Moderately correlated (r ≈ 0.50) outcome depends time (linear trend), random effects (subject site), subset fixed-effect predictors (x1, x5, x15). Use case: Demonstrating modelPrune() mixed models (lme4 engine) prune fixed effects preserving random effects structure.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/longitudinal_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Longitudinal Data for Clinical Research — longitudinal_example","text":"","code":"data(longitudinal_example)  if (FALSE) { # \\dontrun{ # Prune fixed effects in mixed model (requires lme4) if (requireNamespace(\"lme4\", quietly = TRUE)) {   pruned <- modelPrune(     outcome ~ x1 + x2 + x3 + x4 + x5 + (1|subject) + (1|site),     data = longitudinal_example,     engine = \"lme4\",     limit = 5   )    # Random effects preserved, only fixed effects pruned   attr(pruned, \"selected_vars\") } } # }"},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"Identifies maximal subsets variables symmetric matrix (typically correlation matrix) pairwise absolute values stay specified threshold. Implements exact algorithms Eppstein–Löffler–Strash (ELS) Bron–Kerbosch (without pivoting).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"","code":"MatSelect(mat, threshold = 0.7, method = NULL, force_in = NULL, ...)"},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"mat numeric, symmetric matrix 1s diagonal (e.g. correlation matrix). Column names (present) used label output variables. threshold numeric scalar (0, 1). Maximum allowed absolute pairwise value. Defaults 0.7. method Character. Selection algorithm use. One \"els\" \"bron-kerbosch\". specified, function chooses automatically: \"els\" force_in provided, otherwise \"bron-kerbosch\". force_in Optional integer vector 1-based column indices force every subset. ... Additional arguments passed backend, e.g., use_pivot (logical) enabling pivoting Bron–Kerbosch (ignored ELS).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"object class CorrCombo, containing valid subsets correlation statistics.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/MatSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select Variable Subsets with Low Correlation or Association (Matrix Interface) — MatSelect","text":"","code":"set.seed(42) mat <- matrix(rnorm(100), ncol = 10) colnames(mat) <- paste0(\"V\", 1:10) cmat <- cor(mat)  # Default method (Bron-Kerbosch) res1 <- MatSelect(cmat, threshold = 0.5)  # Bron–Kerbosch without pivot res2 <- MatSelect(cmat, threshold = 0.5, method = \"bron-kerbosch\", use_pivot = FALSE)  # Bron–Kerbosch with pivoting res3 <- MatSelect(cmat, threshold = 0.5, method = \"bron-kerbosch\", use_pivot = TRUE)  # Force variable 1 into every subset (with warning if too correlated) res4 <- MatSelect(cmat, threshold = 0.5, force_in = 1)"},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":null,"dir":"Reference","previous_headings":"","what":"Model-Based Predictor Pruning — modelPrune","title":"Model-Based Predictor Pruning — modelPrune","text":"modelPrune() performs iterative removal fixed-effect predictors based model diagnostics (e.g., VIF) remaining predictors satisfy specified threshold. supports linear models, generalized linear models, mixed models.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model-Based Predictor Pruning — modelPrune","text":"","code":"modelPrune(   formula,   data,   engine = \"lm\",   criterion = \"vif\",   limit = 5,   force_in = NULL,   max_steps = NULL,   ... )"},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model-Based Predictor Pruning — modelPrune","text":"formula model formula specifying response predictors. May include random effects mixed models (e.g., y ~ x1 + x2 + (1|group)). data data.frame containing variables formula. engine Either character string built-engines, list defining custom engine. Built-engines (character string): \"lm\" (default): Linear models via stats::lm() \"glm\": Generalized linear models via stats::glm() (requires family argument) \"lme4\": Mixed models via lme4::lmer() lme4::glmer() (requires lme4 package) \"glmmTMB\": Generalized linear mixed models via glmmTMB::glmmTMB() (requires glmmTMB package) Custom engine (named list required components): fit: function(formula, data, ...) returns fitted model object diagnostics: function(model, fixed_effects) returns named numeric vector diagnostic scores (one per fixed effect, higher values = worse) name (optional): character string used error messages (default: \"custom\") criterion Character string specifying diagnostic criterion pruning. built-engines, \"vif\" (Variance Inflation Factor) supported. custom engines, parameter ignored (diagnostics computed engine's diagnostics function). Default: \"vif\". limit Numeric scalar. Maximum allowed value criterion. Predictors diagnostic values exceeding limit iteratively removed. Default: 5 (common VIF threshold). force_in Character vector predictor names must retained final model. variables removed pruning. Default: NULL. max_steps Integer. Maximum number pruning iterations. NULL (default), pruning continues diagnostics limit removable predictors remain. ... Additional arguments passed modeling function (e.g., family glm/glmer, control parameters lme4/glmmTMB).","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model-Based Predictor Pruning — modelPrune","text":"data.frame containing retained predictors (response). result following attributes: selected_vars Character vector retained predictor names removed_vars Character vector removed predictor names (order removal) engine Character string indicating engine used criterion Character string indicating criterion used limit threshold value used final_model final fitted model object (optional)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model-Based Predictor Pruning — modelPrune","text":"modelPrune() works : Parsing formula identify fixed-effect predictors Fitting initial model Computing diagnostics fixed-effect predictor Checking feasibility force_in constraints Iteratively removing predictor worst diagnostic value (excluding force_in variables) diagnostics ≤ limit Returning pruned data frame Random Effects: mixed models (lme4, glmmTMB), fixed-effect predictors considered pruning. Random-effect structure preserved exactly specified original formula. VIF Computation: Variance Inflation Factors computed fixed-effects design matrix. categorical predictors, VIF represents inflation entire factor (individual dummy variables). Determinism: algorithm deterministic. Ties diagnostic values broken removing predictor appears last formula. Force-Constraints: variables force_in violate diagnostic threshold, function error. ensures constraint feasible pruning begins.","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/modelPrune.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model-Based Predictor Pruning — modelPrune","text":"","code":"# Linear model with VIF-based pruning data(mtcars) pruned <- modelPrune(mpg ~ ., data = mtcars, engine = \"lm\", limit = 5) names(pruned) #> [1] \"mpg\"  \"drat\" \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\"  # Force certain predictors to remain pruned <- modelPrune(mpg ~ ., data = mtcars, force_in = \"drat\", limit = 20)  # GLM example (requires family argument) pruned <- modelPrune(am ~ ., data = mtcars, engine = \"glm\",                      family = binomial(), limit = 5) #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: glm.fit: algorithm did not converge #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred  if (FALSE) { # \\dontrun{ # Custom engine example (INLA) inla_engine <- list(   name = \"inla\",   fit = function(formula, data, ...) {     inla::inla(formula = formula, data = data,                family = list(...)$family %||% \"gaussian\",                control.compute = list(config = TRUE))   },   diagnostics = function(model, fixed_effects) {     scores <- model$summary.fixed[, \"sd\"]     names(scores) <- rownames(model$summary.fixed)     scores[fixed_effects]   } )  pruned <- modelPrune(y ~ x1 + x2 + x3, data = df,                      engine = inla_engine, limit = 0.5) } # }"},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example Survey Data for Social Science Research — survey_example","title":"Example Survey Data for Social Science Research — survey_example","text":"simulated questionnaire dataset 30 Likert-scale items measuring three latent constructs (satisfaction, engagement, loyalty), plus demographic variables overall satisfaction score.","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example Survey Data for Social Science Research — survey_example","text":"","code":"survey_example"},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Example Survey Data for Social Science Research — survey_example","text":"data frame 200 rows 35 variables: respondent_id Integer. Unique respondent identifier age Integer. Respondent age (18-75 years) gender Factor. Gender (Male, Female, ) education Ordered factor. Education level (High School, Bachelor, Master, PhD) overall_satisfaction Integer. Overall satisfaction score (0-100) satisfaction_1, satisfaction_2, satisfaction_3, satisfaction_4, satisfaction_5, satisfaction_6, satisfaction_7, satisfaction_8, satisfaction_9, satisfaction_10 Ordered factor. Satisfaction items (1-7 Likert scale) engagement_1, engagement_2, engagement_3, engagement_4, engagement_5, engagement_6, engagement_7, engagement_8, engagement_9, engagement_10 Ordered factor. Engagement items (1-7 Likert scale) loyalty_1, loyalty_2, loyalty_3, loyalty_4, loyalty_5, loyalty_6, loyalty_7, loyalty_8, loyalty_9, loyalty_10 Ordered factor. Loyalty items (1-7 Likert scale)","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Example Survey Data for Social Science Research — survey_example","text":"Simulated data based typical customer satisfaction survey structures","code":""},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Example Survey Data for Social Science Research — survey_example","text":"dataset represents common scenario survey research: multiple items measuring similar constructs lead redundancy multicollinearity. Items within construct correlated (satisfaction, engagement, loyalty), constructs inter-correlated. Use case: Demonstrating assocSelect() identifying redundant questionnaire items mixed-type data (ordered factors + numeric variables).","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/reference/survey_example.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Example Survey Data for Social Science Research — survey_example","text":"","code":"data(survey_example)  # This dataset has mixed types: numeric (age, overall_satisfaction), # factors (gender, education), and ordered factors (Likert items) str(survey_example[, 1:10]) #> 'data.frame':\t200 obs. of  10 variables: #>  $ respondent_id       : int  1 2 3 4 5 6 7 8 9 10 ... #>  $ age                 : num  38 32 18 18 19 39 33 26 26 42 ... #>  $ gender              : Factor w/ 3 levels \"Female\",\"Male\",..: 2 3 1 2 2 1 1 2 2 1 ... #>  $ education           : Ord.factor w/ 4 levels \"High School\"<..: 3 1 4 2 2 1 1 1 2 3 ... #>  $ overall_satisfaction: num  58 40 44 40 58 67 61 49 51 52 ... #>  $ satisfaction_1      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 5 3 4 5 5 4 4 5 ... #>  $ satisfaction_2      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 4 6 6 4 4 3 ... #>  $ satisfaction_3      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 3 3 4 5 3 4 4 ... #>  $ satisfaction_4      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 6 3 4 4 4 5 4 3 2 4 ... #>  $ satisfaction_5      : Ord.factor w/ 7 levels \"1\"<\"2\"<\"3\"<\"4\"<..: 7 4 5 5 5 4 3 6 4 6 ...  # \\donttest{ # Use assocSelect() for mixed-type data pruning # This may take a few seconds with 34 variables pruned <- assocSelect(survey_example[, -1],  # Exclude respondent_id                       threshold = 0.8,                       method_ord_ord = \"spearman\") length(attr(pruned, \"selected_vars\")) #> [1] 0 # }"},{"path":[]},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"major-release-predictor-pruning-toolkit-3-0-0","dir":"Changelog","previous_headings":"","what":"Major Release: Predictor Pruning Toolkit","title":"corrselect 3.0.0","text":"Version 3.0.0 represents major expansion corrselect specialized subset enumeration tool comprehensive predictor pruning toolkit. Fully backward compatible 2.x - existing code continues work.","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"bug-fixes-3-0-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"corrselect 3.0.0","text":"Added proper handling Inf NA VIF values pruning loop Clamped extreme R² values (> 0.9999) prevent division near-zero Added safety checks prevent removing variables Now uses stats::model.matrix() engines (robust) Eliminated “find columns” warnings Test suite: 261 tests pass zero warnings (CRAN-compliant)","code":""},{"path":[]},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"new-functions-3-0-0","dir":"Changelog","previous_headings":"Major Features","what":"New Functions","title":"corrselect 3.0.0","text":"Model-free pruning using pairwise correlations associations Automatic measure selection (measure = \"auto\") Supports exact mode (small p), greedy mode (large p), auto-selection force_in parameter protect important predictors Returns single pruned data.frame pairwise associations ≤ threshold VIF-based iterative removal multicollinear predictors Supports multiple engines: lm, glm, lme4, glmmTMB Custom engine support: Define modeling backends (INLA, mgcv, brms, etc.) Prunes fixed effects (preserves random effects mixed models) force_in parameter protecting important variables Returns pruned data.frame final fitted model","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"new-c-backend-3-0-0","dir":"Changelog","previous_headings":"Major Features","what":"New C++ Backend","title":"corrselect 3.0.0","text":"Polynomial-time complexity O(p² × k) vs exponential exact search Handles p > 100 efficiently Deterministic tie-breaking reproducibility Used corrPrune(mode = \"greedy\") mode = \"auto\"","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"enhancements-3-0-0","dir":"Changelog","previous_headings":"","what":"Enhancements","title":"corrselect 3.0.0","text":"Exact methods (corrSelect(), assocSelect()) now integrate seamlessly corrPrune() Deterministic subset selection multiple maximal sets exist Improved error messages threshold feasibility checks Better handling edge cases (single predictor, correlated, etc.) Custom engine interface modelPrune(): Users can define custom modeling backends fit diagnostics functions, enabling integration R modeling package","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"documentation-3-0-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"corrselect 3.0.0","text":"Quick Start: 5-minute introduction corrPrune() modelPrune() Complete Workflows: Real-world examples across 4 domains (ecology, social science, genomics, clinical) Comparison Alternatives: choose corrselect vs caret, Boruta, glmnet Performance Benchmarks: Timing comparisons, scalability tests, optimization guidelines Advanced Topics: Algorithms, custom engines (INLA, mgcv), performance optimization, troubleshooting Four new example datasets full documentation (bioclim, survey, genes, longitudinal) Updated README quickstart examples custom engine support Full documentation corrPrune() modelPrune() Usage examples modeling engines","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"package-changes-3-0-0","dir":"Changelog","previous_headings":"","what":"Package Changes","title":"corrselect 3.0.0","text":"Added lme4 glmmTMB Suggests (required respective engines) Version bumped 3.0.0 (major feature release) Updated package description reflect expanded pruning functionality","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"notes-3-0-0","dir":"Changelog","previous_headings":"","what":"Notes","title":"corrselect 3.0.0","text":"breaking changes: Version 3.0.0 fully backward compatible 2.0.1 large predictor sets (p > 20), use corrPrune(mode = \"auto\") best performance Mixed model engines require optional packages: install install.packages(c(\"lme4\", \"glmmTMB\"))","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"corrselect-201","dir":"Changelog","previous_headings":"","what":"corrselect 2.0.1","title":"corrselect 2.0.1","text":"CRAN release: 2025-09-08","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"bug-fixes-2-0-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"corrselect 2.0.1","text":"force_in MatSelect() now correctly accepts character column names. els now correctly lists valid subsets single variable forced . corrSelect() now displays appropriate warning one variable remains dropping unsupported columns. Association matrix construction assocSelect() now safely falls back 0 failed meaningless associations (e.g. empty chi-squared tables due sparse combinations unused factor levels).","code":""},{"path":"https://gcol33.github.io/corrselect/news/index.html","id":"features-added-2-0-1","dir":"Changelog","previous_headings":"","what":"Features Added","title":"corrselect 2.0.1","text":"assocSelect() now supports logical columns automatically converting factors.","code":""}]

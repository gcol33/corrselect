<h1 id="summary">Summary</h1>
<p><code>corrselect</code> <span class="citation"
data-cites="cran">(Colling 2025)</span> is a model-agnostic R package
for selecting variable subsets whose pairwise correlations or
associations do not exceed a user-defined threshold. Instead of
returning a single heuristic solution, it enumerates all maximal
admissible subsets. This allows users to select subsets before model
fitting, avoiding the common problems of highly correlated or associated
predictors, which inflate variance estimates, destabilize coefficient
estimates, and obscure the relative importance of variables. The package
also supports forced inclusion of user-specified predictors
(<code>forced_in</code>), ensuring that key variables are retained while
admissibility constraints govern the remainder.</p>
<p>The package supports both numeric and mixed-type data.
Correlation-based workflows include measures such as Pearson, Spearman,
Kendall, and biweight midcorrelation <span class="citation"
data-cites="Langfelder2008">(Langfelder and Horvath 2008)</span>, which
take values in <span class="math inline">[−1, 1]</span>.
Association-based workflows use measures normalized to <span
class="math inline">[0, 1]</span> for consistent thresholding, including
distance correlation <span class="citation"
data-cites="Szekely2007 Szekely2009">(Székely et al. 2007; Székely and
Rizzo 2009)</span>, the maximal information coefficient <span
class="citation" data-cites="Reshef2011">(<span class="nocase">Reshef et
al.</span> 2011)</span>, ANOVA <span
class="math inline"><em>η</em><sup>2</sup></span>, and Cramér’s V.</p>
<h1 id="statement-of-need">Statement of Need</h1>
<p>Collinearity among predictors is common in applied modeling and can
degrade inference and prediction <span class="citation"
data-cites="Dormann2013">(<span class="nocase">Dormann et al.</span>
2013)</span>. Popular utilities such as
<code>caret::findCorrelation()</code> apply greedy, order-dependent
filtering and return a single solution. Embedded and wrapper methods
like the elastic net <span class="citation"
data-cites="ZouHastie2005">(Zou and Hastie 2005)</span> or recursive
feature elimination <span class="citation"
data-cites="Witten2009">(Witten et al. 2009)</span> can be powerful but
couple selection to a specific model and reduce transparency.</p>
<p><code>corrselect</code> instead formulates a global admissible set
problem. Given variables <span
class="math inline"><em>X</em><sub>1</sub>, …, <em>X</em><sub><em>p</em></sub></span>
and pairwise measures <span
class="math inline"><em>r</em><sub><em>i</em><em>j</em></sub></span>,
the goal is to find all maximal subsets <span
class="math inline"><em>S</em></span> such that</p>
<p><span
class="math display">|<em>r</em><sub><em>i</em><em>j</em></sub>| ≤ <em>t</em>  for
all <em>i</em> ≠ <em>j</em> ∈ <em>S</em>,</span></p>
<p>with a user threshold <span
class="math inline"><em>t</em> ∈ (0, 1)</span>. The software supports
mixed variable types, optional forced inclusion of key predictors, and
exhaustive coverage of all maximal solutions.</p>
<h1 id="functionality">Functionality</h1>
<p>Three core functions implement the main subset selection tasks:</p>
<ul>
<li><code>corrSelect()</code> takes a numeric data frame, computes
pairwise correlations, and selects admissible subsets at threshold <span
class="math inline"><em>t</em></span>.</li>
<li><code>assocSelect()</code> handles mixed-type data, computes
normalized association measures in <span
class="math inline">[0, 1]</span>, and selects admissible subsets at
threshold <span class="math inline"><em>t</em></span>.</li>
<li><code>MatSelect()</code> provides a lower-level interface for users
who already have a precomputed correlation or association matrix.</li>
</ul>
<p>All return a <code>CorrCombo</code> object containing maximal
subsets, summary statistics, and standard methods <code>print</code>,
<code>summary</code> and <code>as.data.frame</code>. For example, given
a data frame <code>df</code> in wide format (variables in columns,
observations in rows), <code>corrSelect(df, t = 0.7)</code> returns all
maximal subsets of numeric variables whose pairwise correlations are
below 0.7. The function <code>assocSelect(df, t = 0.7)</code>
generalizes this to mixed-type variables (numeric, binary, or
categorical) using normalized association measures.</p>
<p>Internally, the package implements two algorithms for exhaustive
enumeration:</p>
<ul>
<li><strong>Efficient Local Search (ELS)</strong>: a recursive
branch-and-bound algorithm that expands admissible subsets while pruning
early, particularly effective when <code>forced_in</code> seeds are
specified.<br />
</li>
<li><strong>Bron–Kerbosch</strong>: classical maximal clique enumeration
on the complement of the thresholded association graph <span
class="citation" data-cites="Bron1973">(Bron and Kerbosch 1973)</span>,
guaranteeing exhaustive coverage and performing well when the graph is
sparse.</li>
</ul>
<p>Both methods ensure non-redundant and complete enumeration of
admissible subsets.</p>
<h1 id="related-work">Related Work</h1>
<p>Heuristic correlation filters are widely used but are order dependent
and return only a single result. <code>corrselect</code> extends this
space by providing exhaustive enumeration, support for mixed data, and
user control via <code>forced_in</code>. Compared with embedded or
wrapper selection, it is model agnostic and interpretable. Its
graph-theoretic foundation links admissible subsets to maximal cliques
and independent sets, with ELS offering a complementary search
strategy.</p>
<p>Other feature selection methods include embedded approaches such as
the elastic net <span class="citation" data-cites="ZouHastie2005">(Zou
and Hastie 2005)</span>, recursive feature elimination <span
class="citation" data-cites="Witten2009">(Witten et al. 2009)</span>, or
permutation-based algorithms such as Boruta. These methods can be
powerful but are tied to specific modeling frameworks,
non-deterministic, and less interpretable in the presence of
multicollinearity. By contrast, <code>corrselect</code> is fast,
deterministic, and model agnostic, formulating subset selection as a
well-defined graph optimization problem.</p>
<h1 id="applications">Applications</h1>
<p>The approach supports feature screening in high-dimensional settings
and exploratory mapping of alternative, equally valid predictor sets.
With support for robust correlation and association measures such as
biweight midcorrelation <span class="citation"
data-cites="Langfelder2008">(Langfelder and Horvath 2008)</span>,
distance correlation <span class="citation"
data-cites="Szekely2007 Szekely2009">(Székely et al. 2007; Székely and
Rizzo 2009)</span>, and the maximal information coefficient <span
class="citation" data-cites="Reshef2011">(<span class="nocase">Reshef et
al.</span> 2011)</span>, <code>corrselect</code> is applicable across
domains including genomics, network analysis, environmental modeling,
and machine learning.</p>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Bron1973" class="csl-entry" role="listitem">
Bron, Coen, and Joep Kerbosch. 1973. <span>“Algorithm 457: Finding All
Cliques of an Undirected Graph.”</span> <em>Communications of the
ACM</em> 16 (9): 575–77. <a
href="https://doi.org/10.1145/362342.362367">https://doi.org/10.1145/362342.362367</a>.
</div>
<div id="ref-cran" class="csl-entry" role="listitem">
Colling, Gilles. 2025. <em>Corrselect: Correlation-Based Variable Subset
Selection</em>. <a
href="https://doi.org/10.32614/CRAN.package.corrselect">https://doi.org/10.32614/CRAN.package.corrselect</a>.
</div>
<div id="ref-Dormann2013" class="csl-entry" role="listitem">
<span class="nocase">Dormann, Carsten F., Jane Elith, Sven Bacher, and
et al.</span> 2013. <span>“Collinearity: A Review of Methods to Deal
with It and a Simulation Study Evaluating Their Performance.”</span>
<em>Ecography</em> 36 (1): 27–46. <a
href="https://doi.org/10.1111/j.1600-0587.2012.07348.x">https://doi.org/10.1111/j.1600-0587.2012.07348.x</a>.
</div>
<div id="ref-Langfelder2008" class="csl-entry" role="listitem">
Langfelder, Peter, and Steve Horvath. 2008. <span>“WGCNA: An r Package
for Weighted Correlation Network Analysis.”</span> <em>BMC
Bioinformatics</em> 9 (1): 559. <a
href="https://doi.org/10.1186/1471-2105-9-559">https://doi.org/10.1186/1471-2105-9-559</a>.
</div>
<div id="ref-Reshef2011" class="csl-entry" role="listitem">
<span class="nocase">Reshef, David N., Yakir A. Reshef, Hilary K.
Finucane, and et al.</span> 2011. <span>“Detecting Novel Associations in
Large Data Sets.”</span> <em>Science</em> 334 (6062): 1518–24. <a
href="https://doi.org/10.1126/science.1205438">https://doi.org/10.1126/science.1205438</a>.
</div>
<div id="ref-Szekely2009" class="csl-entry" role="listitem">
Székely, Gábor J., and Maria L. Rizzo. 2009. <span>“Brownian Distance
Covariance.”</span> <em>The Annals of Applied Statistics</em> 3 (4):
1236–65. <a
href="https://doi.org/10.1214/09-AOAS312">https://doi.org/10.1214/09-AOAS312</a>.
</div>
<div id="ref-Szekely2007" class="csl-entry" role="listitem">
Székely, Gábor J., Maria L. Rizzo, and N. K. Bakirov. 2007.
<span>“Measuring and Testing Dependence by Correlation of
Distances.”</span> <em>The Annals of Statistics</em> 35 (6): 2769–94. <a
href="https://doi.org/10.1214/009053607000000505">https://doi.org/10.1214/009053607000000505</a>.
</div>
<div id="ref-Witten2009" class="csl-entry" role="listitem">
Witten, Daniela M., Robert Tibshirani, and Trevor Hastie. 2009. <span>“A
Penalized Matrix Decomposition, with Applications to Sparse Principal
Components and Canonical Correlation Analysis.”</span>
<em>Biostatistics</em> 10 (3): 515–34. <a
href="https://doi.org/10.1093/biostatistics/kxp008">https://doi.org/10.1093/biostatistics/kxp008</a>.
</div>
<div id="ref-ZouHastie2005" class="csl-entry" role="listitem">
Zou, Hui, and Trevor Hastie. 2005. <span>“Regularization and Variable
Selection via the Elastic Net.”</span> <em>Journal of the Royal
Statistical Society: Series B</em> 67 (2): 301–20. <a
href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">https://doi.org/10.1111/j.1467-9868.2005.00503.x</a>.
</div>
</div>
